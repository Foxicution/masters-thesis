{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Node features\n",
    "x = torch.tensor([[1], [2], [3], [4]], dtype=torch.float)\n",
    "\n",
    "# Edges (directed)\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 0], [1, 2, 3, 0, 2]], dtype=torch.long)\n",
    "\n",
    "# Create a simple graph\n",
    "data = Data(x=x, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleGATModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(SimpleGATModel, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleGATModel(in_channels=1, hidden_channels=8, out_channels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from GAT: tensor([[-0.9282, -0.5029],\n",
      "        [-0.8358, -0.5684],\n",
      "        [-0.8299, -0.5728],\n",
      "        [-0.9039, -0.5192]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = data.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data)\n",
    "\n",
    "print(\"Output from GAT:\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# Create three simple graphs\n",
    "graph1 = Data(x=torch.randn(3, 4), edge_index=torch.tensor([[0, 1], [1, 2]]))\n",
    "graph2 = Data(x=torch.randn(4, 4), edge_index=torch.tensor([[0, 1, 2], [1, 2, 3]]))\n",
    "graph3 = Data(x=torch.randn(5, 4), edge_index=torch.tensor([[0, 1, 3, 4], [1, 2, 4, 0]]))\n",
    "\n",
    "graphs = [graph1, graph2, graph3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[12, 4], edge_index=[2, 9], batch=[12], ptr=[4])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "# Batch the graphs\n",
    "batched_graph = Batch.from_data_list(graphs)\n",
    "print(batched_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)  # Aggregate node features for each graph in the batch\n",
    "        return x\n",
    "\n",
    "# Instantiate the model for 4 features per node, hidden size of 8, and output size of 2\n",
    "model = GATModel(in_channels=4, hidden_channels=8, out_channels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for each graph in the batch: tensor([[ 0.4257, -0.1969],\n",
      "        [ 0.3806, -0.1568],\n",
      "        [-0.0144, -0.4852]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "batched_graph = batched_graph.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(batched_graph.x, batched_graph.edge_index, batched_graph.batch)\n",
    "\n",
    "print(\"Output for each graph in the batch:\", out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of batched graphs with regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# Example synthetic graphs with variable sizes\n",
    "batch_1 = [Data(x=torch.randn(5, 4), edge_index=torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]], dtype=torch.long))]\n",
    "batch_2 = [Data(x=torch.randn(3, 4), edge_index=torch.tensor([[0, 1], [1, 2]], dtype=torch.long)),\n",
    "           Data(x=torch.randn(4, 4), edge_index=torch.tensor([[0, 1, 3], [1, 2, 0]], dtype=torch.long))]\n",
    "\n",
    "# Example target values for each batch\n",
    "targets = torch.tensor([1.5, 2.5], dtype=torch.float)  # Assume one target per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to use a Transformer for the attention in the attention. I also want to then output the graph feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomGATModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(CustomGATModel, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        # Attention parameters\n",
    "        self.attention_weight = nn.Parameter(torch.Tensor(1, hidden_channels))\n",
    "        nn.init.xavier_uniform_(self.attention_weight.data)\n",
    "        \n",
    "        self.regressor = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, batched_graphs):\n",
    "        batched_graphs_representations = []\n",
    "        \n",
    "        for graph in batched_graphs:\n",
    "            x, edge_index = graph.x, graph.edge_index\n",
    "            x = F.relu(self.conv1(x, edge_index))\n",
    "            x = self.conv2(x, edge_index)\n",
    "            graph_rep = global_mean_pool(x, torch.zeros(x.size(0), dtype=torch.long))\n",
    "            batched_graphs_representations.append(graph_rep)\n",
    "        \n",
    "        stacked_graphs = torch.stack(batched_graphs_representations)\n",
    "        attention_scores = F.softmax(torch.matmul(stacked_graphs, self.attention_weight.t()), dim=0)\n",
    "        weighted_graphs = attention_scores * stacked_graphs\n",
    "        aggregated_representation = weighted_graphs.sum(dim=0)\n",
    "        \n",
    "        return self.regressor(aggregated_representation.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 5.70572829246521\n",
      "Epoch 2: Loss = 5.039193868637085\n",
      "Epoch 3: Loss = 4.404805541038513\n",
      "Epoch 4: Loss = 3.770244836807251\n",
      "Epoch 5: Loss = 3.127368927001953\n",
      "Epoch 6: Loss = 2.4923004806041718\n",
      "Epoch 7: Loss = 1.8808511048555374\n",
      "Epoch 8: Loss = 1.3253581002354622\n",
      "Epoch 9: Loss = 0.8666664697229862\n",
      "Epoch 10: Loss = 0.5506589123979211\n",
      "Epoch 11: Loss = 0.3989603519439697\n",
      "Epoch 12: Loss = 0.3771768808364868\n",
      "Epoch 13: Loss = 0.4059327505528927\n",
      "Epoch 14: Loss = 0.4133408199995756\n",
      "Epoch 15: Loss = 0.37083821976557374\n",
      "Epoch 16: Loss = 0.2901630220003426\n",
      "Epoch 17: Loss = 0.1969689299003221\n",
      "Epoch 18: Loss = 0.11430122726596892\n",
      "Epoch 19: Loss = 0.05676121870055795\n",
      "Epoch 20: Loss = 0.022949688602238894\n",
      "Epoch 21: Loss = 0.007973676081746817\n",
      "Epoch 22: Loss = 0.0050618820896488614\n",
      "Epoch 23: Loss = 0.00774279423058033\n",
      "Epoch 24: Loss = 0.011435679392889142\n",
      "Epoch 25: Loss = 0.014049841091036797\n",
      "Epoch 26: Loss = 0.015249293091983418\n",
      "Epoch 27: Loss = 0.015510070137679577\n",
      "Epoch 28: Loss = 0.015359828947111964\n",
      "Epoch 29: Loss = 0.015021981205791235\n",
      "Epoch 30: Loss = 0.014223311562091112\n",
      "Epoch 31: Loss = 0.012663526926189661\n",
      "Epoch 32: Loss = 0.010380833642557263\n",
      "Epoch 33: Loss = 0.007679834263399243\n",
      "Epoch 34: Loss = 0.0050283229211345315\n",
      "Epoch 35: Loss = 0.0028707688907161355\n",
      "Epoch 36: Loss = 0.00142632209463045\n",
      "Epoch 37: Loss = 0.000656224561680574\n",
      "Epoch 38: Loss = 0.0003670152073027566\n",
      "Epoch 39: Loss = 0.0003237716155126691\n",
      "Epoch 40: Loss = 0.000353702900611097\n",
      "Epoch 41: Loss = 0.00037535335088279\n",
      "Epoch 42: Loss = 0.0003815337040578015\n",
      "Epoch 43: Loss = 0.0003951323888031766\n",
      "Epoch 44: Loss = 0.000429514329880476\n",
      "Epoch 45: Loss = 0.0004726581246359274\n",
      "Epoch 46: Loss = 0.0004964735708199441\n",
      "Epoch 47: Loss = 0.00047705772340123076\n",
      "Epoch 48: Loss = 0.0004097312266821973\n",
      "Epoch 49: Loss = 0.0003104493252976681\n",
      "Epoch 50: Loss = 0.00020542689344438259\n",
      "Epoch 51: Loss = 0.00011760117558878846\n",
      "Epoch 52: Loss = 5.8069250371772796e-05\n",
      "Epoch 53: Loss = 2.5699962861835957e-05\n",
      "Epoch 54: Loss = 1.242170453252811e-05\n",
      "Epoch 55: Loss = 9.523972948954906e-06\n",
      "Epoch 56: Loss = 1.1287088909739396e-05\n",
      "Epoch 57: Loss = 1.5120236895427297e-05\n",
      "Epoch 58: Loss = 1.9852117247864953e-05\n",
      "Epoch 59: Loss = 2.41999505306012e-05\n",
      "Epoch 60: Loss = 2.6552715098659974e-05\n",
      "Epoch 61: Loss = 2.5737880605447572e-05\n",
      "Epoch 62: Loss = 2.1817893866682425e-05\n",
      "Epoch 63: Loss = 1.608644697626005e-05\n",
      "Epoch 64: Loss = 1.0323494279873557e-05\n",
      "Epoch 65: Loss = 5.873675945622381e-06\n",
      "Epoch 66: Loss = 3.1566157758788904e-06\n",
      "Epoch 67: Loss = 1.8136397841317375e-06\n",
      "Epoch 68: Loss = 1.20481502108305e-06\n",
      "Epoch 69: Loss = 8.718944002339413e-07\n",
      "Epoch 70: Loss = 6.77093709100518e-07\n",
      "Epoch 71: Loss = 6.728296852998028e-07\n",
      "Epoch 72: Loss = 8.82039131511192e-07\n",
      "Epoch 73: Loss = 1.1993296595846914e-06\n",
      "Epoch 74: Loss = 1.4413733424589736e-06\n",
      "Epoch 75: Loss = 1.4692091099277604e-06\n",
      "Epoch 76: Loss = 1.2674309175508824e-06\n",
      "Epoch 77: Loss = 9.312374800174439e-07\n",
      "Epoch 78: Loss = 5.86409157676826e-07\n",
      "Epoch 79: Loss = 3.201212734893488e-07\n",
      "Epoch 80: Loss = 1.5446045154021704e-07\n",
      "Epoch 81: Loss = 6.924216222614632e-08\n",
      "Epoch 82: Loss = 3.41921406743495e-08\n",
      "Epoch 83: Loss = 3.008870663734342e-08\n",
      "Epoch 84: Loss = 4.686626908778635e-08\n",
      "Epoch 85: Loss = 7.447051331155308e-08\n",
      "Epoch 86: Loss = 9.883052598524955e-08\n",
      "Epoch 87: Loss = 1.0779743320199486e-07\n",
      "Epoch 88: Loss = 9.7580233671124e-08\n",
      "Epoch 89: Loss = 7.429528636748728e-08\n",
      "Epoch 90: Loss = 4.855661472902284e-08\n",
      "Epoch 91: Loss = 2.857873937500699e-08\n",
      "Epoch 92: Loss = 1.6386941581458814e-08\n",
      "Epoch 93: Loss = 1.0005720696426579e-08\n",
      "Epoch 94: Loss = 6.104308170051809e-09\n",
      "Epoch 95: Loss = 3.484757371552405e-09\n",
      "Epoch 96: Loss = 2.4121220576489577e-09\n",
      "Epoch 97: Loss = 3.246732660500129e-09\n",
      "Epoch 98: Loss = 5.368924860249535e-09\n",
      "Epoch 99: Loss = 7.368072374447365e-09\n",
      "Epoch 100: Loss = 7.967436488343083e-09\n",
      "Epoch 101: Loss = 6.998845947236987e-09\n",
      "Epoch 102: Loss = 5.1275321766297566e-09\n",
      "Epoch 103: Loss = 3.2059972454590024e-09\n",
      "Epoch 104: Loss = 1.723066134218243e-09\n",
      "Epoch 105: Loss = 8.077734037215123e-10\n",
      "Epoch 106: Loss = 3.383888724783901e-10\n",
      "Epoch 107: Loss = 1.553601691739459e-10\n",
      "Epoch 108: Loss = 1.9340973267389927e-10\n",
      "Epoch 109: Loss = 3.80310893888236e-10\n",
      "Epoch 110: Loss = 5.900702149119752e-10\n",
      "Epoch 111: Loss = 6.92558899118012e-10\n",
      "Epoch 112: Loss = 6.45634656848415e-10\n",
      "Epoch 113: Loss = 4.952767085342202e-10\n",
      "Epoch 114: Loss = 3.2290614626617753e-10\n",
      "Epoch 115: Loss = 1.9247181626269594e-10\n",
      "Epoch 116: Loss = 1.1690559631460928e-10\n",
      "Epoch 117: Loss = 7.0947692165646e-11\n",
      "Epoch 118: Loss = 3.849009999612463e-11\n",
      "Epoch 119: Loss = 1.7763568394002505e-11\n",
      "Epoch 120: Loss = 1.6626700016786344e-11\n",
      "Epoch 121: Loss = 3.036149109902908e-11\n",
      "Epoch 122: Loss = 5.071143505119835e-11\n",
      "Epoch 123: Loss = 5.985612006043084e-11\n",
      "Epoch 124: Loss = 5.972111694063642e-11\n",
      "Epoch 125: Loss = 4.5567105644295225e-11\n",
      "Epoch 126: Loss = 2.8705926524708048e-11\n",
      "Epoch 127: Loss = 1.4779288903810084e-11\n",
      "Epoch 128: Loss = 6.622258297284134e-12\n",
      "Epoch 129: Loss = 2.8492763703980017e-12\n",
      "Epoch 130: Loss = 1.2860823517257813e-12\n",
      "Epoch 131: Loss = 1.7124079931818414e-12\n",
      "Epoch 132: Loss = 3.325340003357269e-12\n",
      "Epoch 133: Loss = 4.89563944938709e-12\n",
      "Epoch 134: Loss = 4.89563944938709e-12\n",
      "Epoch 135: Loss = 5.258016244624741e-12\n",
      "Epoch 136: Loss = 4.661160346586257e-12\n",
      "Epoch 137: Loss = 2.6219026949547697e-12\n",
      "Epoch 138: Loss = 1.8545165403338615e-12\n",
      "Epoch 139: Loss = 1.0231815394945443e-12\n",
      "Epoch 140: Loss = 4.618527782440651e-13\n",
      "Epoch 141: Loss = 2.8421709430404007e-13\n",
      "Epoch 142: Loss = 2.5579538487363607e-13\n",
      "Epoch 143: Loss = 2.2737367544323206e-13\n",
      "Epoch 144: Loss = 3.694822225952521e-13\n",
      "Epoch 145: Loss = 4.618527782440651e-13\n",
      "Epoch 146: Loss = 3.481659405224491e-13\n",
      "Epoch 147: Loss = 3.481659405224491e-13\n",
      "Epoch 148: Loss = 2.5579538487363607e-13\n",
      "Epoch 149: Loss = 3.694822225952521e-13\n",
      "Epoch 150: Loss = 2.5579538487363607e-13\n",
      "Epoch 151: Loss = 2.2737367544323206e-13\n",
      "Epoch 152: Loss = 2.2737367544323206e-13\n",
      "Epoch 153: Loss = 2.842170943040401e-14\n",
      "Epoch 154: Loss = 2.842170943040401e-14\n",
      "Epoch 155: Loss = 0.0\n",
      "Epoch 156: Loss = 2.842170943040401e-14\n",
      "Epoch 157: Loss = 0.0\n",
      "Epoch 158: Loss = 0.0\n",
      "Epoch 159: Loss = 2.842170943040401e-14\n",
      "Epoch 160: Loss = 2.842170943040401e-14\n",
      "Epoch 161: Loss = 2.842170943040401e-14\n",
      "Epoch 162: Loss = 2.842170943040401e-14\n",
      "Epoch 163: Loss = 2.842170943040401e-14\n",
      "Epoch 164: Loss = 2.842170943040401e-14\n",
      "Epoch 165: Loss = 2.842170943040401e-14\n",
      "Epoch 166: Loss = 2.842170943040401e-14\n",
      "Epoch 167: Loss = 0.0\n",
      "Epoch 168: Loss = 0.0\n",
      "Epoch 169: Loss = 0.0\n",
      "Epoch 170: Loss = 0.0\n",
      "Epoch 171: Loss = 0.0\n",
      "Epoch 172: Loss = 0.0\n",
      "Epoch 173: Loss = 0.0\n",
      "Epoch 174: Loss = 0.0\n",
      "Epoch 175: Loss = 0.0\n",
      "Epoch 176: Loss = 0.0\n",
      "Epoch 177: Loss = 0.0\n",
      "Epoch 178: Loss = 0.0\n",
      "Epoch 179: Loss = 0.0\n",
      "Epoch 180: Loss = 0.0\n",
      "Epoch 181: Loss = 0.0\n",
      "Epoch 182: Loss = 0.0\n",
      "Epoch 183: Loss = 0.0\n",
      "Epoch 184: Loss = 0.0\n",
      "Epoch 185: Loss = 0.0\n",
      "Epoch 186: Loss = 0.0\n",
      "Epoch 187: Loss = 0.0\n",
      "Epoch 188: Loss = 0.0\n",
      "Epoch 189: Loss = 0.0\n",
      "Epoch 190: Loss = 0.0\n",
      "Epoch 191: Loss = 0.0\n",
      "Epoch 192: Loss = 0.0\n",
      "Epoch 193: Loss = 0.0\n",
      "Epoch 194: Loss = 0.0\n",
      "Epoch 195: Loss = 0.0\n",
      "Epoch 196: Loss = 0.0\n",
      "Epoch 197: Loss = 0.0\n",
      "Epoch 198: Loss = 0.0\n",
      "Epoch 199: Loss = 0.0\n",
      "Epoch 200: Loss = 0.0\n",
      "Epoch 201: Loss = 0.0\n",
      "Epoch 202: Loss = 0.0\n",
      "Epoch 203: Loss = 0.0\n",
      "Epoch 204: Loss = 0.0\n",
      "Epoch 205: Loss = 0.0\n",
      "Epoch 206: Loss = 0.0\n",
      "Epoch 207: Loss = 0.0\n",
      "Epoch 208: Loss = 0.0\n",
      "Epoch 209: Loss = 0.0\n",
      "Epoch 210: Loss = 0.0\n",
      "Epoch 211: Loss = 0.0\n",
      "Epoch 212: Loss = 0.0\n",
      "Epoch 213: Loss = 0.0\n",
      "Epoch 214: Loss = 0.0\n",
      "Epoch 215: Loss = 0.0\n",
      "Epoch 216: Loss = 0.0\n",
      "Epoch 217: Loss = 0.0\n",
      "Epoch 218: Loss = 0.0\n",
      "Epoch 219: Loss = 0.0\n",
      "Epoch 220: Loss = 0.0\n",
      "Epoch 221: Loss = 0.0\n",
      "Epoch 222: Loss = 0.0\n",
      "Epoch 223: Loss = 0.0\n",
      "Epoch 224: Loss = 0.0\n",
      "Epoch 225: Loss = 0.0\n",
      "Epoch 226: Loss = 0.0\n",
      "Epoch 227: Loss = 0.0\n",
      "Epoch 228: Loss = 0.0\n",
      "Epoch 229: Loss = 0.0\n",
      "Epoch 230: Loss = 0.0\n",
      "Epoch 231: Loss = 0.0\n",
      "Epoch 232: Loss = 0.0\n",
      "Epoch 233: Loss = 0.0\n",
      "Epoch 234: Loss = 0.0\n",
      "Epoch 235: Loss = 0.0\n",
      "Epoch 236: Loss = 0.0\n",
      "Epoch 237: Loss = 0.0\n",
      "Epoch 238: Loss = 0.0\n",
      "Epoch 239: Loss = 0.0\n",
      "Epoch 240: Loss = 0.0\n",
      "Epoch 241: Loss = 0.0\n",
      "Epoch 242: Loss = 0.0\n",
      "Epoch 243: Loss = 0.0\n",
      "Epoch 244: Loss = 0.0\n",
      "Epoch 245: Loss = 0.0\n",
      "Epoch 246: Loss = 0.0\n",
      "Epoch 247: Loss = 0.0\n",
      "Epoch 248: Loss = 0.0\n",
      "Epoch 249: Loss = 0.0\n",
      "Epoch 250: Loss = 0.0\n",
      "Epoch 251: Loss = 0.0\n",
      "Epoch 252: Loss = 0.0\n",
      "Epoch 253: Loss = 0.0\n",
      "Epoch 254: Loss = 0.0\n",
      "Epoch 255: Loss = 0.0\n",
      "Epoch 256: Loss = 0.0\n",
      "Epoch 257: Loss = 0.0\n",
      "Epoch 258: Loss = 0.0\n",
      "Epoch 259: Loss = 0.0\n",
      "Epoch 260: Loss = 0.0\n",
      "Epoch 261: Loss = 0.0\n",
      "Epoch 262: Loss = 0.0\n",
      "Epoch 263: Loss = 0.0\n",
      "Epoch 264: Loss = 0.0\n",
      "Epoch 265: Loss = 0.0\n",
      "Epoch 266: Loss = 0.0\n",
      "Epoch 267: Loss = 0.0\n",
      "Epoch 268: Loss = 0.0\n",
      "Epoch 269: Loss = 0.0\n",
      "Epoch 270: Loss = 0.0\n",
      "Epoch 271: Loss = 0.0\n",
      "Epoch 272: Loss = 0.0\n",
      "Epoch 273: Loss = 0.0\n",
      "Epoch 274: Loss = 0.0\n",
      "Epoch 275: Loss = 0.0\n",
      "Epoch 276: Loss = 0.0\n",
      "Epoch 277: Loss = 0.0\n",
      "Epoch 278: Loss = 0.0\n",
      "Epoch 279: Loss = 0.0\n",
      "Epoch 280: Loss = 0.0\n",
      "Epoch 281: Loss = 0.0\n",
      "Epoch 282: Loss = 0.0\n",
      "Epoch 283: Loss = 0.0\n",
      "Epoch 284: Loss = 0.0\n",
      "Epoch 285: Loss = 0.0\n",
      "Epoch 286: Loss = 0.0\n",
      "Epoch 287: Loss = 0.0\n",
      "Epoch 288: Loss = 0.0\n",
      "Epoch 289: Loss = 0.0\n",
      "Epoch 290: Loss = 0.0\n",
      "Epoch 291: Loss = 0.0\n",
      "Epoch 292: Loss = 0.0\n",
      "Epoch 293: Loss = 0.0\n",
      "Epoch 294: Loss = 0.0\n",
      "Epoch 295: Loss = 0.0\n",
      "Epoch 296: Loss = 0.0\n",
      "Epoch 297: Loss = 0.0\n",
      "Epoch 298: Loss = 0.0\n",
      "Epoch 299: Loss = 0.0\n",
      "Epoch 300: Loss = 0.0\n",
      "Epoch 301: Loss = 0.0\n",
      "Epoch 302: Loss = 0.0\n",
      "Epoch 303: Loss = 0.0\n",
      "Epoch 304: Loss = 0.0\n",
      "Epoch 305: Loss = 0.0\n",
      "Epoch 306: Loss = 0.0\n",
      "Epoch 307: Loss = 0.0\n",
      "Epoch 308: Loss = 0.0\n",
      "Epoch 309: Loss = 0.0\n",
      "Epoch 310: Loss = 0.0\n",
      "Epoch 311: Loss = 0.0\n",
      "Epoch 312: Loss = 0.0\n",
      "Epoch 313: Loss = 0.0\n",
      "Epoch 314: Loss = 0.0\n",
      "Epoch 315: Loss = 0.0\n",
      "Epoch 316: Loss = 0.0\n",
      "Epoch 317: Loss = 0.0\n",
      "Epoch 318: Loss = 0.0\n",
      "Epoch 319: Loss = 0.0\n",
      "Epoch 320: Loss = 0.0\n",
      "Epoch 321: Loss = 0.0\n",
      "Epoch 322: Loss = 0.0\n",
      "Epoch 323: Loss = 0.0\n",
      "Epoch 324: Loss = 0.0\n",
      "Epoch 325: Loss = 0.0\n",
      "Epoch 326: Loss = 0.0\n",
      "Epoch 327: Loss = 0.0\n",
      "Epoch 328: Loss = 0.0\n",
      "Epoch 329: Loss = 0.0\n",
      "Epoch 330: Loss = 0.0\n",
      "Epoch 331: Loss = 0.0\n",
      "Epoch 332: Loss = 0.0\n",
      "Epoch 333: Loss = 0.0\n",
      "Epoch 334: Loss = 0.0\n",
      "Epoch 335: Loss = 0.0\n",
      "Epoch 336: Loss = 0.0\n",
      "Epoch 337: Loss = 0.0\n",
      "Epoch 338: Loss = 0.0\n",
      "Epoch 339: Loss = 0.0\n",
      "Epoch 340: Loss = 0.0\n",
      "Epoch 341: Loss = 0.0\n",
      "Epoch 342: Loss = 0.0\n",
      "Epoch 343: Loss = 0.0\n",
      "Epoch 344: Loss = 0.0\n",
      "Epoch 345: Loss = 0.0\n",
      "Epoch 346: Loss = 0.0\n",
      "Epoch 347: Loss = 0.0\n",
      "Epoch 348: Loss = 0.0\n",
      "Epoch 349: Loss = 0.0\n",
      "Epoch 350: Loss = 0.0\n",
      "Epoch 351: Loss = 0.0\n",
      "Epoch 352: Loss = 0.0\n",
      "Epoch 353: Loss = 0.0\n",
      "Epoch 354: Loss = 0.0\n",
      "Epoch 355: Loss = 0.0\n",
      "Epoch 356: Loss = 0.0\n",
      "Epoch 357: Loss = 0.0\n",
      "Epoch 358: Loss = 0.0\n",
      "Epoch 359: Loss = 0.0\n",
      "Epoch 360: Loss = 0.0\n",
      "Epoch 361: Loss = 0.0\n",
      "Epoch 362: Loss = 0.0\n",
      "Epoch 363: Loss = 0.0\n",
      "Epoch 364: Loss = 0.0\n",
      "Epoch 365: Loss = 0.0\n",
      "Epoch 366: Loss = 0.0\n",
      "Epoch 367: Loss = 0.0\n",
      "Epoch 368: Loss = 0.0\n",
      "Epoch 369: Loss = 0.0\n",
      "Epoch 370: Loss = 0.0\n",
      "Epoch 371: Loss = 0.0\n",
      "Epoch 372: Loss = 0.0\n",
      "Epoch 373: Loss = 0.0\n",
      "Epoch 374: Loss = 0.0\n",
      "Epoch 375: Loss = 0.0\n",
      "Epoch 376: Loss = 0.0\n",
      "Epoch 377: Loss = 0.0\n",
      "Epoch 378: Loss = 0.0\n",
      "Epoch 379: Loss = 0.0\n",
      "Epoch 380: Loss = 0.0\n",
      "Epoch 381: Loss = 0.0\n",
      "Epoch 382: Loss = 0.0\n",
      "Epoch 383: Loss = 0.0\n",
      "Epoch 384: Loss = 0.0\n",
      "Epoch 385: Loss = 0.0\n",
      "Epoch 386: Loss = 0.0\n",
      "Epoch 387: Loss = 0.0\n",
      "Epoch 388: Loss = 0.0\n",
      "Epoch 389: Loss = 0.0\n",
      "Epoch 390: Loss = 0.0\n",
      "Epoch 391: Loss = 0.0\n",
      "Epoch 392: Loss = 0.0\n",
      "Epoch 393: Loss = 0.0\n",
      "Epoch 394: Loss = 0.0\n",
      "Epoch 395: Loss = 0.0\n",
      "Epoch 396: Loss = 0.0\n",
      "Epoch 397: Loss = 0.0\n",
      "Epoch 398: Loss = 0.0\n",
      "Epoch 399: Loss = 0.0\n",
      "Epoch 400: Loss = 0.0\n",
      "Epoch 401: Loss = 0.0\n",
      "Epoch 402: Loss = 0.0\n",
      "Epoch 403: Loss = 0.0\n",
      "Epoch 404: Loss = 0.0\n",
      "Epoch 405: Loss = 0.0\n",
      "Epoch 406: Loss = 0.0\n",
      "Epoch 407: Loss = 0.0\n",
      "Epoch 408: Loss = 0.0\n",
      "Epoch 409: Loss = 0.0\n",
      "Epoch 410: Loss = 0.0\n",
      "Epoch 411: Loss = 0.0\n",
      "Epoch 412: Loss = 0.0\n",
      "Epoch 413: Loss = 0.0\n",
      "Epoch 414: Loss = 0.0\n",
      "Epoch 415: Loss = 0.0\n",
      "Epoch 416: Loss = 0.0\n",
      "Epoch 417: Loss = 0.0\n",
      "Epoch 418: Loss = 0.0\n",
      "Epoch 419: Loss = 0.0\n",
      "Epoch 420: Loss = 0.0\n",
      "Epoch 421: Loss = 0.0\n",
      "Epoch 422: Loss = 0.0\n",
      "Epoch 423: Loss = 0.0\n",
      "Epoch 424: Loss = 0.0\n",
      "Epoch 425: Loss = 0.0\n",
      "Epoch 426: Loss = 0.0\n",
      "Epoch 427: Loss = 0.0\n",
      "Epoch 428: Loss = 0.0\n",
      "Epoch 429: Loss = 0.0\n",
      "Epoch 430: Loss = 0.0\n",
      "Epoch 431: Loss = 0.0\n",
      "Epoch 432: Loss = 0.0\n",
      "Epoch 433: Loss = 0.0\n",
      "Epoch 434: Loss = 0.0\n",
      "Epoch 435: Loss = 0.0\n",
      "Epoch 436: Loss = 0.0\n",
      "Epoch 437: Loss = 0.0\n",
      "Epoch 438: Loss = 0.0\n",
      "Epoch 439: Loss = 0.0\n",
      "Epoch 440: Loss = 0.0\n",
      "Epoch 441: Loss = 0.0\n",
      "Epoch 442: Loss = 0.0\n",
      "Epoch 443: Loss = 0.0\n",
      "Epoch 444: Loss = 0.0\n",
      "Epoch 445: Loss = 0.0\n",
      "Epoch 446: Loss = 0.0\n",
      "Epoch 447: Loss = 0.0\n",
      "Epoch 448: Loss = 0.0\n",
      "Epoch 449: Loss = 0.0\n",
      "Epoch 450: Loss = 0.0\n",
      "Epoch 451: Loss = 0.0\n",
      "Epoch 452: Loss = 0.0\n",
      "Epoch 453: Loss = 0.0\n",
      "Epoch 454: Loss = 0.0\n",
      "Epoch 455: Loss = 0.0\n",
      "Epoch 456: Loss = 0.0\n",
      "Epoch 457: Loss = 0.0\n",
      "Epoch 458: Loss = 0.0\n",
      "Epoch 459: Loss = 0.0\n",
      "Epoch 460: Loss = 0.0\n",
      "Epoch 461: Loss = 0.0\n",
      "Epoch 462: Loss = 0.0\n",
      "Epoch 463: Loss = 0.0\n",
      "Epoch 464: Loss = 0.0\n",
      "Epoch 465: Loss = 0.0\n",
      "Epoch 466: Loss = 0.0\n",
      "Epoch 467: Loss = 0.0\n",
      "Epoch 468: Loss = 0.0\n",
      "Epoch 469: Loss = 0.0\n",
      "Epoch 470: Loss = 0.0\n",
      "Epoch 471: Loss = 0.0\n",
      "Epoch 472: Loss = 0.0\n",
      "Epoch 473: Loss = 0.0\n",
      "Epoch 474: Loss = 0.0\n",
      "Epoch 475: Loss = 0.0\n",
      "Epoch 476: Loss = 0.0\n",
      "Epoch 477: Loss = 0.0\n",
      "Epoch 478: Loss = 0.0\n",
      "Epoch 479: Loss = 0.0\n",
      "Epoch 480: Loss = 0.0\n",
      "Epoch 481: Loss = 0.0\n",
      "Epoch 482: Loss = 0.0\n",
      "Epoch 483: Loss = 0.0\n",
      "Epoch 484: Loss = 0.0\n",
      "Epoch 485: Loss = 0.0\n",
      "Epoch 486: Loss = 0.0\n",
      "Epoch 487: Loss = 0.0\n",
      "Epoch 488: Loss = 0.0\n",
      "Epoch 489: Loss = 0.0\n",
      "Epoch 490: Loss = 0.0\n",
      "Epoch 491: Loss = 0.0\n",
      "Epoch 492: Loss = 0.0\n",
      "Epoch 493: Loss = 0.0\n",
      "Epoch 494: Loss = 0.0\n",
      "Epoch 495: Loss = 0.0\n",
      "Epoch 496: Loss = 0.0\n",
      "Epoch 497: Loss = 0.0\n",
      "Epoch 498: Loss = 0.0\n",
      "Epoch 499: Loss = 0.0\n",
      "Epoch 500: Loss = 0.0\n",
      "Epoch 501: Loss = 0.0\n",
      "Epoch 502: Loss = 0.0\n",
      "Epoch 503: Loss = 0.0\n",
      "Epoch 504: Loss = 0.0\n",
      "Epoch 505: Loss = 0.0\n",
      "Epoch 506: Loss = 0.0\n",
      "Epoch 507: Loss = 0.0\n",
      "Epoch 508: Loss = 0.0\n",
      "Epoch 509: Loss = 0.0\n",
      "Epoch 510: Loss = 0.0\n",
      "Epoch 511: Loss = 0.0\n",
      "Epoch 512: Loss = 0.0\n",
      "Epoch 513: Loss = 0.0\n",
      "Epoch 514: Loss = 0.0\n",
      "Epoch 515: Loss = 0.0\n",
      "Epoch 516: Loss = 0.0\n",
      "Epoch 517: Loss = 0.0\n",
      "Epoch 518: Loss = 0.0\n",
      "Epoch 519: Loss = 0.0\n",
      "Epoch 520: Loss = 0.0\n",
      "Epoch 521: Loss = 0.0\n",
      "Epoch 522: Loss = 0.0\n",
      "Epoch 523: Loss = 0.0\n",
      "Epoch 524: Loss = 0.0\n",
      "Epoch 525: Loss = 0.0\n",
      "Epoch 526: Loss = 0.0\n",
      "Epoch 527: Loss = 0.0\n",
      "Epoch 528: Loss = 0.0\n",
      "Epoch 529: Loss = 0.0\n",
      "Epoch 530: Loss = 0.0\n",
      "Epoch 531: Loss = 0.0\n",
      "Epoch 532: Loss = 0.0\n",
      "Epoch 533: Loss = 0.0\n",
      "Epoch 534: Loss = 0.0\n",
      "Epoch 535: Loss = 0.0\n",
      "Epoch 536: Loss = 0.0\n",
      "Epoch 537: Loss = 0.0\n",
      "Epoch 538: Loss = 0.0\n",
      "Epoch 539: Loss = 0.0\n",
      "Epoch 540: Loss = 0.0\n",
      "Epoch 541: Loss = 0.0\n",
      "Epoch 542: Loss = 0.0\n",
      "Epoch 543: Loss = 0.0\n",
      "Epoch 544: Loss = 0.0\n",
      "Epoch 545: Loss = 0.0\n",
      "Epoch 546: Loss = 0.0\n",
      "Epoch 547: Loss = 0.0\n",
      "Epoch 548: Loss = 0.0\n",
      "Epoch 549: Loss = 0.0\n",
      "Epoch 550: Loss = 0.0\n",
      "Epoch 551: Loss = 0.0\n",
      "Epoch 552: Loss = 0.0\n",
      "Epoch 553: Loss = 0.0\n",
      "Epoch 554: Loss = 0.0\n",
      "Epoch 555: Loss = 0.0\n",
      "Epoch 556: Loss = 0.0\n",
      "Epoch 557: Loss = 0.0\n",
      "Epoch 558: Loss = 0.0\n",
      "Epoch 559: Loss = 0.0\n",
      "Epoch 560: Loss = 0.0\n",
      "Epoch 561: Loss = 0.0\n",
      "Epoch 562: Loss = 0.0\n",
      "Epoch 563: Loss = 0.0\n",
      "Epoch 564: Loss = 0.0\n",
      "Epoch 565: Loss = 0.0\n",
      "Epoch 566: Loss = 0.0\n",
      "Epoch 567: Loss = 0.0\n",
      "Epoch 568: Loss = 0.0\n",
      "Epoch 569: Loss = 0.0\n",
      "Epoch 570: Loss = 0.0\n",
      "Epoch 571: Loss = 0.0\n",
      "Epoch 572: Loss = 0.0\n",
      "Epoch 573: Loss = 0.0\n",
      "Epoch 574: Loss = 0.0\n",
      "Epoch 575: Loss = 0.0\n",
      "Epoch 576: Loss = 0.0\n",
      "Epoch 577: Loss = 0.0\n",
      "Epoch 578: Loss = 0.0\n",
      "Epoch 579: Loss = 0.0\n",
      "Epoch 580: Loss = 0.0\n",
      "Epoch 581: Loss = 0.0\n",
      "Epoch 582: Loss = 0.0\n",
      "Epoch 583: Loss = 0.0\n",
      "Epoch 584: Loss = 0.0\n",
      "Epoch 585: Loss = 0.0\n",
      "Epoch 586: Loss = 0.0\n",
      "Epoch 587: Loss = 0.0\n",
      "Epoch 588: Loss = 0.0\n",
      "Epoch 589: Loss = 0.0\n",
      "Epoch 590: Loss = 0.0\n",
      "Epoch 591: Loss = 0.0\n",
      "Epoch 592: Loss = 0.0\n",
      "Epoch 593: Loss = 0.0\n",
      "Epoch 594: Loss = 0.0\n",
      "Epoch 595: Loss = 0.0\n",
      "Epoch 596: Loss = 0.0\n",
      "Epoch 597: Loss = 0.0\n",
      "Epoch 598: Loss = 0.0\n",
      "Epoch 599: Loss = 0.0\n",
      "Epoch 600: Loss = 0.0\n",
      "Epoch 601: Loss = 0.0\n",
      "Epoch 602: Loss = 0.0\n",
      "Epoch 603: Loss = 0.0\n",
      "Epoch 604: Loss = 0.0\n",
      "Epoch 605: Loss = 0.0\n",
      "Epoch 606: Loss = 0.0\n",
      "Epoch 607: Loss = 0.0\n",
      "Epoch 608: Loss = 0.0\n",
      "Epoch 609: Loss = 0.0\n",
      "Epoch 610: Loss = 0.0\n",
      "Epoch 611: Loss = 0.0\n",
      "Epoch 612: Loss = 0.0\n",
      "Epoch 613: Loss = 0.0\n",
      "Epoch 614: Loss = 0.0\n",
      "Epoch 615: Loss = 0.0\n",
      "Epoch 616: Loss = 0.0\n",
      "Epoch 617: Loss = 0.0\n",
      "Epoch 618: Loss = 0.0\n",
      "Epoch 619: Loss = 0.0\n",
      "Epoch 620: Loss = 0.0\n",
      "Epoch 621: Loss = 0.0\n",
      "Epoch 622: Loss = 0.0\n",
      "Epoch 623: Loss = 0.0\n",
      "Epoch 624: Loss = 0.0\n",
      "Epoch 625: Loss = 0.0\n",
      "Epoch 626: Loss = 0.0\n",
      "Epoch 627: Loss = 0.0\n",
      "Epoch 628: Loss = 0.0\n",
      "Epoch 629: Loss = 0.0\n",
      "Epoch 630: Loss = 0.0\n",
      "Epoch 631: Loss = 0.0\n",
      "Epoch 632: Loss = 0.0\n",
      "Epoch 633: Loss = 0.0\n",
      "Epoch 634: Loss = 0.0\n",
      "Epoch 635: Loss = 0.0\n",
      "Epoch 636: Loss = 0.0\n",
      "Epoch 637: Loss = 0.0\n",
      "Epoch 638: Loss = 0.0\n",
      "Epoch 639: Loss = 0.0\n",
      "Epoch 640: Loss = 0.0\n",
      "Epoch 641: Loss = 0.0\n",
      "Epoch 642: Loss = 0.0\n",
      "Epoch 643: Loss = 0.0\n",
      "Epoch 644: Loss = 0.0\n",
      "Epoch 645: Loss = 0.0\n",
      "Epoch 646: Loss = 0.0\n",
      "Epoch 647: Loss = 0.0\n",
      "Epoch 648: Loss = 0.0\n",
      "Epoch 649: Loss = 0.0\n",
      "Epoch 650: Loss = 0.0\n",
      "Epoch 651: Loss = 0.0\n",
      "Epoch 652: Loss = 0.0\n",
      "Epoch 653: Loss = 0.0\n",
      "Epoch 654: Loss = 0.0\n",
      "Epoch 655: Loss = 0.0\n",
      "Epoch 656: Loss = 0.0\n",
      "Epoch 657: Loss = 0.0\n",
      "Epoch 658: Loss = 0.0\n",
      "Epoch 659: Loss = 0.0\n",
      "Epoch 660: Loss = 0.0\n",
      "Epoch 661: Loss = 0.0\n",
      "Epoch 662: Loss = 0.0\n",
      "Epoch 663: Loss = 0.0\n",
      "Epoch 664: Loss = 0.0\n",
      "Epoch 665: Loss = 0.0\n",
      "Epoch 666: Loss = 0.0\n",
      "Epoch 667: Loss = 0.0\n",
      "Epoch 668: Loss = 0.0\n",
      "Epoch 669: Loss = 0.0\n",
      "Epoch 670: Loss = 0.0\n",
      "Epoch 671: Loss = 0.0\n",
      "Epoch 672: Loss = 0.0\n",
      "Epoch 673: Loss = 0.0\n",
      "Epoch 674: Loss = 0.0\n",
      "Epoch 675: Loss = 0.0\n",
      "Epoch 676: Loss = 0.0\n",
      "Epoch 677: Loss = 0.0\n",
      "Epoch 678: Loss = 0.0\n",
      "Epoch 679: Loss = 0.0\n",
      "Epoch 680: Loss = 0.0\n",
      "Epoch 681: Loss = 0.0\n",
      "Epoch 682: Loss = 0.0\n",
      "Epoch 683: Loss = 0.0\n",
      "Epoch 684: Loss = 0.0\n",
      "Epoch 685: Loss = 0.0\n",
      "Epoch 686: Loss = 0.0\n",
      "Epoch 687: Loss = 0.0\n",
      "Epoch 688: Loss = 0.0\n",
      "Epoch 689: Loss = 0.0\n",
      "Epoch 690: Loss = 0.0\n",
      "Epoch 691: Loss = 0.0\n",
      "Epoch 692: Loss = 0.0\n",
      "Epoch 693: Loss = 0.0\n",
      "Epoch 694: Loss = 0.0\n",
      "Epoch 695: Loss = 0.0\n",
      "Epoch 696: Loss = 0.0\n",
      "Epoch 697: Loss = 0.0\n",
      "Epoch 698: Loss = 0.0\n",
      "Epoch 699: Loss = 0.0\n",
      "Epoch 700: Loss = 0.0\n",
      "Epoch 701: Loss = 0.0\n",
      "Epoch 702: Loss = 0.0\n",
      "Epoch 703: Loss = 0.0\n",
      "Epoch 704: Loss = 0.0\n",
      "Epoch 705: Loss = 0.0\n",
      "Epoch 706: Loss = 0.0\n",
      "Epoch 707: Loss = 0.0\n",
      "Epoch 708: Loss = 0.0\n",
      "Epoch 709: Loss = 0.0\n",
      "Epoch 710: Loss = 0.0\n",
      "Epoch 711: Loss = 0.0\n",
      "Epoch 712: Loss = 0.0\n",
      "Epoch 713: Loss = 0.0\n",
      "Epoch 714: Loss = 0.0\n",
      "Epoch 715: Loss = 0.0\n",
      "Epoch 716: Loss = 0.0\n",
      "Epoch 717: Loss = 0.0\n",
      "Epoch 718: Loss = 0.0\n",
      "Epoch 719: Loss = 0.0\n",
      "Epoch 720: Loss = 0.0\n",
      "Epoch 721: Loss = 0.0\n",
      "Epoch 722: Loss = 0.0\n",
      "Epoch 723: Loss = 0.0\n",
      "Epoch 724: Loss = 0.0\n",
      "Epoch 725: Loss = 0.0\n",
      "Epoch 726: Loss = 0.0\n",
      "Epoch 727: Loss = 0.0\n",
      "Epoch 728: Loss = 0.0\n",
      "Epoch 729: Loss = 0.0\n",
      "Epoch 730: Loss = 0.0\n",
      "Epoch 731: Loss = 0.0\n",
      "Epoch 732: Loss = 0.0\n",
      "Epoch 733: Loss = 0.0\n",
      "Epoch 734: Loss = 0.0\n",
      "Epoch 735: Loss = 0.0\n",
      "Epoch 736: Loss = 0.0\n",
      "Epoch 737: Loss = 0.0\n",
      "Epoch 738: Loss = 0.0\n",
      "Epoch 739: Loss = 0.0\n",
      "Epoch 740: Loss = 0.0\n",
      "Epoch 741: Loss = 0.0\n",
      "Epoch 742: Loss = 0.0\n",
      "Epoch 743: Loss = 0.0\n",
      "Epoch 744: Loss = 0.0\n",
      "Epoch 745: Loss = 0.0\n",
      "Epoch 746: Loss = 0.0\n",
      "Epoch 747: Loss = 0.0\n",
      "Epoch 748: Loss = 0.0\n",
      "Epoch 749: Loss = 0.0\n",
      "Epoch 750: Loss = 0.0\n",
      "Epoch 751: Loss = 0.0\n",
      "Epoch 752: Loss = 0.0\n",
      "Epoch 753: Loss = 0.0\n",
      "Epoch 754: Loss = 0.0\n",
      "Epoch 755: Loss = 0.0\n",
      "Epoch 756: Loss = 0.0\n",
      "Epoch 757: Loss = 0.0\n",
      "Epoch 758: Loss = 0.0\n",
      "Epoch 759: Loss = 0.0\n",
      "Epoch 760: Loss = 0.0\n",
      "Epoch 761: Loss = 0.0\n",
      "Epoch 762: Loss = 0.0\n",
      "Epoch 763: Loss = 0.0\n",
      "Epoch 764: Loss = 0.0\n",
      "Epoch 765: Loss = 0.0\n",
      "Epoch 766: Loss = 0.0\n",
      "Epoch 767: Loss = 0.0\n",
      "Epoch 768: Loss = 0.0\n",
      "Epoch 769: Loss = 0.0\n",
      "Epoch 770: Loss = 0.0\n",
      "Epoch 771: Loss = 0.0\n",
      "Epoch 772: Loss = 0.0\n",
      "Epoch 773: Loss = 0.0\n",
      "Epoch 774: Loss = 0.0\n",
      "Epoch 775: Loss = 0.0\n",
      "Epoch 776: Loss = 0.0\n",
      "Epoch 777: Loss = 0.0\n",
      "Epoch 778: Loss = 0.0\n",
      "Epoch 779: Loss = 0.0\n",
      "Epoch 780: Loss = 0.0\n",
      "Epoch 781: Loss = 0.0\n",
      "Epoch 782: Loss = 0.0\n",
      "Epoch 783: Loss = 0.0\n",
      "Epoch 784: Loss = 0.0\n",
      "Epoch 785: Loss = 0.0\n",
      "Epoch 786: Loss = 0.0\n",
      "Epoch 787: Loss = 0.0\n",
      "Epoch 788: Loss = 0.0\n",
      "Epoch 789: Loss = 0.0\n",
      "Epoch 790: Loss = 0.0\n",
      "Epoch 791: Loss = 0.0\n",
      "Epoch 792: Loss = 0.0\n",
      "Epoch 793: Loss = 0.0\n",
      "Epoch 794: Loss = 0.0\n",
      "Epoch 795: Loss = 0.0\n",
      "Epoch 796: Loss = 0.0\n",
      "Epoch 797: Loss = 0.0\n",
      "Epoch 798: Loss = 0.0\n",
      "Epoch 799: Loss = 0.0\n",
      "Epoch 800: Loss = 0.0\n",
      "Epoch 801: Loss = 0.0\n",
      "Epoch 802: Loss = 0.0\n",
      "Epoch 803: Loss = 0.0\n",
      "Epoch 804: Loss = 0.0\n",
      "Epoch 805: Loss = 0.0\n",
      "Epoch 806: Loss = 0.0\n",
      "Epoch 807: Loss = 0.0\n",
      "Epoch 808: Loss = 0.0\n",
      "Epoch 809: Loss = 0.0\n",
      "Epoch 810: Loss = 0.0\n",
      "Epoch 811: Loss = 0.0\n",
      "Epoch 812: Loss = 0.0\n",
      "Epoch 813: Loss = 0.0\n",
      "Epoch 814: Loss = 0.0\n",
      "Epoch 815: Loss = 0.0\n",
      "Epoch 816: Loss = 0.0\n",
      "Epoch 817: Loss = 0.0\n",
      "Epoch 818: Loss = 0.0\n",
      "Epoch 819: Loss = 0.0\n",
      "Epoch 820: Loss = 0.0\n",
      "Epoch 821: Loss = 0.0\n",
      "Epoch 822: Loss = 0.0\n",
      "Epoch 823: Loss = 0.0\n",
      "Epoch 824: Loss = 0.0\n",
      "Epoch 825: Loss = 0.0\n",
      "Epoch 826: Loss = 0.0\n",
      "Epoch 827: Loss = 0.0\n",
      "Epoch 828: Loss = 0.0\n",
      "Epoch 829: Loss = 0.0\n",
      "Epoch 830: Loss = 0.0\n",
      "Epoch 831: Loss = 0.0\n",
      "Epoch 832: Loss = 0.0\n",
      "Epoch 833: Loss = 0.0\n",
      "Epoch 834: Loss = 0.0\n",
      "Epoch 835: Loss = 0.0\n",
      "Epoch 836: Loss = 0.0\n",
      "Epoch 837: Loss = 0.0\n",
      "Epoch 838: Loss = 0.0\n",
      "Epoch 839: Loss = 0.0\n",
      "Epoch 840: Loss = 0.0\n",
      "Epoch 841: Loss = 0.0\n",
      "Epoch 842: Loss = 0.0\n",
      "Epoch 843: Loss = 0.0\n",
      "Epoch 844: Loss = 0.0\n",
      "Epoch 845: Loss = 0.0\n",
      "Epoch 846: Loss = 0.0\n",
      "Epoch 847: Loss = 0.0\n",
      "Epoch 848: Loss = 0.0\n",
      "Epoch 849: Loss = 0.0\n",
      "Epoch 850: Loss = 0.0\n",
      "Epoch 851: Loss = 0.0\n",
      "Epoch 852: Loss = 0.0\n",
      "Epoch 853: Loss = 0.0\n",
      "Epoch 854: Loss = 0.0\n",
      "Epoch 855: Loss = 0.0\n",
      "Epoch 856: Loss = 0.0\n",
      "Epoch 857: Loss = 0.0\n",
      "Epoch 858: Loss = 0.0\n",
      "Epoch 859: Loss = 0.0\n",
      "Epoch 860: Loss = 0.0\n",
      "Epoch 861: Loss = 0.0\n",
      "Epoch 862: Loss = 0.0\n",
      "Epoch 863: Loss = 0.0\n",
      "Epoch 864: Loss = 0.0\n",
      "Epoch 865: Loss = 0.0\n",
      "Epoch 866: Loss = 0.0\n",
      "Epoch 867: Loss = 0.0\n",
      "Epoch 868: Loss = 0.0\n",
      "Epoch 869: Loss = 0.0\n",
      "Epoch 870: Loss = 0.0\n",
      "Epoch 871: Loss = 0.0\n",
      "Epoch 872: Loss = 0.0\n",
      "Epoch 873: Loss = 0.0\n",
      "Epoch 874: Loss = 0.0\n",
      "Epoch 875: Loss = 0.0\n",
      "Epoch 876: Loss = 0.0\n",
      "Epoch 877: Loss = 0.0\n",
      "Epoch 878: Loss = 0.0\n",
      "Epoch 879: Loss = 0.0\n",
      "Epoch 880: Loss = 0.0\n",
      "Epoch 881: Loss = 0.0\n",
      "Epoch 882: Loss = 0.0\n",
      "Epoch 883: Loss = 0.0\n",
      "Epoch 884: Loss = 0.0\n",
      "Epoch 885: Loss = 0.0\n",
      "Epoch 886: Loss = 0.0\n",
      "Epoch 887: Loss = 0.0\n",
      "Epoch 888: Loss = 0.0\n",
      "Epoch 889: Loss = 0.0\n",
      "Epoch 890: Loss = 0.0\n",
      "Epoch 891: Loss = 0.0\n",
      "Epoch 892: Loss = 0.0\n",
      "Epoch 893: Loss = 0.0\n",
      "Epoch 894: Loss = 0.0\n",
      "Epoch 895: Loss = 0.0\n",
      "Epoch 896: Loss = 0.0\n",
      "Epoch 897: Loss = 0.0\n",
      "Epoch 898: Loss = 0.0\n",
      "Epoch 899: Loss = 0.0\n",
      "Epoch 900: Loss = 0.0\n",
      "Epoch 901: Loss = 0.0\n",
      "Epoch 902: Loss = 0.0\n",
      "Epoch 903: Loss = 0.0\n",
      "Epoch 904: Loss = 0.0\n",
      "Epoch 905: Loss = 0.0\n",
      "Epoch 906: Loss = 0.0\n",
      "Epoch 907: Loss = 0.0\n",
      "Epoch 908: Loss = 0.0\n",
      "Epoch 909: Loss = 0.0\n",
      "Epoch 910: Loss = 0.0\n",
      "Epoch 911: Loss = 0.0\n",
      "Epoch 912: Loss = 0.0\n",
      "Epoch 913: Loss = 0.0\n",
      "Epoch 914: Loss = 0.0\n",
      "Epoch 915: Loss = 0.0\n",
      "Epoch 916: Loss = 0.0\n",
      "Epoch 917: Loss = 0.0\n",
      "Epoch 918: Loss = 0.0\n",
      "Epoch 919: Loss = 0.0\n",
      "Epoch 920: Loss = 0.0\n",
      "Epoch 921: Loss = 0.0\n",
      "Epoch 922: Loss = 0.0\n",
      "Epoch 923: Loss = 0.0\n",
      "Epoch 924: Loss = 0.0\n",
      "Epoch 925: Loss = 0.0\n",
      "Epoch 926: Loss = 0.0\n",
      "Epoch 927: Loss = 0.0\n",
      "Epoch 928: Loss = 0.0\n",
      "Epoch 929: Loss = 0.0\n",
      "Epoch 930: Loss = 0.0\n",
      "Epoch 931: Loss = 0.0\n",
      "Epoch 932: Loss = 0.0\n",
      "Epoch 933: Loss = 0.0\n",
      "Epoch 934: Loss = 0.0\n",
      "Epoch 935: Loss = 0.0\n",
      "Epoch 936: Loss = 0.0\n",
      "Epoch 937: Loss = 0.0\n",
      "Epoch 938: Loss = 0.0\n",
      "Epoch 939: Loss = 0.0\n",
      "Epoch 940: Loss = 0.0\n",
      "Epoch 941: Loss = 0.0\n",
      "Epoch 942: Loss = 0.0\n",
      "Epoch 943: Loss = 0.0\n",
      "Epoch 944: Loss = 0.0\n",
      "Epoch 945: Loss = 0.0\n",
      "Epoch 946: Loss = 0.0\n",
      "Epoch 947: Loss = 0.0\n",
      "Epoch 948: Loss = 0.0\n",
      "Epoch 949: Loss = 0.0\n",
      "Epoch 950: Loss = 0.0\n",
      "Epoch 951: Loss = 0.0\n",
      "Epoch 952: Loss = 0.0\n",
      "Epoch 953: Loss = 0.0\n",
      "Epoch 954: Loss = 0.0\n",
      "Epoch 955: Loss = 0.0\n",
      "Epoch 956: Loss = 0.0\n",
      "Epoch 957: Loss = 0.0\n",
      "Epoch 958: Loss = 0.0\n",
      "Epoch 959: Loss = 0.0\n",
      "Epoch 960: Loss = 0.0\n",
      "Epoch 961: Loss = 0.0\n",
      "Epoch 962: Loss = 0.0\n",
      "Epoch 963: Loss = 0.0\n",
      "Epoch 964: Loss = 0.0\n",
      "Epoch 965: Loss = 0.0\n",
      "Epoch 966: Loss = 0.0\n",
      "Epoch 967: Loss = 0.0\n",
      "Epoch 968: Loss = 0.0\n",
      "Epoch 969: Loss = 0.0\n",
      "Epoch 970: Loss = 0.0\n",
      "Epoch 971: Loss = 0.0\n",
      "Epoch 972: Loss = 0.0\n",
      "Epoch 973: Loss = 0.0\n",
      "Epoch 974: Loss = 0.0\n",
      "Epoch 975: Loss = 0.0\n",
      "Epoch 976: Loss = 0.0\n",
      "Epoch 977: Loss = 0.0\n",
      "Epoch 978: Loss = 0.0\n",
      "Epoch 979: Loss = 0.0\n",
      "Epoch 980: Loss = 0.0\n",
      "Epoch 981: Loss = 0.0\n",
      "Epoch 982: Loss = 0.0\n",
      "Epoch 983: Loss = 0.0\n",
      "Epoch 984: Loss = 0.0\n",
      "Epoch 985: Loss = 0.0\n",
      "Epoch 986: Loss = 0.0\n",
      "Epoch 987: Loss = 0.0\n",
      "Epoch 988: Loss = 0.0\n",
      "Epoch 989: Loss = 0.0\n",
      "Epoch 990: Loss = 0.0\n",
      "Epoch 991: Loss = 0.0\n",
      "Epoch 992: Loss = 0.0\n",
      "Epoch 993: Loss = 0.0\n",
      "Epoch 994: Loss = 0.0\n",
      "Epoch 995: Loss = 0.0\n",
      "Epoch 996: Loss = 0.0\n",
      "Epoch 997: Loss = 0.0\n",
      "Epoch 998: Loss = 0.0\n",
      "Epoch 999: Loss = 0.0\n",
      "Epoch 1000: Loss = 0.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomGATModel(in_channels=4, hidden_channels=8, out_channels=1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Assuming batch_1 and batch_2 are prepared and available\n",
    "batches = [batch_1, batch_2]\n",
    "targets = targets.to(device)\n",
    "\n",
    "for epoch in range(1000):  # Example: 10 epochs\n",
    "    total_loss = 0\n",
    "    for batch_graphs, target in zip(batches, targets):\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(batch_graphs).squeeze(-1)  # Adjust dimensions as necessary\n",
    "        loss = criterion(prediction.squeeze(-1), target.unsqueeze(0))  # Ensure target is correctly shaped\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Loss = {total_loss / len(batches)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance, Transformers for modeling batch graph attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# Example synthetic graphs with variable sizes\n",
    "batch_1 = [Data(x=torch.randn(5, 4), edge_index=torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]], dtype=torch.long))]\n",
    "batch_2 = [Data(x=torch.randn(3, 4), edge_index=torch.tensor([[0, 1], [1, 2]], dtype=torch.long)),\n",
    "           Data(x=torch.randn(4, 4), edge_index=torch.tensor([[0, 1, 3], [1, 2, 0]], dtype=torch.long))]\n",
    "\n",
    "# Example target values for each batch\n",
    "targets = torch.tensor([1.5, 2.5], dtype=torch.float)  # Assume one target per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, TransformerConv\n",
    "\n",
    "class TransformerGATModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_heads=2):\n",
    "        super(TransformerGATModel, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels, heads=1, concat=True)\n",
    "        \n",
    "        # Transformer layer for aggregating graph embeddings\n",
    "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_channels, nhead=num_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(transformer_encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.regressor = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, batched_graphs):\n",
    "        batched_graphs_representations = []\n",
    "\n",
    "        for graph in batched_graphs:\n",
    "            x, edge_index = graph.x, graph.edge_index\n",
    "            x = F.relu(self.conv1(x, edge_index))\n",
    "            x = self.conv2(x, edge_index)\n",
    "            # Apply global_mean_pool to obtain a 2D tensor for each graph: (1, hidden_channels)\n",
    "            graph_rep = global_mean_pool(x, graph.batch).unsqueeze(0)  # Ensuring it's (1, hidden_channels)\n",
    "            batched_graphs_representations.append(graph_rep)\n",
    "\n",
    "        # Directly concatenating representations; they're already in the correct form: (1, hidden_channels)\n",
    "        graphs_embeddings = torch.cat(batched_graphs_representations, dim=1)  # Corrected concatenation along the 'sequence length' dimension\n",
    "\n",
    "        print(f\"Graph Embeddings Shape after concatenation: {graphs_embeddings.shape}\")\n",
    "\n",
    "        # The tensor should already be in the desired shape (1, num_graphs, hidden_channels), no need for unsqueeze(0)\n",
    "        transformed_embeddings = self.transformer_encoder(graphs_embeddings).squeeze(0)\n",
    "\n",
    "        # Assuming we take the first graph's embedding for the regression task\n",
    "        aggregated_representation = transformed_embeddings[0]\n",
    "\n",
    "        return self.regressor(aggregated_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Embeddings Shape after concatenation: torch.Size([1, 1, 8])\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 2, 8])\n",
      "Epoch 1: Loss = 1.8528321981430054\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 1, 8])\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 2, 8])\n",
      "Epoch 2: Loss = 1.109409049153328\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 1, 8])\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 2, 8])\n",
      "Epoch 3: Loss = 0.5549232298508286\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 1, 8])\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 2, 8])\n",
      "Epoch 4: Loss = 0.34817803045734763\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 1, 8])\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 2, 8])\n",
      "Epoch 5: Loss = 0.27030055969953537\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 1, 8])\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 2, 8])\n",
      "Epoch 6: Loss = 0.23133083432912827\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 1, 8])\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 2, 8])\n",
      "Epoch 7: Loss = 0.21969260275363922\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 1, 8])\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 2, 8])\n",
      "Epoch 8: Loss = 0.2316889986395836\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 1, 8])\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 2, 8])\n",
      "Epoch 9: Loss = 0.23850952088832855\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 1, 8])\n",
      "Graph Embeddings Shape after concatenation: torch.Size([1, 2, 8])\n",
      "Epoch 10: Loss = 0.2243334874510765\n"
     ]
    }
   ],
   "source": [
    "model = TransformerGATModel(in_channels=4, hidden_channels=8, out_channels=1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Assuming batch_1 and batch_2 are prepared and available\n",
    "batches = [batch_1, batch_2]\n",
    "targets = targets.to(device)\n",
    "\n",
    "for epoch in range(10):  # Example: 10 epochs\n",
    "    total_loss = 0\n",
    "    for batch_graphs, target in zip(batches, targets):\n",
    "        batch_graphs = [data.to(device) for data in batch_graphs]\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(batch_graphs)  # Transformer output ignored during training\n",
    "        # prediction = prediction.squeeze(-1)\n",
    "        loss = criterion(prediction, target.unsqueeze(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Loss = {total_loss / len(batches)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum (interpretability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1351,  1.1669, -0.9262, -0.8257, -0.3861,  0.3903,  0.5441, -1.0211,\n",
       "          0.5573,  0.3320,  0.6110,  0.5079, -0.2697,  1.4705,  0.9492, -0.0376],\n",
       "        [-0.3726, -1.0210,  0.9684,  1.5519, -1.6162,  0.7513, -0.7545,  0.5429,\n",
       "          0.6375,  0.2802,  0.5645,  0.1275, -1.9762, -1.8341,  1.5570, -1.8068],\n",
       "        [ 2.9383, -2.2058,  1.4129, -0.7265, -0.4072, -1.9488,  1.2779,  0.2046,\n",
       "         -1.7946,  0.0854, -0.2489, -0.0537,  0.8847,  1.4898, -1.2300, -0.7111],\n",
       "        [-0.3702,  0.7118, -0.4895, -0.9216,  0.5241,  0.4836, -1.1000,  0.8136,\n",
       "         -1.2032, -1.2309,  0.5547, -2.5203,  1.4530,  1.2069,  0.3703, -0.3149],\n",
       "        [-0.7967,  1.4777, -1.2517, -1.9297,  1.0242,  1.7581,  1.0581, -1.9194,\n",
       "          0.9537, -0.9572, -1.3933,  0.9033, -0.3585, -1.3424,  2.3679, -0.1724]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding(torch.randint(0, 10, (5,1))[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0091],\n",
       "        [-1.0722],\n",
       "        [-1.6071],\n",
       "        [ 0.6237],\n",
       "        [-0.3591]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding (doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 3.0943110585212708\n",
      "Epoch 2: Loss = 2.388317734003067\n",
      "Epoch 3: Loss = 1.740965947508812\n",
      "Epoch 4: Loss = 1.1382575891911983\n",
      "Epoch 5: Loss = 0.7296831235289574\n",
      "Epoch 6: Loss = 0.5646854788064957\n",
      "Epoch 7: Loss = 0.4473808705806732\n",
      "Epoch 8: Loss = 0.3433838002383709\n",
      "Epoch 9: Loss = 0.2571139745414257\n",
      "Epoch 10: Loss = 0.14878914155997336\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, TransformerConv\n",
    "\n",
    "# Example synthetic graphs with variable sizes and categorical features (as indices)\n",
    "num_node_features = 10  # Assuming 10 different categories for nodes\n",
    "embedding_dim = 16  # Dimensionality of the embedding space\n",
    "batch_1 = [Data(x=torch.randint(0, num_node_features, (5,1)), edge_index=torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]], dtype=torch.long))]\n",
    "batch_2 = [Data(x=torch.randint(0, num_node_features, (3,1)), edge_index=torch.tensor([[0, 1], [1, 2]], dtype=torch.long)),\n",
    "           Data(x=torch.randint(0, num_node_features, (4,1)), edge_index=torch.tensor([[0, 1, 3], [1, 2, 0]], dtype=torch.long))]\n",
    "\n",
    "# Example target values for each batch\n",
    "targets = torch.tensor([1.5, 2.5], dtype=torch.float)  # Assume one target per batch\n",
    "\n",
    "class TransformerGATModel(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_channels, out_channels, num_heads=2):\n",
    "        super(TransformerGATModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.conv1 = GATConv(embedding_dim, hidden_channels, heads=num_heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels, heads=1, concat=True)\n",
    "        \n",
    "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_channels, nhead=num_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(transformer_encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.attention_fc = torch.nn.Linear(hidden_channels, 1)\n",
    "        self.regressor = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.embedding(x[:, 0].long())  # Embedding lookup\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)  # Now x is (num_graphs, hidden_channels)\n",
    "        \n",
    "        attention_scores = self.attention_fc(x).squeeze(-1)  # Shape: (num_graphs,)\n",
    "        attention_weights = F.softmax(attention_scores, dim=0)  # Shape: (num_graphs,)\n",
    "        \n",
    "        x = torch.sum(x * attention_weights.unsqueeze(-1), dim=0)  # Shape: (hidden_channels,)\n",
    "\n",
    "        return self.regressor(x)\n",
    "\n",
    "model = TransformerGATModel(num_embeddings=num_node_features, embedding_dim=embedding_dim, hidden_channels=8, out_channels=1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "batches = [batch_1, batch_2]\n",
    "targets = targets\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):  # Example: 10 epochs\n",
    "    total_loss = 0\n",
    "    for batch_graphs, target in zip(batches, targets):\n",
    "        batched_data = Batch.from_data_list(batch_graphs)\n",
    "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(x, edge_index, batch).squeeze()\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Loss = {total_loss / len(batches)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot (works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 3.978468418121338\n",
      "Epoch 2: Loss = 3.380600333213806\n",
      "Epoch 3: Loss = 2.767776906490326\n",
      "Epoch 4: Loss = 2.1250728368759155\n",
      "Epoch 5: Loss = 1.4657915830612183\n",
      "Epoch 6: Loss = 0.8563261106610298\n",
      "Epoch 7: Loss = 0.379573218524456\n",
      "Epoch 8: Loss = 0.1423940286040306\n",
      "Epoch 9: Loss = 0.17340817535296082\n",
      "Epoch 10: Loss = 0.32862586341798306\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, TransformerConv\n",
    "\n",
    "# Example synthetic graphs with variable sizes and categorical features (as indices)\n",
    "num_node_features = 10  # Assuming 10 different categories for nodes\n",
    "embedding_dim = 16  # Dimensionality of the embedding space\n",
    "batch_1 = [Data(x=F.one_hot(torch.randint(0, num_node_features, (5,)), num_classes=num_node_features).float(), edge_index=torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]], dtype=torch.long))]\n",
    "batch_2 = [\n",
    "    Data(x=F.one_hot(torch.randint(0, num_node_features, (3,)), num_classes=num_node_features).float(), edge_index=torch.tensor([[0, 1], [1, 2]], dtype=torch.long)),\n",
    "    Data(x=F.one_hot(torch.randint(0, num_node_features, (4,)), num_classes=num_node_features).float(), edge_index=torch.tensor([[0, 1, 3], [1, 2, 0]], dtype=torch.long))\n",
    "]\n",
    "\n",
    "# Example target values for each batch\n",
    "targets = torch.tensor([1.5, 2.5], dtype=torch.float)  # Assume one target per batch\n",
    "\n",
    "class TransformerGATModel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, out_channels, num_heads=2):\n",
    "        super(TransformerGATModel, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, hidden_channels, heads=num_heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels, heads=1, concat=True)\n",
    "        \n",
    "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_channels, nhead=num_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(transformer_encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.attention_fc = torch.nn.Linear(hidden_channels, 1)\n",
    "        self.regressor = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # No embedding lookup needed, x is already one-hot encoded\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)  # Now x is (num_graphs, hidden_channels)\n",
    "        \n",
    "        attention_scores = self.attention_fc(x).squeeze(-1)  # Shape: (num_graphs,)\n",
    "        attention_weights = F.softmax(attention_scores, dim=0)  # Shape: (num_graphs,)\n",
    "        \n",
    "        x = torch.sum(x * attention_weights.unsqueeze(-1), dim=0)  # Shape: (hidden_channels,)\n",
    "\n",
    "        return self.regressor(x)\n",
    "\n",
    "model = TransformerGATModel(num_features=num_node_features, hidden_channels=8, out_channels=1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "batches = [batch_1, batch_2]\n",
    "targets = targets\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):  # Example: 10 epochs\n",
    "    total_loss = 0\n",
    "    for batch_graphs, target in zip(batches, targets):\n",
    "        batched_data = Batch.from_data_list(batch_graphs)\n",
    "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(x, edge_index, batch).squeeze()\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Loss = {total_loss / len(batches)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split embedding and GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "num_node_features = 10\n",
    "\n",
    "# Example synthetic graphs with categorical features as indices\n",
    "batch_1 = [Data(x=torch.randint(0, num_node_features, (5,1)), edge_index=torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]], dtype=torch.long))]\n",
    "batch_2 = [Data(x=torch.randint(0, num_node_features, (3,1)), edge_index=torch.tensor([[0, 1], [1, 2]], dtype=torch.long)),\n",
    "           Data(x=torch.randint(0, num_node_features, (4,1)), edge_index=torch.tensor([[0, 1, 3], [1, 2, 0]], dtype=torch.long))]\n",
    "\n",
    "# Example target values for each batch\n",
    "targets = torch.tensor([1.5, 2.5], dtype=torch.float)  # Assume one target per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super(NodeFeatureEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Assuming x is of shape (num_nodes, 1) where each entry is the category index\n",
    "        return self.embedding(x.squeeze())  # Embedding lookup and squeeze to drop extra dimension\n",
    "\n",
    "class TransformerGATModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_channels, out_channels, num_heads=2):\n",
    "        super(TransformerGATModel, self).__init__()\n",
    "        self.conv1 = GATConv(embedding_dim, hidden_channels, heads=num_heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels, heads=1, concat=True)\n",
    "        \n",
    "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_channels, nhead=num_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(transformer_encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.attention_fc = torch.nn.Linear(hidden_channels, 1)\n",
    "        self.regressor = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        attention_scores = self.attention_fc(x).squeeze(-1)\n",
    "        attention_weights = F.softmax(attention_scores, dim=0)\n",
    "        \n",
    "        x = torch.sum(x * attention_weights.unsqueeze(-1), dim=0)\n",
    "\n",
    "        return self.regressor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Epoch 1: Loss = 0.0\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16 \n",
    "\n",
    "embedding_module = NodeFeatureEmbedding(num_embeddings=num_node_features, embedding_dim=embedding_dim)\n",
    "model = TransformerGATModel(embedding_dim=embedding_dim, hidden_channels=8, out_channels=1)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(list(embedding_module.parameters()) + list(model.parameters()), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "batches = [batch_1, batch_2]\n",
    "targets = targets\n",
    "\n",
    "model.train()\n",
    "embedding_module.train()\n",
    "for epoch in range(1):  # For example, 10 epochs\n",
    "    total_loss = 0\n",
    "    for batch_graphs, target in zip(batches, targets):\n",
    "        batched_data = Batch.from_data_list(batch_graphs)\n",
    "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Embedding step\n",
    "        embedded_x = embedding_module(x)\n",
    "        \n",
    "        # Model prediction\n",
    "        prediction = model(embedded_x, edge_index, batch).squeeze()\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Loss = {total_loss / len(batches)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import CaptumExplainer, Explainer, AttentionExplainer, DummyExplainer, GNNExplainer, GraphMaskExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(),\n",
    "    explanation_type='model',\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    ),\n",
    "    node_mask_type='object',\n",
    "    edge_mask_type='object',\n",
    "    # threshold_config=dict(\n",
    "    #     threshold_type='topk',\n",
    "    #     value=200,\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2318, -0.7330,  0.0937, -0.2265, -1.4654,  1.8962, -1.4301, -0.2911,\n",
       "           1.2544, -1.0393, -0.8726, -0.8512,  0.3378,  0.2421, -1.2632, -0.9029],\n",
       "         [-0.5159,  0.7221,  0.2068,  0.8916, -1.5426,  0.3701,  0.7634, -2.2375,\n",
       "          -0.8007, -0.4983,  1.5802, -1.5427, -0.9859, -1.6191, -0.9459,  0.9179],\n",
       "         [-0.5159,  0.7221,  0.2068,  0.8916, -1.5426,  0.3701,  0.7634, -2.2375,\n",
       "          -0.8007, -0.4983,  1.5802, -1.5427, -0.9859, -1.6191, -0.9459,  0.9179],\n",
       "         [-0.5159,  0.7221,  0.2068,  0.8916, -1.5426,  0.3701,  0.7634, -2.2375,\n",
       "          -0.8007, -0.4983,  1.5802, -1.5427, -0.9859, -1.6191, -0.9459,  0.9179],\n",
       "         [-0.8762, -2.2037, -0.1223,  0.5847,  0.2672, -0.1254,  0.5732,  1.1065,\n",
       "           0.1983, -0.6314,  0.4182,  0.3535, -1.2620, -0.0181,  0.6575, -0.7783],\n",
       "         [-0.7811,  0.0647,  1.6319, -0.9613,  0.2375,  0.0637,  0.8754, -1.5875,\n",
       "           0.0560,  0.5753, -0.1972, -0.3851, -0.3808,  0.9382,  0.3022,  0.4016],\n",
       "         [-0.7811,  0.0647,  1.6319, -0.9613,  0.2375,  0.0637,  0.8754, -1.5875,\n",
       "           0.0560,  0.5753, -0.1972, -0.3851, -0.3808,  0.9382,  0.3022,  0.4016]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " DataBatch(x=[7, 1], edge_index=[2, 5], batch=[7], ptr=[3]))"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_module(batched_data.x), batched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Explanation(node_mask=[7, 1], edge_mask=[5], prediction=[1], target=[1], x=[7, 16], edge_index=[2, 5], batch=[7])"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "embedding_module.eval()\n",
    "batched_data = Batch.from_data_list(batch_2).to(device)\n",
    "embedded_batched_data = embedding_module(batched_data.x).detach()\n",
    "explanation = explainer(embedded_batched_data, batched_data.edge_index, batch=batch)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# Example synthetic graphs with variable sizes\n",
    "batch_1 = [Data(x=torch.randn(5, 1), edge_index=torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]], dtype=torch.long))]\n",
    "batch_2 = [Data(x=torch.randn(3, 1), edge_index=torch.tensor([[0, 1], [1, 2]], dtype=torch.long)),\n",
    "           Data(x=torch.randn(4, 1), edge_index=torch.tensor([[0, 1, 3], [1, 2, 0]], dtype=torch.long))]\n",
    "\n",
    "# Example target values for each batch\n",
    "targets = torch.tensor([1.5, 2.5], dtype=torch.float)  # Assume one target per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch: list[list[Data]]) -> tuple[Batch, torch.Tensor]:\n",
    "    batched_graphs, targets = [], []\n",
    "    for graph in batch:\n",
    "        batched_graph = Batch.from_data_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, TransformerConv\n",
    "\n",
    "class TransformerGATModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_heads=2):\n",
    "        super(TransformerGATModel, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels, heads=1, concat=True)\n",
    "        \n",
    "        # Transformer layer for aggregating graph embeddings\n",
    "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_channels, nhead=num_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(transformer_encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.attention_fc = torch.nn.Linear(hidden_channels, 1)\n",
    "        self.regressor = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)  # Now x is (num_graphs, hidden_channels)\n",
    "\n",
    "        # Compute attention scores and normalize them\n",
    "        attention_scores = self.attention_fc(x).squeeze(-1)  # Shape: (num_graphs,)\n",
    "        attention_weights = F.softmax(attention_scores, dim=0)  # Shape: (num_graphs,)\n",
    "        \n",
    "        # Weighted aggregation of graph embeddings\n",
    "        x = torch.sum(x * attention_weights.unsqueeze(-1), dim=0)  # Shape: (hidden_channels,)\n",
    "\n",
    "        # Optional: Pass through transformer for further processing\n",
    "        # x = x.unsqueeze(0)  # Add batch dimension\n",
    "        # x = self.transformer_encoder(x)\n",
    "        # x = x.squeeze(0)  # Remove batch dimension\n",
    "\n",
    "        return self.regressor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 4.371841907501221\n",
      "Epoch 2: Loss = 3.530035376548767\n",
      "Epoch 3: Loss = 2.757626533508301\n",
      "Epoch 4: Loss = 2.033356010913849\n",
      "Epoch 5: Loss = 1.3543277084827423\n",
      "Epoch 6: Loss = 0.7552263513207436\n",
      "Epoch 7: Loss = 0.3093621153384447\n",
      "Epoch 8: Loss = 0.10194680467247963\n",
      "Epoch 9: Loss = 0.15472016524290666\n",
      "Epoch 10: Loss = 0.33475046418607235\n",
      "Epoch 11: Loss = 0.43409615755081177\n",
      "Epoch 12: Loss = 0.3825946431607008\n",
      "Epoch 13: Loss = 0.2551683522760868\n",
      "Epoch 14: Loss = 0.14377659768797457\n",
      "Epoch 15: Loss = 0.08711149916052818\n",
      "Epoch 16: Loss = 0.07504083774983883\n",
      "Epoch 17: Loss = 0.08002956444397569\n",
      "Epoch 18: Loss = 0.07950342446565628\n",
      "Epoch 19: Loss = 0.06498551060758473\n",
      "Epoch 20: Loss = 0.03992889776418451\n",
      "Epoch 21: Loss = 0.015051940880312031\n",
      "Epoch 22: Loss = 0.0015987755032256246\n",
      "Epoch 23: Loss = 0.0034611260052770376\n",
      "Epoch 24: Loss = 0.01312545221298933\n",
      "Epoch 25: Loss = 0.01812074752524495\n",
      "Epoch 26: Loss = 0.013587004039436579\n",
      "Epoch 27: Loss = 0.005173133919015527\n",
      "Epoch 28: Loss = 0.0005030700194765814\n",
      "Epoch 29: Loss = 0.0014853996690362692\n",
      "Epoch 30: Loss = 0.0047132514882832766\n",
      "Epoch 31: Loss = 0.006290337769314647\n",
      "Epoch 32: Loss = 0.005087139084935188\n",
      "Epoch 33: Loss = 0.002666572720045224\n",
      "Epoch 34: Loss = 0.00114892019337276\n",
      "Epoch 35: Loss = 0.0012066653871443123\n",
      "Epoch 36: Loss = 0.0018363655835855752\n",
      "Epoch 37: Loss = 0.0018003724337631866\n",
      "Epoch 38: Loss = 0.001001624279524549\n",
      "Epoch 39: Loss = 0.00021304661231624777\n",
      "Epoch 40: Loss = 1.892922773549799e-05\n",
      "Epoch 41: Loss = 0.0002894177632697392\n",
      "Epoch 42: Loss = 0.0005283520658849739\n",
      "Epoch 43: Loss = 0.00045491561832022853\n",
      "Epoch 44: Loss = 0.00019360577425686643\n",
      "Epoch 45: Loss = 2.4083707330646575e-05\n",
      "Epoch 46: Loss = 5.762337241321802e-05\n",
      "Epoch 47: Loss = 0.00017305606888839975\n",
      "Epoch 48: Loss = 0.0002082606515614316\n",
      "Epoch 49: Loss = 0.00013910888810642064\n",
      "Epoch 50: Loss = 5.833372597408015e-05\n",
      "Epoch 51: Loss = 3.74693117919378e-05\n",
      "Epoch 52: Loss = 5.826920289564441e-05\n",
      "Epoch 53: Loss = 6.459603858388618e-05\n",
      "Epoch 54: Loss = 3.814243245869875e-05\n",
      "Epoch 55: Loss = 7.44579028832959e-06\n",
      "Epoch 56: Loss = 9.919773447109037e-07\n",
      "Epoch 57: Loss = 1.3778257880403544e-05\n",
      "Epoch 58: Loss = 2.1916064838478633e-05\n",
      "Epoch 59: Loss = 1.5099948996066814e-05\n",
      "Epoch 60: Loss = 4.0192721897369665e-06\n",
      "Epoch 61: Loss = 1.259906866835081e-06\n",
      "Epoch 62: Loss = 6.018231715643196e-06\n",
      "Epoch 63: Loss = 9.287772627430968e-06\n",
      "Epoch 64: Loss = 6.935122200957267e-06\n",
      "Epoch 65: Loss = 2.8090617263387685e-06\n",
      "Epoch 66: Loss = 1.4485066230918164e-06\n",
      "Epoch 67: Loss = 2.456518160443011e-06\n",
      "Epoch 68: Loss = 2.762654169430334e-06\n",
      "Epoch 69: Loss = 1.4298166775006393e-06\n",
      "Epoch 70: Loss = 1.5920026186222458e-07\n",
      "Epoch 71: Loss = 2.4098415707385357e-07\n",
      "Epoch 72: Loss = 9.546791943648714e-07\n",
      "Epoch 73: Loss = 1.052229237075153e-06\n",
      "Epoch 74: Loss = 4.826530428658771e-07\n",
      "Epoch 75: Loss = 8.018855623959098e-08\n",
      "Epoch 76: Loss = 2.1381322312663542e-07\n",
      "Epoch 77: Loss = 4.644669218123454e-07\n",
      "Epoch 78: Loss = 4.1304775777462055e-07\n",
      "Epoch 79: Loss = 1.7293211840296863e-07\n",
      "Epoch 80: Loss = 6.024333742971066e-08\n",
      "Epoch 81: Loss = 1.1284274137324246e-07\n",
      "Epoch 82: Loss = 1.439753987142467e-07\n",
      "Epoch 83: Loss = 7.654227829334559e-08\n",
      "Epoch 84: Loss = 1.0699295671656728e-08\n",
      "Epoch 85: Loss = 2.4006006071886077e-08\n",
      "Epoch 86: Loss = 6.381899453344886e-08\n",
      "Epoch 87: Loss = 5.784187351309811e-08\n",
      "Epoch 88: Loss = 2.005310761887813e-08\n",
      "Epoch 89: Loss = 5.078938158931123e-09\n",
      "Epoch 90: Loss = 1.9578187959723437e-08\n",
      "Epoch 91: Loss = 2.8485892755725217e-08\n",
      "Epoch 92: Loss = 1.7103786831285106e-08\n",
      "Epoch 93: Loss = 3.98108568333555e-09\n",
      "Epoch 94: Loss = 3.855916475004051e-09\n",
      "Epoch 95: Loss = 8.508891369274352e-09\n",
      "Epoch 96: Loss = 6.7779239998344565e-09\n",
      "Epoch 97: Loss = 1.9366623860150867e-09\n",
      "Epoch 98: Loss = 1.4034711171007075e-09\n",
      "Epoch 99: Loss = 4.026823319236428e-09\n",
      "Epoch 100: Loss = 4.213518423057394e-09\n",
      "Epoch 101: Loss = 1.6974865957308793e-09\n",
      "Epoch 102: Loss = 3.035793838535028e-10\n",
      "Epoch 103: Loss = 1.155179063516698e-09\n",
      "Epoch 104: Loss = 1.8218315744888969e-09\n",
      "Epoch 105: Loss = 1.0344720635657723e-09\n",
      "Epoch 106: Loss = 1.5285195331671275e-10\n",
      "Epoch 107: Loss = 2.376623342570383e-10\n",
      "Epoch 108: Loss = 5.970832717139274e-10\n",
      "Epoch 109: Loss = 4.3778669578387053e-10\n",
      "Epoch 110: Loss = 1.4410517223950592e-10\n",
      "Epoch 111: Loss = 1.7246293282369152e-10\n",
      "Epoch 112: Loss = 3.234390533179976e-10\n",
      "Epoch 113: Loss = 2.5131186021098983e-10\n",
      "Epoch 114: Loss = 6.59170495964645e-11\n",
      "Epoch 115: Loss = 2.652456032592454e-11\n",
      "Epoch 116: Loss = 1.0889067425523535e-10\n",
      "Epoch 117: Loss = 1.0825829122040886e-10\n",
      "Epoch 118: Loss = 3.2095215374283725e-11\n",
      "Epoch 119: Loss = 1.8829382497642655e-12\n",
      "Epoch 120: Loss = 3.4788172342814505e-11\n",
      "Epoch 121: Loss = 4.948219611833338e-11\n",
      "Epoch 122: Loss = 2.33981722885801e-11\n",
      "Epoch 123: Loss = 1.1830536550405668e-11\n",
      "Epoch 124: Loss = 2.3142376903706463e-11\n",
      "Epoch 125: Loss = 2.5579538487363607e-11\n",
      "Epoch 126: Loss = 6.394884621840902e-12\n",
      "Epoch 127: Loss = 6.039613253960852e-13\n",
      "Epoch 128: Loss = 6.856737400084967e-12\n",
      "Epoch 129: Loss = 8.697043085703626e-12\n",
      "Epoch 130: Loss = 2.2524204723595176e-12\n",
      "Epoch 131: Loss = 1.2079226507921703e-13\n",
      "Epoch 132: Loss = 2.0463630789890885e-12\n",
      "Epoch 133: Loss = 2.6219026949547697e-12\n",
      "Epoch 134: Loss = 2.0534685063466895e-12\n",
      "Epoch 135: Loss = 9.663381206337363e-13\n",
      "Epoch 136: Loss = 1.1368683772161603e-12\n",
      "Epoch 137: Loss = 1.4210854715202004e-12\n",
      "Epoch 138: Loss = 4.618527782440651e-13\n",
      "Epoch 139: Loss = 7.105427357601002e-15\n",
      "Epoch 140: Loss = 1.2079226507921703e-13\n",
      "Epoch 141: Loss = 1.4210854715202004e-13\n",
      "Epoch 142: Loss = 1.7763568394002505e-13\n",
      "Epoch 143: Loss = 1.1368683772161603e-13\n",
      "Epoch 144: Loss = 3.552713678800501e-14\n",
      "Epoch 145: Loss = 6.394884621840902e-14\n",
      "Epoch 146: Loss = 9.237055564881302e-14\n",
      "Epoch 147: Loss = 9.237055564881302e-14\n",
      "Epoch 148: Loss = 5.684341886080802e-14\n",
      "Epoch 149: Loss = 2.842170943040401e-14\n",
      "Epoch 150: Loss = 2.842170943040401e-14\n",
      "Epoch 151: Loss = 5.684341886080802e-14\n",
      "Epoch 152: Loss = 3.552713678800501e-14\n",
      "Epoch 153: Loss = 7.105427357601002e-15\n",
      "Epoch 154: Loss = 7.105427357601002e-15\n",
      "Epoch 155: Loss = 7.105427357601002e-15\n",
      "Epoch 156: Loss = 1.1368683772161603e-13\n",
      "Epoch 157: Loss = 3.552713678800501e-14\n",
      "Epoch 158: Loss = 3.552713678800501e-14\n",
      "Epoch 159: Loss = 7.105427357601002e-15\n",
      "Epoch 160: Loss = 7.105427357601002e-15\n",
      "Epoch 161: Loss = 3.552713678800501e-14\n",
      "Epoch 162: Loss = 3.552713678800501e-14\n",
      "Epoch 163: Loss = 3.552713678800501e-14\n",
      "Epoch 164: Loss = 3.552713678800501e-14\n",
      "Epoch 165: Loss = 7.105427357601002e-15\n",
      "Epoch 166: Loss = 7.105427357601002e-15\n",
      "Epoch 167: Loss = 7.105427357601002e-15\n",
      "Epoch 168: Loss = 3.552713678800501e-14\n",
      "Epoch 169: Loss = 3.552713678800501e-14\n",
      "Epoch 170: Loss = 0.0\n",
      "Epoch 171: Loss = 3.552713678800501e-14\n",
      "Epoch 172: Loss = 3.552713678800501e-14\n",
      "Epoch 173: Loss = 3.552713678800501e-14\n",
      "Epoch 174: Loss = 3.552713678800501e-14\n",
      "Epoch 175: Loss = 0.0\n",
      "Epoch 176: Loss = 0.0\n",
      "Epoch 177: Loss = 2.842170943040401e-14\n",
      "Epoch 178: Loss = 0.0\n",
      "Epoch 179: Loss = 0.0\n",
      "Epoch 180: Loss = 7.105427357601002e-15\n",
      "Epoch 181: Loss = 7.105427357601002e-15\n",
      "Epoch 182: Loss = 0.0\n",
      "Epoch 183: Loss = 0.0\n",
      "Epoch 184: Loss = 0.0\n",
      "Epoch 185: Loss = 0.0\n",
      "Epoch 186: Loss = 0.0\n",
      "Epoch 187: Loss = 0.0\n",
      "Epoch 188: Loss = 0.0\n",
      "Epoch 189: Loss = 0.0\n",
      "Epoch 190: Loss = 0.0\n",
      "Epoch 191: Loss = 0.0\n",
      "Epoch 192: Loss = 0.0\n",
      "Epoch 193: Loss = 0.0\n",
      "Epoch 194: Loss = 0.0\n",
      "Epoch 195: Loss = 0.0\n",
      "Epoch 196: Loss = 0.0\n",
      "Epoch 197: Loss = 0.0\n",
      "Epoch 198: Loss = 0.0\n",
      "Epoch 199: Loss = 0.0\n",
      "Epoch 200: Loss = 0.0\n",
      "Epoch 201: Loss = 0.0\n",
      "Epoch 202: Loss = 0.0\n",
      "Epoch 203: Loss = 0.0\n",
      "Epoch 204: Loss = 0.0\n",
      "Epoch 205: Loss = 0.0\n",
      "Epoch 206: Loss = 0.0\n",
      "Epoch 207: Loss = 0.0\n",
      "Epoch 208: Loss = 0.0\n",
      "Epoch 209: Loss = 0.0\n",
      "Epoch 210: Loss = 0.0\n",
      "Epoch 211: Loss = 0.0\n",
      "Epoch 212: Loss = 0.0\n",
      "Epoch 213: Loss = 0.0\n",
      "Epoch 214: Loss = 0.0\n",
      "Epoch 215: Loss = 0.0\n",
      "Epoch 216: Loss = 0.0\n",
      "Epoch 217: Loss = 0.0\n",
      "Epoch 218: Loss = 0.0\n",
      "Epoch 219: Loss = 0.0\n",
      "Epoch 220: Loss = 0.0\n",
      "Epoch 221: Loss = 0.0\n",
      "Epoch 222: Loss = 0.0\n",
      "Epoch 223: Loss = 0.0\n",
      "Epoch 224: Loss = 0.0\n",
      "Epoch 225: Loss = 0.0\n",
      "Epoch 226: Loss = 0.0\n",
      "Epoch 227: Loss = 0.0\n",
      "Epoch 228: Loss = 0.0\n",
      "Epoch 229: Loss = 0.0\n",
      "Epoch 230: Loss = 0.0\n",
      "Epoch 231: Loss = 0.0\n",
      "Epoch 232: Loss = 0.0\n",
      "Epoch 233: Loss = 0.0\n",
      "Epoch 234: Loss = 0.0\n",
      "Epoch 235: Loss = 0.0\n",
      "Epoch 236: Loss = 0.0\n",
      "Epoch 237: Loss = 0.0\n",
      "Epoch 238: Loss = 0.0\n",
      "Epoch 239: Loss = 0.0\n",
      "Epoch 240: Loss = 0.0\n",
      "Epoch 241: Loss = 0.0\n",
      "Epoch 242: Loss = 0.0\n",
      "Epoch 243: Loss = 0.0\n",
      "Epoch 244: Loss = 0.0\n",
      "Epoch 245: Loss = 0.0\n",
      "Epoch 246: Loss = 0.0\n",
      "Epoch 247: Loss = 0.0\n",
      "Epoch 248: Loss = 0.0\n",
      "Epoch 249: Loss = 0.0\n",
      "Epoch 250: Loss = 0.0\n",
      "Epoch 251: Loss = 0.0\n",
      "Epoch 252: Loss = 0.0\n",
      "Epoch 253: Loss = 0.0\n",
      "Epoch 254: Loss = 0.0\n",
      "Epoch 255: Loss = 0.0\n",
      "Epoch 256: Loss = 0.0\n",
      "Epoch 257: Loss = 0.0\n",
      "Epoch 258: Loss = 0.0\n",
      "Epoch 259: Loss = 0.0\n",
      "Epoch 260: Loss = 0.0\n",
      "Epoch 261: Loss = 0.0\n",
      "Epoch 262: Loss = 0.0\n",
      "Epoch 263: Loss = 0.0\n",
      "Epoch 264: Loss = 0.0\n",
      "Epoch 265: Loss = 0.0\n",
      "Epoch 266: Loss = 0.0\n",
      "Epoch 267: Loss = 0.0\n",
      "Epoch 268: Loss = 0.0\n",
      "Epoch 269: Loss = 0.0\n",
      "Epoch 270: Loss = 0.0\n",
      "Epoch 271: Loss = 0.0\n",
      "Epoch 272: Loss = 0.0\n",
      "Epoch 273: Loss = 0.0\n",
      "Epoch 274: Loss = 0.0\n",
      "Epoch 275: Loss = 0.0\n",
      "Epoch 276: Loss = 0.0\n",
      "Epoch 277: Loss = 0.0\n",
      "Epoch 278: Loss = 0.0\n",
      "Epoch 279: Loss = 0.0\n",
      "Epoch 280: Loss = 0.0\n",
      "Epoch 281: Loss = 0.0\n",
      "Epoch 282: Loss = 0.0\n",
      "Epoch 283: Loss = 0.0\n",
      "Epoch 284: Loss = 0.0\n",
      "Epoch 285: Loss = 0.0\n",
      "Epoch 286: Loss = 0.0\n",
      "Epoch 287: Loss = 0.0\n",
      "Epoch 288: Loss = 0.0\n",
      "Epoch 289: Loss = 0.0\n",
      "Epoch 290: Loss = 0.0\n",
      "Epoch 291: Loss = 0.0\n",
      "Epoch 292: Loss = 0.0\n",
      "Epoch 293: Loss = 0.0\n",
      "Epoch 294: Loss = 0.0\n",
      "Epoch 295: Loss = 0.0\n",
      "Epoch 296: Loss = 0.0\n",
      "Epoch 297: Loss = 0.0\n",
      "Epoch 298: Loss = 0.0\n",
      "Epoch 299: Loss = 0.0\n",
      "Epoch 300: Loss = 0.0\n",
      "Epoch 301: Loss = 0.0\n",
      "Epoch 302: Loss = 0.0\n",
      "Epoch 303: Loss = 0.0\n",
      "Epoch 304: Loss = 0.0\n",
      "Epoch 305: Loss = 0.0\n",
      "Epoch 306: Loss = 0.0\n",
      "Epoch 307: Loss = 0.0\n",
      "Epoch 308: Loss = 0.0\n",
      "Epoch 309: Loss = 0.0\n",
      "Epoch 310: Loss = 0.0\n",
      "Epoch 311: Loss = 0.0\n",
      "Epoch 312: Loss = 0.0\n",
      "Epoch 313: Loss = 0.0\n",
      "Epoch 314: Loss = 0.0\n",
      "Epoch 315: Loss = 0.0\n",
      "Epoch 316: Loss = 0.0\n",
      "Epoch 317: Loss = 0.0\n",
      "Epoch 318: Loss = 0.0\n",
      "Epoch 319: Loss = 0.0\n",
      "Epoch 320: Loss = 0.0\n",
      "Epoch 321: Loss = 0.0\n",
      "Epoch 322: Loss = 0.0\n",
      "Epoch 323: Loss = 0.0\n",
      "Epoch 324: Loss = 0.0\n",
      "Epoch 325: Loss = 0.0\n",
      "Epoch 326: Loss = 0.0\n",
      "Epoch 327: Loss = 0.0\n",
      "Epoch 328: Loss = 0.0\n",
      "Epoch 329: Loss = 0.0\n",
      "Epoch 330: Loss = 0.0\n",
      "Epoch 331: Loss = 0.0\n",
      "Epoch 332: Loss = 0.0\n",
      "Epoch 333: Loss = 0.0\n",
      "Epoch 334: Loss = 0.0\n",
      "Epoch 335: Loss = 0.0\n",
      "Epoch 336: Loss = 0.0\n",
      "Epoch 337: Loss = 0.0\n",
      "Epoch 338: Loss = 0.0\n",
      "Epoch 339: Loss = 0.0\n",
      "Epoch 340: Loss = 0.0\n",
      "Epoch 341: Loss = 0.0\n",
      "Epoch 342: Loss = 0.0\n",
      "Epoch 343: Loss = 0.0\n",
      "Epoch 344: Loss = 0.0\n",
      "Epoch 345: Loss = 0.0\n",
      "Epoch 346: Loss = 0.0\n",
      "Epoch 347: Loss = 0.0\n",
      "Epoch 348: Loss = 0.0\n",
      "Epoch 349: Loss = 0.0\n",
      "Epoch 350: Loss = 0.0\n",
      "Epoch 351: Loss = 0.0\n",
      "Epoch 352: Loss = 0.0\n",
      "Epoch 353: Loss = 0.0\n",
      "Epoch 354: Loss = 0.0\n",
      "Epoch 355: Loss = 0.0\n",
      "Epoch 356: Loss = 0.0\n",
      "Epoch 357: Loss = 0.0\n",
      "Epoch 358: Loss = 0.0\n",
      "Epoch 359: Loss = 0.0\n",
      "Epoch 360: Loss = 0.0\n",
      "Epoch 361: Loss = 0.0\n",
      "Epoch 362: Loss = 0.0\n",
      "Epoch 363: Loss = 0.0\n",
      "Epoch 364: Loss = 0.0\n",
      "Epoch 365: Loss = 0.0\n",
      "Epoch 366: Loss = 0.0\n",
      "Epoch 367: Loss = 0.0\n",
      "Epoch 368: Loss = 0.0\n",
      "Epoch 369: Loss = 0.0\n",
      "Epoch 370: Loss = 0.0\n",
      "Epoch 371: Loss = 0.0\n",
      "Epoch 372: Loss = 0.0\n",
      "Epoch 373: Loss = 0.0\n",
      "Epoch 374: Loss = 0.0\n",
      "Epoch 375: Loss = 0.0\n",
      "Epoch 376: Loss = 0.0\n",
      "Epoch 377: Loss = 0.0\n",
      "Epoch 378: Loss = 0.0\n",
      "Epoch 379: Loss = 0.0\n",
      "Epoch 380: Loss = 0.0\n",
      "Epoch 381: Loss = 0.0\n",
      "Epoch 382: Loss = 0.0\n",
      "Epoch 383: Loss = 0.0\n",
      "Epoch 384: Loss = 0.0\n",
      "Epoch 385: Loss = 0.0\n",
      "Epoch 386: Loss = 0.0\n",
      "Epoch 387: Loss = 0.0\n",
      "Epoch 388: Loss = 0.0\n",
      "Epoch 389: Loss = 0.0\n",
      "Epoch 390: Loss = 0.0\n",
      "Epoch 391: Loss = 0.0\n",
      "Epoch 392: Loss = 0.0\n",
      "Epoch 393: Loss = 0.0\n",
      "Epoch 394: Loss = 0.0\n",
      "Epoch 395: Loss = 0.0\n",
      "Epoch 396: Loss = 0.0\n",
      "Epoch 397: Loss = 0.0\n",
      "Epoch 398: Loss = 0.0\n",
      "Epoch 399: Loss = 0.0\n",
      "Epoch 400: Loss = 0.0\n",
      "Epoch 401: Loss = 0.0\n",
      "Epoch 402: Loss = 0.0\n",
      "Epoch 403: Loss = 0.0\n",
      "Epoch 404: Loss = 0.0\n",
      "Epoch 405: Loss = 0.0\n",
      "Epoch 406: Loss = 0.0\n",
      "Epoch 407: Loss = 0.0\n",
      "Epoch 408: Loss = 0.0\n",
      "Epoch 409: Loss = 0.0\n",
      "Epoch 410: Loss = 0.0\n",
      "Epoch 411: Loss = 0.0\n",
      "Epoch 412: Loss = 0.0\n",
      "Epoch 413: Loss = 0.0\n",
      "Epoch 414: Loss = 0.0\n",
      "Epoch 415: Loss = 0.0\n",
      "Epoch 416: Loss = 0.0\n",
      "Epoch 417: Loss = 0.0\n",
      "Epoch 418: Loss = 0.0\n",
      "Epoch 419: Loss = 0.0\n",
      "Epoch 420: Loss = 0.0\n",
      "Epoch 421: Loss = 0.0\n",
      "Epoch 422: Loss = 0.0\n",
      "Epoch 423: Loss = 0.0\n",
      "Epoch 424: Loss = 0.0\n",
      "Epoch 425: Loss = 0.0\n",
      "Epoch 426: Loss = 0.0\n",
      "Epoch 427: Loss = 0.0\n",
      "Epoch 428: Loss = 0.0\n",
      "Epoch 429: Loss = 0.0\n",
      "Epoch 430: Loss = 0.0\n",
      "Epoch 431: Loss = 0.0\n",
      "Epoch 432: Loss = 0.0\n",
      "Epoch 433: Loss = 0.0\n",
      "Epoch 434: Loss = 0.0\n",
      "Epoch 435: Loss = 0.0\n",
      "Epoch 436: Loss = 0.0\n",
      "Epoch 437: Loss = 0.0\n",
      "Epoch 438: Loss = 0.0\n",
      "Epoch 439: Loss = 0.0\n",
      "Epoch 440: Loss = 0.0\n",
      "Epoch 441: Loss = 0.0\n",
      "Epoch 442: Loss = 0.0\n",
      "Epoch 443: Loss = 0.0\n",
      "Epoch 444: Loss = 0.0\n",
      "Epoch 445: Loss = 0.0\n",
      "Epoch 446: Loss = 0.0\n",
      "Epoch 447: Loss = 0.0\n",
      "Epoch 448: Loss = 0.0\n",
      "Epoch 449: Loss = 0.0\n",
      "Epoch 450: Loss = 0.0\n",
      "Epoch 451: Loss = 0.0\n",
      "Epoch 452: Loss = 0.0\n",
      "Epoch 453: Loss = 0.0\n",
      "Epoch 454: Loss = 0.0\n",
      "Epoch 455: Loss = 0.0\n",
      "Epoch 456: Loss = 0.0\n",
      "Epoch 457: Loss = 0.0\n",
      "Epoch 458: Loss = 0.0\n",
      "Epoch 459: Loss = 0.0\n",
      "Epoch 460: Loss = 0.0\n",
      "Epoch 461: Loss = 0.0\n",
      "Epoch 462: Loss = 0.0\n",
      "Epoch 463: Loss = 0.0\n",
      "Epoch 464: Loss = 0.0\n",
      "Epoch 465: Loss = 0.0\n",
      "Epoch 466: Loss = 0.0\n",
      "Epoch 467: Loss = 0.0\n",
      "Epoch 468: Loss = 0.0\n",
      "Epoch 469: Loss = 0.0\n",
      "Epoch 470: Loss = 0.0\n",
      "Epoch 471: Loss = 0.0\n",
      "Epoch 472: Loss = 0.0\n",
      "Epoch 473: Loss = 0.0\n",
      "Epoch 474: Loss = 0.0\n",
      "Epoch 475: Loss = 0.0\n",
      "Epoch 476: Loss = 0.0\n",
      "Epoch 477: Loss = 0.0\n",
      "Epoch 478: Loss = 0.0\n",
      "Epoch 479: Loss = 0.0\n",
      "Epoch 480: Loss = 0.0\n",
      "Epoch 481: Loss = 0.0\n",
      "Epoch 482: Loss = 0.0\n",
      "Epoch 483: Loss = 0.0\n",
      "Epoch 484: Loss = 0.0\n",
      "Epoch 485: Loss = 0.0\n",
      "Epoch 486: Loss = 0.0\n",
      "Epoch 487: Loss = 0.0\n",
      "Epoch 488: Loss = 0.0\n",
      "Epoch 489: Loss = 0.0\n",
      "Epoch 490: Loss = 0.0\n",
      "Epoch 491: Loss = 0.0\n",
      "Epoch 492: Loss = 0.0\n",
      "Epoch 493: Loss = 0.0\n",
      "Epoch 494: Loss = 0.0\n",
      "Epoch 495: Loss = 0.0\n",
      "Epoch 496: Loss = 0.0\n",
      "Epoch 497: Loss = 0.0\n",
      "Epoch 498: Loss = 0.0\n",
      "Epoch 499: Loss = 0.0\n",
      "Epoch 500: Loss = 0.0\n",
      "Epoch 501: Loss = 0.0\n",
      "Epoch 502: Loss = 0.0\n",
      "Epoch 503: Loss = 0.0\n",
      "Epoch 504: Loss = 0.0\n",
      "Epoch 505: Loss = 0.0\n",
      "Epoch 506: Loss = 0.0\n",
      "Epoch 507: Loss = 0.0\n",
      "Epoch 508: Loss = 0.0\n",
      "Epoch 509: Loss = 0.0\n",
      "Epoch 510: Loss = 0.0\n",
      "Epoch 511: Loss = 0.0\n",
      "Epoch 512: Loss = 0.0\n",
      "Epoch 513: Loss = 0.0\n",
      "Epoch 514: Loss = 0.0\n",
      "Epoch 515: Loss = 0.0\n",
      "Epoch 516: Loss = 0.0\n",
      "Epoch 517: Loss = 0.0\n",
      "Epoch 518: Loss = 0.0\n",
      "Epoch 519: Loss = 0.0\n",
      "Epoch 520: Loss = 0.0\n",
      "Epoch 521: Loss = 0.0\n",
      "Epoch 522: Loss = 0.0\n",
      "Epoch 523: Loss = 0.0\n",
      "Epoch 524: Loss = 0.0\n",
      "Epoch 525: Loss = 0.0\n",
      "Epoch 526: Loss = 0.0\n",
      "Epoch 527: Loss = 0.0\n",
      "Epoch 528: Loss = 0.0\n",
      "Epoch 529: Loss = 0.0\n",
      "Epoch 530: Loss = 0.0\n",
      "Epoch 531: Loss = 0.0\n",
      "Epoch 532: Loss = 0.0\n",
      "Epoch 533: Loss = 0.0\n",
      "Epoch 534: Loss = 0.0\n",
      "Epoch 535: Loss = 0.0\n",
      "Epoch 536: Loss = 0.0\n",
      "Epoch 537: Loss = 0.0\n",
      "Epoch 538: Loss = 0.0\n",
      "Epoch 539: Loss = 0.0\n",
      "Epoch 540: Loss = 0.0\n",
      "Epoch 541: Loss = 0.0\n",
      "Epoch 542: Loss = 0.0\n",
      "Epoch 543: Loss = 0.0\n",
      "Epoch 544: Loss = 0.0\n",
      "Epoch 545: Loss = 0.0\n",
      "Epoch 546: Loss = 0.0\n",
      "Epoch 547: Loss = 0.0\n",
      "Epoch 548: Loss = 0.0\n",
      "Epoch 549: Loss = 0.0\n",
      "Epoch 550: Loss = 0.0\n",
      "Epoch 551: Loss = 0.0\n",
      "Epoch 552: Loss = 0.0\n",
      "Epoch 553: Loss = 0.0\n",
      "Epoch 554: Loss = 0.0\n",
      "Epoch 555: Loss = 0.0\n",
      "Epoch 556: Loss = 0.0\n",
      "Epoch 557: Loss = 0.0\n",
      "Epoch 558: Loss = 0.0\n",
      "Epoch 559: Loss = 0.0\n",
      "Epoch 560: Loss = 0.0\n",
      "Epoch 561: Loss = 0.0\n",
      "Epoch 562: Loss = 0.0\n",
      "Epoch 563: Loss = 0.0\n",
      "Epoch 564: Loss = 0.0\n",
      "Epoch 565: Loss = 0.0\n",
      "Epoch 566: Loss = 0.0\n",
      "Epoch 567: Loss = 0.0\n",
      "Epoch 568: Loss = 0.0\n",
      "Epoch 569: Loss = 0.0\n",
      "Epoch 570: Loss = 0.0\n",
      "Epoch 571: Loss = 0.0\n",
      "Epoch 572: Loss = 0.0\n",
      "Epoch 573: Loss = 0.0\n",
      "Epoch 574: Loss = 0.0\n",
      "Epoch 575: Loss = 0.0\n",
      "Epoch 576: Loss = 0.0\n",
      "Epoch 577: Loss = 0.0\n",
      "Epoch 578: Loss = 0.0\n",
      "Epoch 579: Loss = 0.0\n",
      "Epoch 580: Loss = 0.0\n",
      "Epoch 581: Loss = 0.0\n",
      "Epoch 582: Loss = 0.0\n",
      "Epoch 583: Loss = 0.0\n",
      "Epoch 584: Loss = 0.0\n",
      "Epoch 585: Loss = 0.0\n",
      "Epoch 586: Loss = 0.0\n",
      "Epoch 587: Loss = 0.0\n",
      "Epoch 588: Loss = 0.0\n",
      "Epoch 589: Loss = 0.0\n",
      "Epoch 590: Loss = 0.0\n",
      "Epoch 591: Loss = 0.0\n",
      "Epoch 592: Loss = 0.0\n",
      "Epoch 593: Loss = 0.0\n",
      "Epoch 594: Loss = 0.0\n",
      "Epoch 595: Loss = 0.0\n",
      "Epoch 596: Loss = 0.0\n",
      "Epoch 597: Loss = 0.0\n",
      "Epoch 598: Loss = 0.0\n",
      "Epoch 599: Loss = 0.0\n",
      "Epoch 600: Loss = 0.0\n",
      "Epoch 601: Loss = 0.0\n",
      "Epoch 602: Loss = 0.0\n",
      "Epoch 603: Loss = 0.0\n",
      "Epoch 604: Loss = 0.0\n",
      "Epoch 605: Loss = 0.0\n",
      "Epoch 606: Loss = 0.0\n",
      "Epoch 607: Loss = 0.0\n",
      "Epoch 608: Loss = 0.0\n",
      "Epoch 609: Loss = 0.0\n",
      "Epoch 610: Loss = 0.0\n",
      "Epoch 611: Loss = 0.0\n",
      "Epoch 612: Loss = 0.0\n",
      "Epoch 613: Loss = 0.0\n",
      "Epoch 614: Loss = 0.0\n",
      "Epoch 615: Loss = 0.0\n",
      "Epoch 616: Loss = 0.0\n",
      "Epoch 617: Loss = 0.0\n",
      "Epoch 618: Loss = 0.0\n",
      "Epoch 619: Loss = 0.0\n",
      "Epoch 620: Loss = 0.0\n",
      "Epoch 621: Loss = 0.0\n",
      "Epoch 622: Loss = 0.0\n",
      "Epoch 623: Loss = 0.0\n",
      "Epoch 624: Loss = 0.0\n",
      "Epoch 625: Loss = 0.0\n",
      "Epoch 626: Loss = 0.0\n",
      "Epoch 627: Loss = 0.0\n",
      "Epoch 628: Loss = 0.0\n",
      "Epoch 629: Loss = 0.0\n",
      "Epoch 630: Loss = 0.0\n",
      "Epoch 631: Loss = 0.0\n",
      "Epoch 632: Loss = 0.0\n",
      "Epoch 633: Loss = 0.0\n",
      "Epoch 634: Loss = 0.0\n",
      "Epoch 635: Loss = 0.0\n",
      "Epoch 636: Loss = 0.0\n",
      "Epoch 637: Loss = 0.0\n",
      "Epoch 638: Loss = 0.0\n",
      "Epoch 639: Loss = 0.0\n",
      "Epoch 640: Loss = 0.0\n",
      "Epoch 641: Loss = 0.0\n",
      "Epoch 642: Loss = 0.0\n",
      "Epoch 643: Loss = 0.0\n",
      "Epoch 644: Loss = 0.0\n",
      "Epoch 645: Loss = 0.0\n",
      "Epoch 646: Loss = 0.0\n",
      "Epoch 647: Loss = 0.0\n",
      "Epoch 648: Loss = 0.0\n",
      "Epoch 649: Loss = 0.0\n",
      "Epoch 650: Loss = 0.0\n",
      "Epoch 651: Loss = 0.0\n",
      "Epoch 652: Loss = 0.0\n",
      "Epoch 653: Loss = 0.0\n",
      "Epoch 654: Loss = 0.0\n",
      "Epoch 655: Loss = 0.0\n",
      "Epoch 656: Loss = 0.0\n",
      "Epoch 657: Loss = 0.0\n",
      "Epoch 658: Loss = 0.0\n",
      "Epoch 659: Loss = 0.0\n",
      "Epoch 660: Loss = 0.0\n",
      "Epoch 661: Loss = 0.0\n",
      "Epoch 662: Loss = 0.0\n",
      "Epoch 663: Loss = 0.0\n",
      "Epoch 664: Loss = 0.0\n",
      "Epoch 665: Loss = 0.0\n",
      "Epoch 666: Loss = 0.0\n",
      "Epoch 667: Loss = 0.0\n",
      "Epoch 668: Loss = 0.0\n",
      "Epoch 669: Loss = 0.0\n",
      "Epoch 670: Loss = 0.0\n",
      "Epoch 671: Loss = 0.0\n",
      "Epoch 672: Loss = 0.0\n",
      "Epoch 673: Loss = 0.0\n",
      "Epoch 674: Loss = 0.0\n",
      "Epoch 675: Loss = 0.0\n",
      "Epoch 676: Loss = 0.0\n",
      "Epoch 677: Loss = 0.0\n",
      "Epoch 678: Loss = 0.0\n",
      "Epoch 679: Loss = 0.0\n",
      "Epoch 680: Loss = 0.0\n",
      "Epoch 681: Loss = 0.0\n",
      "Epoch 682: Loss = 0.0\n",
      "Epoch 683: Loss = 0.0\n",
      "Epoch 684: Loss = 0.0\n",
      "Epoch 685: Loss = 0.0\n",
      "Epoch 686: Loss = 0.0\n",
      "Epoch 687: Loss = 0.0\n",
      "Epoch 688: Loss = 0.0\n",
      "Epoch 689: Loss = 0.0\n",
      "Epoch 690: Loss = 0.0\n",
      "Epoch 691: Loss = 0.0\n",
      "Epoch 692: Loss = 0.0\n",
      "Epoch 693: Loss = 0.0\n",
      "Epoch 694: Loss = 0.0\n",
      "Epoch 695: Loss = 0.0\n",
      "Epoch 696: Loss = 0.0\n",
      "Epoch 697: Loss = 0.0\n",
      "Epoch 698: Loss = 0.0\n",
      "Epoch 699: Loss = 0.0\n",
      "Epoch 700: Loss = 0.0\n",
      "Epoch 701: Loss = 0.0\n",
      "Epoch 702: Loss = 0.0\n",
      "Epoch 703: Loss = 0.0\n",
      "Epoch 704: Loss = 0.0\n",
      "Epoch 705: Loss = 0.0\n",
      "Epoch 706: Loss = 0.0\n",
      "Epoch 707: Loss = 0.0\n",
      "Epoch 708: Loss = 0.0\n",
      "Epoch 709: Loss = 0.0\n",
      "Epoch 710: Loss = 0.0\n",
      "Epoch 711: Loss = 0.0\n",
      "Epoch 712: Loss = 0.0\n",
      "Epoch 713: Loss = 0.0\n",
      "Epoch 714: Loss = 0.0\n",
      "Epoch 715: Loss = 0.0\n",
      "Epoch 716: Loss = 0.0\n",
      "Epoch 717: Loss = 0.0\n",
      "Epoch 718: Loss = 0.0\n",
      "Epoch 719: Loss = 0.0\n",
      "Epoch 720: Loss = 0.0\n",
      "Epoch 721: Loss = 0.0\n",
      "Epoch 722: Loss = 0.0\n",
      "Epoch 723: Loss = 0.0\n",
      "Epoch 724: Loss = 0.0\n",
      "Epoch 725: Loss = 0.0\n",
      "Epoch 726: Loss = 0.0\n",
      "Epoch 727: Loss = 0.0\n",
      "Epoch 728: Loss = 0.0\n",
      "Epoch 729: Loss = 0.0\n",
      "Epoch 730: Loss = 0.0\n",
      "Epoch 731: Loss = 0.0\n",
      "Epoch 732: Loss = 0.0\n",
      "Epoch 733: Loss = 0.0\n",
      "Epoch 734: Loss = 0.0\n",
      "Epoch 735: Loss = 0.0\n",
      "Epoch 736: Loss = 0.0\n",
      "Epoch 737: Loss = 0.0\n",
      "Epoch 738: Loss = 0.0\n",
      "Epoch 739: Loss = 0.0\n",
      "Epoch 740: Loss = 0.0\n",
      "Epoch 741: Loss = 0.0\n",
      "Epoch 742: Loss = 0.0\n",
      "Epoch 743: Loss = 0.0\n",
      "Epoch 744: Loss = 0.0\n",
      "Epoch 745: Loss = 0.0\n",
      "Epoch 746: Loss = 0.0\n",
      "Epoch 747: Loss = 0.0\n",
      "Epoch 748: Loss = 0.0\n",
      "Epoch 749: Loss = 0.0\n",
      "Epoch 750: Loss = 0.0\n",
      "Epoch 751: Loss = 0.0\n",
      "Epoch 752: Loss = 0.0\n",
      "Epoch 753: Loss = 0.0\n",
      "Epoch 754: Loss = 0.0\n",
      "Epoch 755: Loss = 0.0\n",
      "Epoch 756: Loss = 0.0\n",
      "Epoch 757: Loss = 0.0\n",
      "Epoch 758: Loss = 0.0\n",
      "Epoch 759: Loss = 0.0\n",
      "Epoch 760: Loss = 0.0\n",
      "Epoch 761: Loss = 0.0\n",
      "Epoch 762: Loss = 0.0\n",
      "Epoch 763: Loss = 0.0\n",
      "Epoch 764: Loss = 0.0\n",
      "Epoch 765: Loss = 0.0\n",
      "Epoch 766: Loss = 0.0\n",
      "Epoch 767: Loss = 0.0\n",
      "Epoch 768: Loss = 0.0\n",
      "Epoch 769: Loss = 0.0\n",
      "Epoch 770: Loss = 0.0\n",
      "Epoch 771: Loss = 0.0\n",
      "Epoch 772: Loss = 0.0\n",
      "Epoch 773: Loss = 0.0\n",
      "Epoch 774: Loss = 0.0\n",
      "Epoch 775: Loss = 0.0\n",
      "Epoch 776: Loss = 0.0\n",
      "Epoch 777: Loss = 0.0\n",
      "Epoch 778: Loss = 0.0\n",
      "Epoch 779: Loss = 0.0\n",
      "Epoch 780: Loss = 0.0\n",
      "Epoch 781: Loss = 0.0\n",
      "Epoch 782: Loss = 0.0\n",
      "Epoch 783: Loss = 0.0\n",
      "Epoch 784: Loss = 0.0\n",
      "Epoch 785: Loss = 0.0\n",
      "Epoch 786: Loss = 0.0\n",
      "Epoch 787: Loss = 0.0\n",
      "Epoch 788: Loss = 0.0\n",
      "Epoch 789: Loss = 0.0\n",
      "Epoch 790: Loss = 0.0\n",
      "Epoch 791: Loss = 0.0\n",
      "Epoch 792: Loss = 0.0\n",
      "Epoch 793: Loss = 0.0\n",
      "Epoch 794: Loss = 0.0\n",
      "Epoch 795: Loss = 0.0\n",
      "Epoch 796: Loss = 0.0\n",
      "Epoch 797: Loss = 0.0\n",
      "Epoch 798: Loss = 0.0\n",
      "Epoch 799: Loss = 0.0\n",
      "Epoch 800: Loss = 0.0\n",
      "Epoch 801: Loss = 0.0\n",
      "Epoch 802: Loss = 0.0\n",
      "Epoch 803: Loss = 0.0\n",
      "Epoch 804: Loss = 0.0\n",
      "Epoch 805: Loss = 0.0\n",
      "Epoch 806: Loss = 0.0\n",
      "Epoch 807: Loss = 0.0\n",
      "Epoch 808: Loss = 0.0\n",
      "Epoch 809: Loss = 0.0\n",
      "Epoch 810: Loss = 0.0\n",
      "Epoch 811: Loss = 0.0\n",
      "Epoch 812: Loss = 0.0\n",
      "Epoch 813: Loss = 0.0\n",
      "Epoch 814: Loss = 0.0\n",
      "Epoch 815: Loss = 0.0\n",
      "Epoch 816: Loss = 0.0\n",
      "Epoch 817: Loss = 0.0\n",
      "Epoch 818: Loss = 0.0\n",
      "Epoch 819: Loss = 0.0\n",
      "Epoch 820: Loss = 0.0\n",
      "Epoch 821: Loss = 0.0\n",
      "Epoch 822: Loss = 0.0\n",
      "Epoch 823: Loss = 0.0\n",
      "Epoch 824: Loss = 0.0\n",
      "Epoch 825: Loss = 0.0\n",
      "Epoch 826: Loss = 0.0\n",
      "Epoch 827: Loss = 0.0\n",
      "Epoch 828: Loss = 0.0\n",
      "Epoch 829: Loss = 0.0\n",
      "Epoch 830: Loss = 0.0\n",
      "Epoch 831: Loss = 0.0\n",
      "Epoch 832: Loss = 0.0\n",
      "Epoch 833: Loss = 0.0\n",
      "Epoch 834: Loss = 0.0\n",
      "Epoch 835: Loss = 0.0\n",
      "Epoch 836: Loss = 0.0\n",
      "Epoch 837: Loss = 0.0\n",
      "Epoch 838: Loss = 0.0\n",
      "Epoch 839: Loss = 0.0\n",
      "Epoch 840: Loss = 0.0\n",
      "Epoch 841: Loss = 0.0\n",
      "Epoch 842: Loss = 0.0\n",
      "Epoch 843: Loss = 0.0\n",
      "Epoch 844: Loss = 0.0\n",
      "Epoch 845: Loss = 0.0\n",
      "Epoch 846: Loss = 0.0\n",
      "Epoch 847: Loss = 0.0\n",
      "Epoch 848: Loss = 0.0\n",
      "Epoch 849: Loss = 0.0\n",
      "Epoch 850: Loss = 0.0\n",
      "Epoch 851: Loss = 0.0\n",
      "Epoch 852: Loss = 0.0\n",
      "Epoch 853: Loss = 0.0\n",
      "Epoch 854: Loss = 0.0\n",
      "Epoch 855: Loss = 0.0\n",
      "Epoch 856: Loss = 0.0\n",
      "Epoch 857: Loss = 0.0\n",
      "Epoch 858: Loss = 0.0\n",
      "Epoch 859: Loss = 0.0\n",
      "Epoch 860: Loss = 0.0\n",
      "Epoch 861: Loss = 0.0\n",
      "Epoch 862: Loss = 0.0\n",
      "Epoch 863: Loss = 0.0\n",
      "Epoch 864: Loss = 0.0\n",
      "Epoch 865: Loss = 0.0\n",
      "Epoch 866: Loss = 0.0\n",
      "Epoch 867: Loss = 0.0\n",
      "Epoch 868: Loss = 0.0\n",
      "Epoch 869: Loss = 0.0\n",
      "Epoch 870: Loss = 0.0\n",
      "Epoch 871: Loss = 0.0\n",
      "Epoch 872: Loss = 0.0\n",
      "Epoch 873: Loss = 0.0\n",
      "Epoch 874: Loss = 0.0\n",
      "Epoch 875: Loss = 0.0\n",
      "Epoch 876: Loss = 0.0\n",
      "Epoch 877: Loss = 0.0\n",
      "Epoch 878: Loss = 0.0\n",
      "Epoch 879: Loss = 0.0\n",
      "Epoch 880: Loss = 0.0\n",
      "Epoch 881: Loss = 0.0\n",
      "Epoch 882: Loss = 0.0\n",
      "Epoch 883: Loss = 0.0\n",
      "Epoch 884: Loss = 0.0\n",
      "Epoch 885: Loss = 0.0\n",
      "Epoch 886: Loss = 0.0\n",
      "Epoch 887: Loss = 0.0\n",
      "Epoch 888: Loss = 0.0\n",
      "Epoch 889: Loss = 0.0\n",
      "Epoch 890: Loss = 0.0\n",
      "Epoch 891: Loss = 0.0\n",
      "Epoch 892: Loss = 0.0\n",
      "Epoch 893: Loss = 0.0\n",
      "Epoch 894: Loss = 0.0\n",
      "Epoch 895: Loss = 0.0\n",
      "Epoch 896: Loss = 0.0\n",
      "Epoch 897: Loss = 0.0\n",
      "Epoch 898: Loss = 0.0\n",
      "Epoch 899: Loss = 0.0\n",
      "Epoch 900: Loss = 0.0\n",
      "Epoch 901: Loss = 0.0\n",
      "Epoch 902: Loss = 0.0\n",
      "Epoch 903: Loss = 0.0\n",
      "Epoch 904: Loss = 0.0\n",
      "Epoch 905: Loss = 0.0\n",
      "Epoch 906: Loss = 0.0\n",
      "Epoch 907: Loss = 0.0\n",
      "Epoch 908: Loss = 0.0\n",
      "Epoch 909: Loss = 0.0\n",
      "Epoch 910: Loss = 0.0\n",
      "Epoch 911: Loss = 0.0\n",
      "Epoch 912: Loss = 0.0\n",
      "Epoch 913: Loss = 0.0\n",
      "Epoch 914: Loss = 0.0\n",
      "Epoch 915: Loss = 0.0\n",
      "Epoch 916: Loss = 0.0\n",
      "Epoch 917: Loss = 0.0\n",
      "Epoch 918: Loss = 0.0\n",
      "Epoch 919: Loss = 0.0\n",
      "Epoch 920: Loss = 0.0\n",
      "Epoch 921: Loss = 0.0\n",
      "Epoch 922: Loss = 0.0\n",
      "Epoch 923: Loss = 0.0\n",
      "Epoch 924: Loss = 0.0\n",
      "Epoch 925: Loss = 0.0\n",
      "Epoch 926: Loss = 0.0\n",
      "Epoch 927: Loss = 0.0\n",
      "Epoch 928: Loss = 0.0\n",
      "Epoch 929: Loss = 0.0\n",
      "Epoch 930: Loss = 0.0\n",
      "Epoch 931: Loss = 0.0\n",
      "Epoch 932: Loss = 0.0\n",
      "Epoch 933: Loss = 0.0\n",
      "Epoch 934: Loss = 0.0\n",
      "Epoch 935: Loss = 0.0\n",
      "Epoch 936: Loss = 0.0\n",
      "Epoch 937: Loss = 0.0\n",
      "Epoch 938: Loss = 0.0\n",
      "Epoch 939: Loss = 0.0\n",
      "Epoch 940: Loss = 0.0\n",
      "Epoch 941: Loss = 0.0\n",
      "Epoch 942: Loss = 0.0\n",
      "Epoch 943: Loss = 0.0\n",
      "Epoch 944: Loss = 0.0\n",
      "Epoch 945: Loss = 0.0\n",
      "Epoch 946: Loss = 0.0\n",
      "Epoch 947: Loss = 0.0\n",
      "Epoch 948: Loss = 0.0\n",
      "Epoch 949: Loss = 0.0\n",
      "Epoch 950: Loss = 0.0\n",
      "Epoch 951: Loss = 0.0\n",
      "Epoch 952: Loss = 0.0\n",
      "Epoch 953: Loss = 0.0\n",
      "Epoch 954: Loss = 0.0\n",
      "Epoch 955: Loss = 0.0\n",
      "Epoch 956: Loss = 0.0\n",
      "Epoch 957: Loss = 0.0\n",
      "Epoch 958: Loss = 0.0\n",
      "Epoch 959: Loss = 0.0\n",
      "Epoch 960: Loss = 0.0\n",
      "Epoch 961: Loss = 0.0\n",
      "Epoch 962: Loss = 0.0\n",
      "Epoch 963: Loss = 0.0\n",
      "Epoch 964: Loss = 0.0\n",
      "Epoch 965: Loss = 0.0\n",
      "Epoch 966: Loss = 0.0\n",
      "Epoch 967: Loss = 0.0\n",
      "Epoch 968: Loss = 0.0\n",
      "Epoch 969: Loss = 0.0\n",
      "Epoch 970: Loss = 0.0\n",
      "Epoch 971: Loss = 0.0\n",
      "Epoch 972: Loss = 0.0\n",
      "Epoch 973: Loss = 0.0\n",
      "Epoch 974: Loss = 0.0\n",
      "Epoch 975: Loss = 0.0\n",
      "Epoch 976: Loss = 0.0\n",
      "Epoch 977: Loss = 0.0\n",
      "Epoch 978: Loss = 0.0\n",
      "Epoch 979: Loss = 0.0\n",
      "Epoch 980: Loss = 0.0\n",
      "Epoch 981: Loss = 0.0\n",
      "Epoch 982: Loss = 0.0\n",
      "Epoch 983: Loss = 0.0\n",
      "Epoch 984: Loss = 0.0\n",
      "Epoch 985: Loss = 0.0\n",
      "Epoch 986: Loss = 0.0\n",
      "Epoch 987: Loss = 0.0\n",
      "Epoch 988: Loss = 0.0\n",
      "Epoch 989: Loss = 0.0\n",
      "Epoch 990: Loss = 0.0\n",
      "Epoch 991: Loss = 0.0\n",
      "Epoch 992: Loss = 0.0\n",
      "Epoch 993: Loss = 0.0\n",
      "Epoch 994: Loss = 0.0\n",
      "Epoch 995: Loss = 0.0\n",
      "Epoch 996: Loss = 0.0\n",
      "Epoch 997: Loss = 0.0\n",
      "Epoch 998: Loss = 0.0\n",
      "Epoch 999: Loss = 0.0\n",
      "Epoch 1000: Loss = 0.0\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "model = TransformerGATModel(in_channels=1, hidden_channels=8, out_channels=1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Assuming batch_1 and batch_2 are prepared and available\n",
    "batches = [batch_1, batch_2]\n",
    "targets = targets.to(device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1000):  # Example: 10 epochs\n",
    "    total_loss = 0\n",
    "    for batch_graphs, target in zip(batches, targets):\n",
    "        # Prepare batched graph data\n",
    "        batched_data = Batch.from_data_list(batch_graphs).to(device)\n",
    "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "        # Ensure target is a float tensor and has the correct shape\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(x, edge_index, batch).squeeze()\n",
    "        # No need to squeeze if we ensure target and prediction shapes align\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Loss = {total_loss / len(batches)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import CaptumExplainer, Explainer, AttentionExplainer, DummyExplainer, GNNExplainer, GraphMaskExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(),\n",
    "    explanation_type='model',\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    ),\n",
    "    node_mask_type='object',\n",
    "    edge_mask_type='object',\n",
    "    # threshold_config=dict(\n",
    "    #     threshold_type='topk',\n",
    "    #     value=200,\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[308], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m batched_data \u001b[38;5;241m=\u001b[39m Batch\u001b[38;5;241m.\u001b[39mfrom_data_list(batch_2)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m x, edge_index, batch \u001b[38;5;241m=\u001b[39m batched_data\u001b[38;5;241m.\u001b[39mx, batched_data\u001b[38;5;241m.\u001b[39medge_index, batched_data\u001b[38;5;241m.\u001b[39mbatch\n\u001b[0;32m----> 3\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m explanation\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch_geometric/explain/explainer.py:205\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 205\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(training)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:87\u001b[0m, in \u001b[0;36mGNNExplainer.forward\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeterogeneous graphs not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m node_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_mask(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_mask,\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_node_mask,\n\u001b[1;32m     92\u001b[0m     apply_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m )\n\u001b[1;32m     94\u001b[0m edge_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_mask(\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_mask,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_edge_mask,\n\u001b[1;32m     97\u001b[0m     apply_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     98\u001b[0m )\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:117\u001b[0m, in \u001b[0;36mGNNExplainer._train\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    109\u001b[0m     model: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    116\u001b[0m ):\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:165\u001b[0m, in \u001b[0;36mGNNExplainer._initialize_masks\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    162\u001b[0m edge_mask_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer_config\u001b[38;5;241m.\u001b[39medge_mask_type\n\u001b[1;32m    164\u001b[0m device \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 165\u001b[0m (N, F), E \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(), edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    167\u001b[0m std \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_mask_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "batched_data = Batch.from_data_list(batch_2).to(device)\n",
    "x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "explanation = explainer(batched_data.x, batched_data.edge_index, batch=batch)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8616, 0.8292, 0.7333, 0.7463, 0.7062])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation[\"edge_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2748],\n",
       "        [0.2871],\n",
       "        [0.2882],\n",
       "        [0.2677],\n",
       "        [0.6105],\n",
       "        [0.2391],\n",
       "        [0.7181]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation[\"node_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'edge_index', 'explanation[\"node_mask\"]', and 'explanation[\"edge_mask\"]' are correctly defined\n",
    "G = nx.Graph()\n",
    "edge_index_np = edge_index.cpu().numpy()\n",
    "for source, target in edge_index_np.T:\n",
    "    G.add_edge(int(source), int(target))\n",
    "\n",
    "# Normalize node and edge importance scores for visualization\n",
    "node_importance = explanation[\"node_mask\"].cpu().numpy()\n",
    "edge_importance = explanation[\"edge_mask\"].cpu().numpy()\n",
    "node_importance_normalized = node_importance / node_importance.max()\n",
    "edge_importance_normalized = edge_importance / edge_importance.max()\n",
    "\n",
    "# Define the colormap and normalization\n",
    "cmap = plt.cm.viridis\n",
    "norm_node = mcolors.Normalize(vmin=node_importance_normalized.min(), vmax=node_importance_normalized.max())\n",
    "norm_edge = mcolors.Normalize(vmin=edge_importance_normalized.min(), vmax=edge_importance_normalized.max())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Use PyGraphviz to find the tree layout\n",
    "pos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n",
    "\n",
    "# Node sizes and colors based on importance\n",
    "node_sizes = 100 + 900 * node_importance_normalized\n",
    "node_colors = [cmap(norm_node(value)) for value in node_importance_normalized]\n",
    "\n",
    "# Apply a power transformation to increase variation in edge widths\n",
    "edge_widths = 1 + np.power(edge_importance_normalized * 2, 4)  # Adjust the exponent as needed\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, ax=ax)\n",
    "\n",
    "# Draw edges with colors and widths based on their importance\n",
    "edges = edge_index_np.T\n",
    "edge_colors = [cmap(norm_edge(edge_importance_normalized[i])) for i in range(len(edges))]\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges, width=edge_widths, edge_color=edge_colors, ax=ax)\n",
    "\n",
    "# Draw node labels with contrasting colors for readability\n",
    "for node, (x, y) in pos.items():\n",
    "    label_color = 'white' if np.mean(node_colors[node]) < 0.5 else 'black'\n",
    "    plt.text(x, y, str(node), ha='center', va='center', color=label_color, fontsize=8)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "# Add colorbar as a legend for node and edge importance\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm_node)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, orientation='vertical', shrink=0.5)\n",
    "cbar.set_label('Importance')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'edge_index', 'explanation[\"node_mask\"]', and 'explanation[\"edge_mask\"]' are correctly defined\n",
    "G = nx.Graph()\n",
    "edge_index_np = edge_index.cpu().numpy()\n",
    "for source, target in edge_index_np.T:\n",
    "    G.add_edge(int(source), int(target))\n",
    "\n",
    "# Ensuring the graph is a tree (for demonstration)\n",
    "# For real data, ensure your graph construction logic correctly reflects its tree structure\n",
    "\n",
    "# Normalize node and edge importance scores for visualization\n",
    "node_importance = explanation[\"node_mask\"].cpu().numpy()\n",
    "edge_importance = explanation[\"edge_mask\"].cpu().numpy()\n",
    "node_importance_normalized = node_importance / node_importance.max()\n",
    "edge_importance_normalized = edge_importance / edge_importance.max()\n",
    "\n",
    "# Define the colormap and normalization\n",
    "cmap = plt.cm.viridis\n",
    "norm_node = mcolors.Normalize(vmin=node_importance_normalized.min(), vmax=node_importance_normalized.max())\n",
    "norm_edge = mcolors.Normalize(vmin=edge_importance_normalized.min(), vmax=edge_importance_normalized.max())\n",
    "\n",
    "# Assuming a tree layout\n",
    "# This simple approach uses hierarchy.tree_layout if available, or a basic planar layout as fallback\n",
    "try:\n",
    "    # Newer networkx versions\n",
    "    pos = nx.drawing.layout.hierarchy.tree_layout(G)\n",
    "except AttributeError:\n",
    "    # Fallback for older networkx versions or missing functionality\n",
    "    pos = nx.spring_layout(G)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Node sizes and colors based on importance\n",
    "node_sizes = 100 + 900 * node_importance_normalized\n",
    "node_colors = [cmap(norm_node(value)) for value in node_importance_normalized]\n",
    "\n",
    "# Draw nodes and edges\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, ax=ax)\n",
    "edge_widths = 1 + np.power(edge_importance_normalized * 2, 4)  # Adjust as needed\n",
    "edges = edge_index_np.T\n",
    "edge_colors = [cmap(norm_edge(edge_importance_normalized[i])) for i in range(len(edges))]\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges, width=edge_widths, edge_color=edge_colors, ax=ax)\n",
    "\n",
    "# Draw labels\n",
    "for node, (x, y) in pos.items():\n",
    "    label_color = 'white' if np.mean(node_colors[node]) < 0.5 else 'black'\n",
    "    plt.text(x, y, str(node), ha='center', va='center', color=label_color, fontsize=8)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "# Colorbar for node importance\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm_node)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, orientation='vertical', shrink=0.5)\n",
    "cbar.set_label('Importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compatible_forward_func(x, edge_index, batch):\n",
    "    # Ensure model output matches expected shape for IntegratedGradients\n",
    "    return model(x, edge_index, batch).unsqueeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing your input graph\n",
    "input_graph = Batch.from_data_list(batch_1).to(device)  # Assume batch_1 is a list of Data objects\n",
    "x, edge_index, batch = input_graph.x, input_graph.edge_index, input_graph.batch\n",
    "\n",
    "# Create a baseline that matches the input's structure but consists of zeros\n",
    "baseline_tuple = (torch.zeros_like(x), edge_index, batch)  # Assuming edge_index and batch do not require gradients\n",
    "\n",
    "# Combine x, edge_index, and batch into a tuple for IG\n",
    "input_tuple = (x, edge_index, batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Captum Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "# Assume 1 numeric feature (float) and 1 categorical feature (integer)\n",
    "batch_1 = [Data(x=torch.randn(5, 2), edge_index=torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]], dtype=torch.long))]\n",
    "batch_1[0].x[:, 1] = torch.randint(0, 3, (5,))  # Assuming 3 categories for the categorical feature\n",
    "\n",
    "batch_2 = [Data(x=torch.randn(3, 2), edge_index=torch.tensor([[0, 1], [1, 2]], dtype=torch.long)),\n",
    "           Data(x=torch.randn(4, 2), edge_index=torch.tensor([[0, 1, 3], [1, 2, 0]], dtype=torch.long))]\n",
    "for data in batch_2:\n",
    "    data.x[:, 1] = torch.randint(0, 3, (data.x.size(0),))  # Similarly, assigning categorical features\n",
    "\n",
    "# Example target values for each batch\n",
    "targets = torch.tensor([1.5, 2.5], dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "class TransformerGATModel(nn.Module):\n",
    "    def __init__(self, num_numeric_features, categorical_feature_dimensions, hidden_channels, out_channels, num_heads=2):\n",
    "        super(TransformerGATModel, self).__init__()\n",
    "        \n",
    "        # Create embedding layers for each categorical feature\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(num_embeddings=dim, embedding_dim=embedding_size)\n",
    "            for dim, embedding_size in categorical_feature_dimensions\n",
    "        ])\n",
    "        \n",
    "        total_embedding_size = sum(embedding_size for _, embedding_size in categorical_feature_dimensions)\n",
    "        total_in_channels = num_numeric_features + total_embedding_size\n",
    "\n",
    "        self.conv1 = GATConv(total_in_channels, hidden_channels, heads=num_heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels, heads=1, concat=True)\n",
    "        \n",
    "        # Transformer layer\n",
    "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_channels, nhead=num_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(transformer_encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.attention_fc = torch.nn.Linear(hidden_channels, 1)\n",
    "        self.regressor = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_numeric, x_categorical, edge_index, batch):\n",
    "        # Embed categorical features and concatenate with numeric features\n",
    "        embeddings = [embedding(x_categorical[:, i]) for i, embedding in enumerate(self.embeddings)]\n",
    "        x = torch.cat([x_numeric] + embeddings, dim=1)\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        attention_scores = self.attention_fc(x).squeeze(-1)\n",
    "        attention_weights = F.softmax(attention_scores, dim=0)\n",
    "        x = torch.sum(x * attention_weights.unsqueeze(-1), dim=0)\n",
    "\n",
    "        return self.regressor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[305], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m batched_data \u001b[38;5;241m=\u001b[39m Batch\u001b[38;5;241m.\u001b[39mfrom_data_list(batch_graphs)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Separate numeric and categorical features\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m x_numeric \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Assuming the first column is numeric\u001b[39;00m\n\u001b[1;32m     23\u001b[0m x_categorical \u001b[38;5;241m=\u001b[39m batched_data\u001b[38;5;241m.\u001b[39mx[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlong()  \u001b[38;5;66;03m# Assuming the second column is categorical\u001b[39;00m\n\u001b[1;32m     24\u001b[0m edge_index, batch \u001b[38;5;241m=\u001b[39m batched_data\u001b[38;5;241m.\u001b[39medge_index, batched_data\u001b[38;5;241m.\u001b[39mbatch\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "model = TransformerGATModel(\n",
    "    num_numeric_features=1,  # We have 1 numeric feature\n",
    "    categorical_feature_dimensions=[(3, 4)],  # One categorical feature with 3 categories and embedding size of 4\n",
    "    hidden_channels=8,\n",
    "    out_channels=1\n",
    ").to(device)  # Use 'cuda' if you're running on a GPU\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "batches = [batch_1, batch_2]\n",
    "targets = targets.to('cpu')  # Move targets to the same device as your model\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):  # Let's assume 10 epochs for brevity\n",
    "    total_loss = 0\n",
    "    for batch_graphs, target in zip(batches, targets):\n",
    "        batched_data = Batch.from_data_list(batch_graphs).to('cpu')\n",
    "        # Separate numeric and categorical features\n",
    "        x_numeric = batched_data.x[:, [0]]  # Assuming the first column is numeric\n",
    "        x_categorical = batched_data.x[:, 1].long()  # Assuming the second column is categorical\n",
    "        edge_index, batch = batched_data.edge_index, batched_data.batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(x_numeric, x_categorical, edge_index, batch).squeeze()\n",
    "        loss = criterion(prediction, target.unsqueeze(0))  # Make sure target is correctly shaped\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Loss = {total_loss / len(batches)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified GAT for captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# Example synthetic graphs with variable sizes\n",
    "batch_1 = [Data(x=torch.randn(5, 4), edge_index=torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]], dtype=torch.long))]\n",
    "batch_2 = [Data(x=torch.randn(3, 4), edge_index=torch.tensor([[0, 1], [1, 2]], dtype=torch.long)),\n",
    "           Data(x=torch.randn(4, 4), edge_index=torch.tensor([[0, 1, 3], [1, 2, 0]], dtype=torch.long))]\n",
    "\n",
    "# Example target values for each batch\n",
    "targets = torch.tensor([1.5, 2.5], dtype=torch.float)  # Assume one target per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedGATModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_heads=2):\n",
    "        super(SimplifiedGATModel, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels, heads=1, concat=True)\n",
    "        self.regressor = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.regressor(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 2.7841637134552\n",
      "Epoch 2: Loss = 1.643030434846878\n",
      "Epoch 3: Loss = 1.23000318557024\n",
      "Epoch 4: Loss = 0.8688380271196365\n",
      "Epoch 5: Loss = 0.5942750629037619\n",
      "Epoch 6: Loss = 0.4000081276608398\n",
      "Epoch 7: Loss = 0.291634077206254\n",
      "Epoch 8: Loss = 0.35051050782203674\n",
      "Epoch 9: Loss = 0.286686435341835\n",
      "Epoch 10: Loss = 0.13467897474765778\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "model = TransformerGATModel(in_channels=4, hidden_channels=8, out_channels=1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Assuming batch_1 and batch_2 are prepared and available\n",
    "batches = [batch_1, batch_2]\n",
    "targets = targets.to(device)\n",
    "\n",
    "for epoch in range(10):  # Example: 10 epochs\n",
    "    total_loss = 0\n",
    "    for batch_graphs, target in zip(batches, targets):\n",
    "        # Prepare batched graph data\n",
    "        batched_data = Batch.from_data_list(batch_graphs).to(device)\n",
    "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "        # Ensure target is a float tensor and has the correct shape\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(x, edge_index, batch).squeeze()\n",
    "        # No need to squeeze if we ensure target and prediction shapes align\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Loss = {total_loss / len(batches)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ig_forward(x, edge_index, batch):\n",
    "    # Ensure the model is in evaluation mode for consistent output\n",
    "    model.eval()\n",
    "    # Forward pass through the model\n",
    "    logits = model(x, edge_index, batch)\n",
    "    # Return the logits or a specific prediction\n",
    "    return logits\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "# Assuming `data_list` is your list of graph data instances\n",
    "input_batch = Batch.from_data_list(batch_1).to(device)\n",
    "\n",
    "# Prepare your inputs\n",
    "x = input_batch.x\n",
    "edge_index = input_batch.edge_index\n",
    "batch = input_batch.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 100 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m baseline_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(x)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Calculate attributions\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m attributions, delta \u001b[38;5;241m=\u001b[39m \u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify the target class or regression output\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[1;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/captum/_utils/common.py:531\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    528\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _format_inputs(inputs)\n\u001b[1;32m    529\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[0;32m--> 531\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _select_targets(output, target)\n",
      "Cell \u001b[0;32mIn[133], line 5\u001b[0m, in \u001b[0;36mig_forward\u001b[0;34m(x, edge_index, batch)\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Return the logits or a specific prediction\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[120], line 20\u001b[0m, in \u001b[0;36mTransformerGATModel.forward\u001b[0;34m(self, x, edge_index, batch, edge_weight)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, batch, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 20\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index, edge_weight)\n\u001b[1;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m global_mean_pool(x, batch)  \u001b[38;5;66;03m# Now x is (num_graphs, hidden_channels)\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch_geometric/nn/conv/gat_conv.py:324\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    321\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size) \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_nodes\n\u001b[1;32m    322\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m remove_self_loops(\n\u001b[1;32m    323\u001b[0m         edge_index, edge_attr)\n\u001b[0;32m--> 324\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43madd_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch_geometric/utils/loop.py:471\u001b[0m, in \u001b[0;36madd_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     loop_index \u001b[38;5;241m=\u001b[39m EdgeIndex(\n\u001b[1;32m    467\u001b[0m         torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, N, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    468\u001b[0m         sparse_size\u001b[38;5;241m=\u001b[39m(N, N),\n\u001b[1;32m    469\u001b[0m         is_undirected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 471\u001b[0m full_edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sparse:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m edge_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch_geometric/edge_index.py:1057\u001b[0m, in \u001b[0;36mEdgeIndex.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__torch_function__\u001b[39m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;66;03m# To account for this, we hold a number of `HANDLED_FUNCTIONS` that\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# implement specific functions for valid `EdgeIndex` routines.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m HANDLED_FUNCTIONS:\n\u001b[0;32m-> 1057\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHANDLED_FUNCTIONS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;66;03m# For all other PyTorch functions, we return a vanilla PyTorch tensor.\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m     _types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(Tensor \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(t, \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types)\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch_geometric/edge_index.py:1204\u001b[0m, in \u001b[0;36mcat\u001b[0;34m(tensors, dim, out)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensors[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1204\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# No valid `EdgeIndex` anymore.\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/projects/general/learning-portfolio/university/masters/masters-thesis/.venv/lib/python3.11/site-packages/torch/_tensor.py:1418\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1418\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 100 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "# Initialize Integrated Gradients with your forward function\n",
    "ig = IntegratedGradients(ig_forward)\n",
    "\n",
    "# Define a baseline (here, zeros with the same shape as your input features)\n",
    "baseline_x = torch.zeros_like(x)\n",
    "\n",
    "# Calculate attributions\n",
    "attributions, delta = ig.attribute(inputs=x,\n",
    "                                    baselines=baseline_x,\n",
    "                                    additional_forward_args=(edge_index, batch),\n",
    "                                    target=0,  # Specify the target class or regression output\n",
    "                                    return_convergence_delta=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working example from torch geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "path = '.'\n",
    "dataset = TUDataset(\"/home/fox/projects/general/learning-portfolio/university/masters/masters-thesis/data/tu_dataset\", name='Mutagenicity').shuffle()\n",
    "test_dataset = dataset[:len(dataset) // 10]\n",
    "train_dataset = dataset[len(dataset) // 10:]\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "\n",
    "def draw_molecule(g, edge_mask=None, draw_edge_labels=False):\n",
    "    g = g.copy().to_undirected()\n",
    "    node_labels = {}\n",
    "    for u, data in g.nodes(data=True):\n",
    "        node_labels[u] = data['name']\n",
    "    pos = nx.planar_layout(g)\n",
    "    pos = nx.spring_layout(g, pos=pos)\n",
    "    if edge_mask is None:\n",
    "        edge_color = 'black'\n",
    "        widths = None\n",
    "    else:\n",
    "        edge_color = [edge_mask[(u, v)] for u, v in g.edges()]\n",
    "        widths = [x * 10 for x in edge_color]\n",
    "    nx.draw(g, pos=pos, labels=node_labels, width=widths,\n",
    "            edge_color=edge_color, edge_cmap=plt.cm.Blues,\n",
    "            node_color='azure')\n",
    "\n",
    "    if draw_edge_labels and edge_mask is not None:\n",
    "        edge_labels = {k: ('%.2f' % v) for k, v in edge_mask.items()}\n",
    "        nx.draw_networkx_edge_labels(g, pos, edge_labels=edge_labels,\n",
    "                                    font_color='red')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def to_molecule(data):\n",
    "    ATOM_MAP = ['C', 'O', 'Cl', 'H', 'N', 'F',\n",
    "                'Br', 'S', 'P', 'I', 'Na', 'K', 'Li', 'Ca']\n",
    "    g = to_networkx(data, node_attrs=['x'])\n",
    "    for u, data in g.nodes(data=True):\n",
    "        data['name'] = ATOM_MAP[data['x'].index(1.0)]\n",
    "        del data['x']\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/sAAAIHCAYAAADAX0zsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABlzUlEQVR4nO3deZyN5f/H8fc5Z/bFjC07ZQ0zI0tkK5WWbxtp4SeZKXuUklJZKgmRkMgSxl72tUhERVF2viUmxEwY6xhmzHLu3x+Db2PGmOXM3OeceT0fj3nMNOe+r/tDmPO+r+v63BbDMAwBAAAAAAC3YTW7AAAAAAAA4FiEfQAAAAAA3AxhHwAAAAAAN0PYBwAAAADAzRD2AQAAAABwM4R9AAAAAADcDGEfAAAAAAA3Q9gHAAAAAMDNEPYBAAAAAHAzhH0AAAAAANwMYR8AAAAAADdD2AcAAAAAwM0Q9gEAAAAAcDOEfQAAAAAA3AxhHwAAAAAAN0PYBwAAAADAzRD2AQAAAABwM4R9AAAAAADcDGEfAAAAAAA3Q9gHAAAAAMDNEPYBAAAAAHAzhH0AAAAAANwMYR8AAAAAADdD2AcAAAAAwM0Q9gEAAAAAcDOEfQAAAAAA3AxhHwAAAAAAN0PYBwAAAADAzRD2AQAAAABwM4R9AAAAAADcDGEfAAAAAAA3Q9gHAAAAAMDNEPYBAAAAAHAzhH0AAAAAANwMYR8AAAAAADdD2AcAAAAAwM0Q9gEAAAAAcDOEfQAAAAAA3IyH2QUAAAAgfxmS7Fc+W5Q222MxtSIAQH4j7AMAALihVElJklKUFvSvZ1XaG0EvSbYCrAsAUDAshmEYZhcBAAAAx7BLuqS0sJ9dNkl+Yn8nALgTwj4AAICbSJKUkIfzfZU20w8AcH3cwAUAAHADicpb0NeV8xMdUAsAwHyEfQAAABeXJOmyg8a6fGU8AIBrI+wDAAC4MLtuPKM/JzJSwRaLdvz2W6avP9qihRqHhGT4foIyb+oHAHAdhH0AAAAXdsnFxgUAFAzCPgAAgItKVc667jvL2ACA/EfYBwAAcFH5vbeevfsA4Lo8zC4AAAAAuZOSzePizp/X6VOnMp6fnOyQ8QEAzoewDwAA4IIMZb+JXquWLW/4Ws3atW/4mv3KdSw5KQwA4BQI+wAAAC4oJ93yPx4/XlWrV8/w/f6vvy57atY78+2SbDkrDQDgBAj7AAAALsjIwbH1GzZU3QYNMnw/uGhRnclkeX9urwMAcB406AMAAHBBBbW0niX8AOCaCPsAAAAuqKDexPFmEQBcE/9+AwAAuCCL8v+NnFXM7AOAqyLsAwAAuKj8br5EcycAcF2EfQAAABfl5eLjAwDyj8UwDJqsAgAAuKh4SVk/PC93bJIC8mFcAEDBYGYfAADAhfm52LgAgIJB2AcAAHBhVkm+Dh7TV7xJBABXx7/jAAAALs5LkreDxvIWe/UBwB0Q9gEAANyAj/I+w+97ZRwAgOsj7AMAALgJL0mBSmuuJ0kpycnZOs925Txm9AHAfdCNHwAAwA0N/egjefj66slnn9UtpUtneN0qyUNpAd+W4VUAgKsj7AMAALgZwzB022236ciRI1qyZIlatW4tuyRDkkVpQd9ibokAgHxG2AcAAHAz27ZtU4MGDeTn56fY2Fj5+fEgPQAobNizDwAA4GYWL14sSXrkkUcI+gBQSBH2AQAA3IhhGFq0aJEk6amnnjK5GgCAWVjGDwAA4Eb27dunkJAQeXl5KTY2VkWKFDG7JACACZjZBwAAcCNXl/A/+OCDBH0AKMQI+wAAAG7k6hL+Nm3amFwJAMBMLOMHAABwE1FRUapatapsNptOnDih4sWLm10SAMAkzOwDAAC4iatL+O+9916CPgAUcoR9AAAAN8ESfgDAVSzjBwAAcAPHjh1ThQoVZLFYFB0drTJlyphdEgDARMzsAwAAuIElS5ZIkpo0aULQBwAQ9gEAANzB1SX8Tz31lMmVAACcAcv4AQAAXNzJkydVpkwZ2e12HT58WJUqVTK7JACAyZjZBwAAcHHLli2T3W5X/fr1CfoAAEmEfQAAAJd39ZF7LOEHAFzFMn4AAAAXdu7cOd1yyy1KTk7WH3/8oRo1aphdEgDACTCzDwAA4MJWrFih5ORk1a5dm6APALiGsA8AAODCWMIPAMgMy/gBAABcVHx8vEqWLKnExETt3LlTderUMbskAICTYGYfAADARa1evVqJiYmqUqWKwsLCzC4HAOBECPsAAAAuatGiRZKkNm3ayGKxmFwNAMCZsIwfAADABSUmJqpkyZKKj4/XL7/8okaNGpldEgDAiTCzDwAA4IK+++47xcfHq3z58rrzzjvNLgcA4GQI+wAAAC7o6hL+J598UlYrb+kAAOnxkwEAAMDFJCcna9myZZJ45B4AIHOEfQAAABezceNGnT17ViVLllSzZs3MLgcA4IQI+wAAAC7m6hL+1q1by2azmVwNAMAZEfYBAABcSGpqqpYsWSKJJfwAgBsj7AMAALiQn3/+WSdOnFBQUJDuvfdes8sBADgpwj4AAIALubqE/4knnpCXl5fJ1QAAnBVhHwAAwEUYhqHFixdLktq0aWNyNQAAZ2YxDMMwuwgAAADc3G+//aY777xT/v7+io2Nla+vr9klAQCcFDP7AAAALuLqrP4jjzxC0AcAZImwDwAA4AIMw7i2X58l/ACAm2EZPwAAgAvYu3evQkND5eXlpVOnTikwMNDskgAAToyZfQAAABdwdQn/gw8+SNAHANwUYR8AAMAFXF3C/9RTT5lcCQDAFbCMHwAAwMkdPHhQ1apVk81m08mTJ1WsWDGzSwIAODlm9gEAAJzc1SX89957L0EfAJAthH0AAAAnxxJ+AEBOsYwfAADAiR09elQVK1aUxWJRTEyMSpcubXZJAAAXwMw+AACAE1uyZIkkqWnTpgR9AEC2EfYBAACcGEv4AQC5wTJ+AAAAJ3XixAmVKVNGhmHo8OHDqlSpktklAQBcBDP7AAAATmrZsmUyDEMNGjQg6AMAcoSwDwAA4KSuPnKvTZs2JlcCAHA1LOMHAABwQmfPntUtt9yilJQU7d+/X9WrVze7JACAC2FmHwAAwAmtWLFCKSkpCgkJIegDAHKMsA8AAOCEWMIPAMgLlvEDAAA4mfj4eJUsWVKJiYnatWuXwsLCzC4JAOBimNkHAABwMt98840SExNVpUoVhYaGml0OAMAFEfYBAACczKJFiyRJTz31lCwWi8nVAABcEcv4AQAAnEhiYqJKliyp+Ph4bdmyRQ0bNjS7JACAC2JmHwAAwImsXbtW8fHxKl++vBo0aGB2OQAAF0XYBwAAcCJXl/C3adNGVitv1QAAucNPEAAAACeRnJys5cuXS+KRewCAvCHsAwAAOIkNGzbo7NmzuuWWW9SsWTOzywEAuDDCPgAAgJO4uoS/devWstlsJlcDAHBlhH0AAAAnkJqaqqVLl0piCT8AIO8I+wAAAE5g8+bNOnHihIKDg3XvvfeaXQ4AwMUR9gEAAJzA1SX8jz/+uLy8vEyuBgDg6gj7AAAAJjMMQ4sXL5YkPfXUUyZXAwBwBxbDMAyziwAAACjMfv31VzVs2FD+/v6KjY2Vr6+v2SUBAFwcM/sAAAAmuzqr/8gjjxD0AQAOQdgHAAAwkWEY1/brs4QfAOAoLOMHAAAw0Z49exQWFiZvb2/FxsYqMDDQ7JIAAG6AmX0AAAATXV3C/+CDDxL0AQAOQ9gHAAAwEUv4AQD5gWX8AAAAJjlw4ICqV68uDw8PnThxQsWKFTO7JACAm2BmHwAAwCRXl/Dfe++9BH0AgEMR9gEAAExydQl/mzZtTK4EAOBuWMYPAABggr///luVKlWSxWJRTEyMSpcubXZJAAA3wsw+AACACZYsWSJJatasGUEfAOBwhH0AAAATsIQfAJCfWMYPAABQwE6cOKEyZcrIMAwdOXJEFStWNLskAICb8TC7AAAAAHdnSLJf+WyRtHLlShmGoQYNGhD0AQD5gpl9AACAfJAqKUlSitKC/r8ZhqFDUVGKP3dOTRo0kK3gywMAuDnCPgAAgAPZJV1SWti/GcMwZLFYZJPkJ5opAQAch7APAADgIEmSEvJwvq8kLwfVAgAo3LiBDAAA4ACJylvQ15XzEx1QCwAAhH0AAIA8SpJ02UFjXb4yHgAAeUHYBwAAyAO7bj6jfygqSq9266Y6lSurlI+PKhQpooeaNtXnY8cqISHj2QnK2NQPAICc4NF7AAAAeXDpJq+vWbVKEc88Iy9vb7Xr2FG1QkKUlJSkX376SYPeeEN/7NunsZMnZzpuQL5UDAAoDGjQBwAAkEupkuKzeP3woUNqFhamsuXLa/n69Spdpky61/86eFBrVq1Sj969Mz0/QOKxfACAXCHsAwAA5FKCst5f36dHD02bOFFrNm1SoyZNcjy+l9I69AMAkFOEfQAAgFy6oKz31tcqX15e3t7aGRWVq/GtkgJzdSYAoLCjQR8AAEAuGMo66MfFxSkmOlq1QkNzfQ37lesAAJBThH0AAIBcuFm3/AtxcZKkgMC8zc3TlR8AkBuEfQAAgFy42Yx7YJEikqT4Cxfy9ToAAGSGR+8BAABkQ2xsrLZv365t27Zp+/btik9I0FerVt3w+CJFiqhM2bL6fe/ePF3XkqezAQCFFWEfAADgOjExMdq+ffu1j23btunYsWPpjvH395fdbpfVeuOFkg899pgiJ0/W1p9/VsPGjXNVC8swAQC5QTd+AABQaBmGoaNHj6absd++fbuOHz+e6fHVq1dX/fr1Va9evbSPe+6RxWa74fiHoqLUrE4dVahUScvXr9ctpUpleH31ypXq0bt3pufTjR8AkFvM7AMAgELBMAwdOnQoXajfvn27Tp06leFYq9WqmjVrXgv19evXV506dVTkyj78qxIkJWVxzduqVNGUuXP1Ytu2alizptp17KhaISFKSkrS1s2btXTBArWPiLjh+bxRAwDkFjP7AADA7djtdh04cCDdMvzt27fr/PnzGY718PBQ7dq1r4X6evXqKSwsTP7+/je9Tqqk+GzUE3XggD4dOVLfr12r4zEx8vb2Vu2wMLVp107hXbrI29s70/MCJN143QAAADdG2AcAAC4tJSVF+/fvTzdjv2PHDsXHZ4zhXl5eCg0NTbcUPzQ0VD4+Prm+frzSQr8jpSQn69DBg6pZsWK2bjoAAHA9wj4AAHAZycnJ2rdvX7oZ+127dikhISHDsb6+vqpTp066GftatWrJy8vLoTXZJeXt4XrpGYahxIQE3VW7tmxWq6ZPn667777bgVcAABQGbAUDAABOKTExUXv37k23DH/37t1KSsq4S97f319169ZNN2N/++23y8Mj/9/qWCX5Km3/viNYLBb9c+iQ7KmpOnL4sFq0aKFXXnlFQ4cOlZ+fn4OuAgBwd8zsAwAA0126dEm7du1KN2O/b98+paSkZDg2KCjof93wr8zaV6tWLctH4BWEREmXHTCOtyQfSefPn1ffvn31xRdfSJKqVq2q6dOnq1mzZg64CgDA3RH2AQBAgbpw4YJ27tyZbsb+999/l91uz3Bs8eLF0y3Dr1evnipXriyLxWJC5TeXpLzN8PtKun6TwerVq9W5c2dFR0fLYrHotdde05AhQ+Tr65uHKwEA3B1hHwAA5Jtz585px44d6Zrn/fnnn8rs7UepUqXShfr69eurQoUKThvsb8Qu6ZJy1rTPJslPaVsCMnPu3Dn16dNH06dPlyRVr15dkZGRaty4cZ5qBQC4L8I+AABwiFOnTmV41N1ff/2V6bHly5fPMGNftmzZAq44f6UqbaY/RWk3AK5nVVrzJC9l//F6X3/9tbp06aKYmBhZrVb16dNHgwcPZpYfAJABYR8AAOTY8ePH04X67du36++//8702FtvvTVdqK9Xr55uueWWAq7YXIbSAr8hyaK0oJ/b9Qpnz57Vq6++qpkzZ0qSbr/9dkVGRqpRo0YOqRUA4B4I+wAA4IYMw1B0dHS6UL9t2zb9888/mR5frVq1dMvw69atq2LFihVw1YXDihUr1LVrVx0/flxWq1VvvPGG3nvvPfn4+JhdGgDACRD2AQCApLRgf/jw4QxL8WNjYzMca7FYdPvtt6dbin/HHXcoKCjIhMoLrzNnzqh3796aPXu2JKlWrVqKjIzUnXfeaXJlAACzEfYBACiE7Ha7oqKi0s3Yb9++XWfPns1wrM1mU+3atdPN2IeFhSkgIMCEypGZZcuWqVu3bjpx4oRsNpv69eunQYMGydvb2+zSAAAmIewDAODmUlNTtX///nQz9jt27NCFCxcyHOvp6anQ0NB0M/ahoaE0gHMBp0+f1ssvv6x58+ZJkkJCQhQZGan69eubXBkAwAyEfQAA3EhycrJ+//33dMvwd+7cqUuXLmU41sfHR3Xq1EnXOC8kJEReXtc/6R2uZPHixerevbtiY2Nls9n09ttva+DAgfx/BYBChrAPAICLunz5svbu3ZtuGf6uXbt0+fLlDMf6+/vrjjvuSDdjf/vtt8vT09OEypHfYmNj1atXL82fP1+SFBYWpsjISNWtW9fkygAABYWwDwCAC0hISNDu3bvTzdjv3btXycnJGY4tUqSI6tatm+5xd9WrV5fNlt2nucNdLFiwQC+99JJOnTolDw8P9e/fX++88w6z/ABQCBD2AQBwMvHx8dq1a1e65nn//e9/lZqamuHYokWLXgv1Vz9XrlxZVqvVhMrhjE6ePKmXXnpJixYtkiTdcccdioyMVJ06dUyuDACQnwj7AACY6Pz589qxY0e65nn79+9XZj+eS5Ysqfr166ebsa9UqZIsFosJlcOVGIah+fPnq2fPnjp9+rQ8PDw0aNAgvfXWW2zlAAA3RdgHAKCAnD59Wjt27Eg3Y3/w4MFMjy1btmy6UF+/fn2VLVuWYI88OXHihHr06KElS5ZIkurVq6fIyEiFhoaaXBkAwNEI+wAA5IOTJ0+mC/Xbtm3TkSNHMj22UqVK6Zbh161bV6VLly7gilFYGIahefPmqVevXjp79qw8PT317rvvql+/fvLw8DC7PACAgxD2AQD5wpBkv/LZIsl65bO7MQxDMTEx6UL99u3bFR0dnenxVapUSTdjX69ePRUvXryAqwakf/75R927d9fy5cslSQ0aNFBkZKRq165tcmUAAEcg7AMAHCZVUpKkFKUF/etZJXlI8pLkin3hDcPQ33//nS7Ub9++XSdOnMhwrMViUY0aNdItw7/jjjsUHBxc8IUDN2AYhubMmaOXX35Z586dk5eXl95//3317duXWX4AcHGEfQBAntklXVJa2M8umyQ/pd0AcEaGYSgqKirDjP2ZM2cyHGu1WlWrVq10M/Z33HGHAgICTKgcyLmYmBh169ZNK1eulCQ1bNhQkZGRqlmzpsmVAQByi7APAMiTJEkJeTjfV2kz/WZKTU3VgQMH0oX6HTt26Pz58xmO9fT0VEhISLoZ+9DQUPn5+ZlQOeA4hmFo5syZ6t27t86fPy9vb2998MEH6tOnj2w2V1yLAwCFG2EfAJBriZIuO2Acb0k+DhgnO1JSUvTHH3+kW4a/Y8cOXbx4MWNd3t4KCwtL1zwvJCRE3t7eBVQtUPCio6PVpUsXffPNN5Kku+66S5GRkapRo4bJlQEAcoKwDwDIlbzO6F8vP2b4k5KStG/fvnQz9rt27VJiYmKGY/38/HTHHXekm7GvWbMmzyBHoWQYhqZPn67XXntNcXFx8vHx0ZAhQ/Tqq68yyw8ALoKwDwDIMbukC5l8f05kpHq+8IK8vb21IypKZcuVS/f6oy1a6MypU/p5795Mxw1U7vfwJyYmas+ePelm7Pfs2aOkpKSM1wkMVN26ddPN2NeoUYMQA1zn6NGj6ty5s7799ltJUpMmTTR9+nRVr17d5MoAADdDm1UAQI5dusnrly9f1ujhwzVy3Lgcj5udlnYXL17Url270jXP27dvn1JTM7YIDA4OzvCou6pVq8pqddbWgIDzqFChglavXq2pU6eqT58+2rx5s+rUqaNhw4bplVde4e8RADgxZvYBADmSKin+Bq9dndkPveMO/fn779r5118qU7bstddvNrMvpYX9f8+vx8XFaefOnelm7P/44w/Z7Rkf7leiRIlrwf7q51tvvVUWiyVXv1YA//P333+rU6dO+u677yRJzZs317Rp01S1alWTKwMAZIaZfQBAjmRcFJ/R6++8o87t22v08OEa8emn2R7bMAxFHTumZV9+eW3G/sCBA5keW6ZMmXShvl69eipfvjzBHsgnFStW1LfffqvJkyerb9+++vHHHxUWFqaPPvpIPXv2ZJYfAJwMM/sAgBy5oLQ9+5m5OrP//a+/aurnn2vh3LnaERV1bXY/OzP7UQcOqP51+4ErVqyYbhl+vXr1VKZMGQf9igDk1OHDh9WpUyetX79eknTPPfdo2rRpqly5ssmVAQCu4hYsACDbDN046F+vb//+SklJ0ZiPPsrRNW6rUkXPdeigYcOGac2aNTp58qSOHDmiJUuWaODAgXr00UcJ+oDJbr31Vq1du1bjx4+Xv7+/Nm7cqLCwMI0fPz7TLTYAgIJH2AcAZFtO3sLfWrmy2j7/vGZMnqzj//yT7fOsVqtmzJqlt956Sw8++KBKliyZ80IB5Dur1aqXXnpJu3fv1j333KOLFy+qV69eatmypQ4fPmx2eQBQ6BH2AQDZltN9X28MGKCUlBSNHj48X68DwDyVK1fW+vXrNW7cOPn5+en7779XaGioJk6cKHaLAoB5CPsAgGzLaeu7WytX1rMdOuR4dp8We4BrsVqt6tWrl3bv3q3mzZsrPj5ePXr00IMPPqgjR46YXR4AFEqEfQBAtuXmh8bV2f2c7N3nhxPgmqpUqaINGzZozJgx8vX11XfffafQ0FBNmTKFWX4AKGC8nwIAZJtFOf/BcVuVKnq2QwdFTpqkk8eP3/R4q5jZB1yZ1WpV7969tWvXLjVt2lQXLlxQ165d9fDDD+vo0aNmlwcAhQZhHwCQIx65OKdv//5KTk7Wgf3782V8AM6nWrVq2rhxo0aNGiUfHx99++23CgkJ0dSpU5nlB4ACQNgHAOSIVy7OqVy1qp7t0CHfxgfgnGw2m/r06aOdO3fqrrvuUlxcnDp37qxHHnlEx44dM7s8AHBrFoNbqwCAHNi4caMSLBY1aNxYnp6eDh3bJinAoSMCcBapqakaPXq0BgwYoMuXLysoKEhjxoxReHi4LBY27wCAozGzDwDIloSEBL322mtq0aKFuoeHKzU11eFLcf0cOhoAZ2Kz2dS3b1/t2LFDDRs21Pnz5/XCCy/o8ccfV0xMjNnlAYDbIewDAG5q69atqlu3rsaMGSNJevCBB+QrOXQ2zlf8UAIKg5o1a2rTpk0aPny4vLy8tGrVKtWuXVuzZs1iLz8AOBDL+AEAN5SUlKTBgwdr2LBhstvtKlOmjL744gs98sgjkqRESZcdcB1vST4OGAeAa9m3b58iIiL022+/SZIef/xxTZo0SWXKlDG5MgBwfUyiAAAytWvXLt1555368MMPZbfb1b59e+3du/da0JfSArpvHq/jK4I+UFjVrl1bP//8sz788EN5enpqxYoVql27tubMmcMsPwDkETP7AIB0UlJSNGLECL333ntKTk5WiRIl9Pnnn+vpp5++4Tl2SZckpebgOjal7dHnrjMASdqzZ48iIiK0fft2SVLr1q01ceJElSpVyuTKAMA1EfYBANf88ccfCg8P19atWyVJrVq10qRJk7L9ZjtVUpKkFKXdALieVZKH0h6vZ3NIxQDcSXJysj766CMNHjxYycnJKl68uD777DO1bduWjv0AkEOEfQCA7Ha7Pv30U7399ttKTExUUFCQxo0bpw4dOuT6DbahtMBvSLIoLejzVh1AduzevVvh4eHauXOnJOmpp57ShAkTdMstt5hbGAC4EMI+ABRyhw4d0gsvvKCNGzdKkh588EFNnTpV5cuXN7kyAIVZcnKyhg4dqiFDhiglJUUlSpTQhAkT9Mwzz5hdGgC4BMI+ABRShmHoiy++UJ8+fRQfHy9/f3+NGjVKXbt2ZbksAKexc+dOhYeHa/fu3ZKkZ555RuPHj1fJkiVNrgwAnBthHwAKoejoaHXu3FmrV6+WJDVv3lyRkZGqXLmyyZUBQEZJSUkaMmSIhg4dqtTUVJUsWVKff/65nnrqKbNLAwCnRdgHgELEMAzNnTtXvXr10rlz5+Tt7a2hQ4eqd+/estlomQfAuW3btk0RERHau3evJKldu3b67LPPVLx4cZMrAwDnQ9gHgEIiNjZW3bt31+LFiyVJDRo00MyZM1WzZk2TKwOA7Lt8+bI++OADDR8+XKmpqSpVqpQmTpyo1q1bm10aADgVwj4AFAJLly5V165dFRsbKw8PD7377rt666235OHhYXZpAJArv/76qyIiIvTf//5XkvTcc8/p008/VbFixUyuDACcA2EfANzY2bNn1bt3b82aNUuSFBISopkzZ6pu3bomVwYAeZeYmKj3339fI0aMkN1uV+nSpTVp0iQ98cQTZpcGAKYj7AOAm1qzZo06deqk6OhoWa1Wvfnmm3rvvffk7e1tdmkA4FBbtmxRRESE/vjjD0nS888/r7Fjx6po0aImVwYUToYk+5XPFknWK59RsAj7AOBm4uPj1bdvX02aNEmSVK1aNc2YMUONGzc2uTIAyD+JiYkaNGiQRo0aJbvdrrJly2ry5Ml69NFHzS4NKBRSJSVJSlFa0L+eVZKHJC9JtAQuGIR9AHAjP/zwgyIiInTo0CFJ0iuvvKJhw4bJz8/P5MoAoGD8/PPPioiI0J9//ilJioiI0OjRoxUcHGxuYYCbsku6pLSwn102SX5KuwGA/MPvLwC4gYSEBPXp00ctWrTQoUOHVKlSJa1bt05jx44l6AMoVBo3bqydO3fq9ddfl8ViUWRkpEJCQrR69WqzSwPcTpKkC8pZ0NeV4y9cOR/5h5l9AHBxW7duVXh4+LW9qp06ddInn3yiIkWKmFwZAJhr06ZNioiI0MGDByWl/fs4atQoBQUFmVwZ4PoSJV12wDjeknwcMA4yYmYfAFxUUlKSBg4cqCZNmuiPP/5QmTJltHLlSn3xxRcEfQCQ1LRpU+3atUuvvvqqLBaLpk6dqpCQEH377bdmlwa4tCQ5JujryjjM8OcPwj4AuKDdu3erYcOGGjJkiFJTU/V///d/2rt3L42oAOA6fn5+Gj16tDZu3KgqVaro2LFjeuihh9S1a1fFxcWZXR7gcuySEm7w2pzISAVbLNrx22+Zvv5oixZqHBKS4fsJyrypH/KGsA8ALiQlJUXDhg1TgwYNtGvXLhUvXlzz58/X3LlzVaxYMbPLAwCn1bx5c+3atUsvv/yyJGnKlCkKDQ3Vd999Z3JlgGu55GLjFmaEfQBwEfv371ezZs30zjvvKDk5WU888YT27dunZ555xuzSAMAl+Pv769NPP9X333+v2267TX///bceeOAB9ejRQxcuXDC7PMDppSrnzficYezCirAPAE7Obrfr008/Vd26dbVlyxYVKVJEM2bM0NKlS1WqVCmzywMAl9OiRQvt3r1bPXv2lCRNnDhRYWFh+v77702uDHBu+b23nr37jkXYBwAndvjwYd1///3q3bu3EhIS1LJlS+3du1cdO3aUxWIxuzwAcFkBAQH67LPPtG7dOlWqVEmHDx/Wfffdp169eik+Pt7s8gCnlJLN4+LOn9fpU6cyfKQkJztkfGQPYR8AnJBhGPriiy8UGhqqDRs2yM/PTxMmTNC3336rChUqmF0eALiN++67T3v27FG3bt0kSePHj1dYWJg2btxocmWAczGU/SZ6rVq2VJWSJTN8bNm8Ocvz7FeuA8fwMLsAAEB6MTEx6tKli77++mtJUrNmzRQZGakqVaqYXBkAuKfAwEBNnDhRTz31lDp16qRDhw6pRYsWeuWVVzR06FD5+/ubXSJgupx0y/94/HhVrV49w/f7v/667KlZ78y3S7LlrDTcAGEfAJyEYRiaN2+eevXqpbNnz8rb21sffvihXn31Vdls/NgDgPz2wAMPaO/evXr99df1xRdf6NNPP9XXX3+t6dOnq1mzZmaXBxSo1NRUnThxQseOHdOxY8d0OSVFjzz7bLbOrd+woeo2aJDh+8FFi+rMqVNZnsvMvuMQ9gHACcTGxqpHjx5atGiRJKl+/fqaOXOmatWqZXJlAFC4FClSRFOmTNHTTz+tzp076+DBg7r77rv16quvasiQIfLz8zO7RCDPLl++rJiYmGtBPjo6OsPX//zzj1L/NQsfWqdOtsN+XtCRyHEI+wBgsqVLl6pbt246efKkPDw8NHDgQL399tvy9PQ0uzQAKLQeeugh7d27V3369NG0adM0evRorVy5UpGRkWrSpInZ5QE3FB8fn2WIP3bsmGJjY7M1ls1mU9myZVWuXDlVqVpVhmHke4Ngmso5DmEfAExy7tw59e7dWzNnzpQk1a5dWzNnzlS9evVMrgwAIElBQUGaOnWqnnrqKXXp0kUHDhxQs2bN9Prrr2vw4MHy9fU1u0QUIoZh6MyZM1mG+GPHjikuLi5b4/n4+KhcuXIqX768ypcvn+nXpUqVSreV8IJytnc/p6xiZt+RCPsAYIJvv/1WL774oqKjo2W1WvXGG2/o/fffl7e3t9mlAQCu88gjj2jv3r167bXXNGPGDH388cdasWKFIiMjddddd5ldHtzA1f3xWYX46OhoJSYmZmu8IkWKZBniy5cvr2LFiuV4lt5DUlIufn05GR+Ow+8nABSg+Ph4vfHGG5o4caIkqWrVqpoxYwZLQgHAyRUtWlSRkZF6+umn1bVrV+3fv19NmzZV37599f7778vHx8fsEuGkkpKSbrg//up/x8TEpNsfn5WSJUtmCO7//u9y5copMDAwX34tXsrfsO+Vj2MXRhbDMGh4CAAF4Mcff1RERIT++usvSdLLL7+sYcOG8UgnAHAxZ86cUe/evTV79mxJUs2aNTVjxgzdeeedJleGghYfH3/D2firX588eTJbY1mtVpUtWzbL2fiyZcuavgowXlL2bkvkjE1SQD6MW5gR9gEgnyUmJmrAgAH65JNPZBiGKlasqOnTp+u+++4zuzQAQB4sW7ZM3bp104kTJ2S1WtWvXz+9++67uQpjhtL2QhtK27PM3mVzGYahs2fP3rTR3fnz57M1nre3d5Yhvly5cipVqpQ8PJx/4bVdaXv3HS1QNOdzNMI+AOSjX3/9VeHh4fr9998lSS+++KI++eQTBQUFmVwZAMARTp8+rVdeeUVz586VlNZsNTIyUg0yecb49VKVtiQ6RZk3PbMqbc+tl9JmPeEYqampOnnyZJYhPjo6WgkJCdkar0iRIjdtdFe8ePF872JfkJIkZe93J3t8xRL+/EDYB4B8kJSUpCFDhmjo0KFKTU1V6dKlNWXKFD322GNmlwYAyAdLlixR9+7ddfLkSdlsNr399tsaOHCgvLwyRhi7pEvK2VJomyQ/MfN5M1f3x2fV6O6ff/5RSkpKtsYrUaJEpiH+6n+XK1dORYoUyedflXNKlHTZAeN4S6LjRf4g7AOAg+3Zs0fh4eHasWOHJKldu3b67LPPVLx4cZMrAwDkp1OnTqlXr1766quvJEmhoaGKjIxM90jVvM6IFuYZ0IsXL2ba3O7fX584cSJbY1mtVpUpUybLRndly5al8eJN8OfZuRH2AcBBUlNT9fHHH2vQoEFKSkpS8eLFNWHCBD377LNmlwYAKEALFy5Ujx49dOrUKXl4eOidd95R//79ZffyYiY0E4Zh6Ny5c1mG+GPHjuncuXPZGs/Ly+umj51zlf3xroCVKs6LsA8ADvDnn38qPDxcv/zyiyTp8ccf1+TJk1W6dGmTKwMAmOHkyZPq2bOnFi5cKEl657339Oa77zpsfFeZEbXb7df2x2e1Rz67++MDAgJUoUKFLPfIlyhRwq32x7sKelA4H8I+AOSB3W7X+PHj1a9fPyUkJKhIkSIaO3aswsPDeaMBAND8+fM1dPhwrd60ST4+Pjf82XAoKkpjR4zQ92vX6nhMjLy8vFQrNFStn31WEV27ytfXN8M5ZncvT0pK0j///JNliI+JicnR/vibNborrPvjXQ1Pl3AOhH0AyKUjR47ohRde0Pfffy9JatmypaZOnaqKFSuaXBkAwJmcuXxZ8vCQzZb5fOaaVasU8cwz8vL2VruOHVUrJERJSUn65aeftHzRIrWPiNDYyZMznJefzyW/uj8+q0Z3J0+eVHaihNVqVenSpbNsdFe2bNlMb2gAyD3CPgDkkGEYmjZtml577TVduHBBfn5+GjlypLp37y6rld1nAID/SZUUn8Xrhw8dUrOwMJUtX17L169X6TJl0r3+18GDWrNqlXr07p3p+QHK2ZLoq/vjswrx0dHROnv2bLbG8/LyuulsfOnSpdkfD5iAsA8AORATE6MuXbro66+/liQ1bdpUkZGRqlq1qsmVAQCcUYLS9jHfSJ8ePTRt4kSt2bRJjZo0yfH4Xkrbvy+lbS2LjY29aaO7S5cuZWvsgICAmza6Y3884LwI+wCQDYZh6KuvvtJLL72ks2fPysvLSx9++KFee+21Gy7LBADggjJvVnZVrfLl5eXtrZ1RUbka/8Q//+jFZ565tj8+OTk5W+cVL148yxDP/njA9bGeBgBu4tSpU3rppZe0YMECSVK9evU0c+ZM1a5d2+TKAADO7GqTshuJi4tTTHS0HmnVKtfXKFmqlHbu3KmLFy9KkiwWi8qUKZNliGd/PFA4EPYBIAvLly9Xly5ddPLkSXl4eGjAgAF655135OnpaXZpAAAnl1XQl6QLcXGSpIDAwFxfw2q1auGSJQoODFS5cuVUunRpfkYBkETYB4BMnTt3Tq+++qpmzJghSapdu7ZmzJih+vXrm1wZAMBV3GyvbOCVZfLxFy7k6TotH3iAN/UAMqBtNABc57vvvlNoaKhmzJghi8WiN998U7/99htBHwCQIzdrW1ekSBGVKVtWv+/dm6/XAVA4EfYB4Ir4+Hj17NlTDzzwgI4dO6YqVaroxx9/1EcffSQfHx+zywMAuJjsvNF+6LHHdCgqSlt//jlfrwOg8OHfBgCQ9NNPP+mOO+7QhAkTJEk9e/bUrl271LRpU5MrAwC4Kotu/ma795tvyt/fX6907qyTJ05keP1QVJQ+Hzv2hudbxcw+gMyxvQdAoZaYmKiBAwdq1KhRMgxDFSpU0LRp09SyZUuzSwMAuAEPSUlZvH5blSqaMneuXmzbVg1r1lS7jh1VKyRESUlJ2rp5s5YuWKD2ERFZjg8AmbEYhnGz3iEA4JZ+++03dezYUb///rsk6YUXXtDo0aMVFBRkcmUAAHeRKik+G8dFHTigT0eO1Pdr1+p4TIy8vb1VOyxMbdq1U3iXLvL29s70vABJNkcWDMBtEPYBFDrJyckaMmSIPvzwQ6WmpqpUqVKaMmWKHn/8cbNLAwC4oXilhX5Hsykt7ANAZlj5A6BQ2bt3rzp27KgdO3ZIkp599llNmDBBxYsXN7kyAIC78pN0QZJhGLJYHLfD3s9hIwFwRzToA1AopKamasSIEapfv7527NihYsWK6csvv9RXX31F0AcA5CurJFtSkkODvq94Iw8gayzjN5EhyX7l89VurXRTBRzvwIEDCg8P189XHmv02GOPacqUKSpdurTJlQEACgO73a7/+7//U4WqVTXwww/zPMPvLYkHwgK4GcJ+AUtVWkfWFKUF/etZlba3wks0WwHyym63a8KECXrzzTeVkJCgwMBAjR07VhEREQ6dXQEAICvvvvuuBg8eLA8PD23fu1cVa9TI9Vi+SnufCAA3w579AmKXdEk3b85iV9rNgCSlhX0/sUQLyI0jR47oxRdf1Pr16yVJ9913n6ZNm6ZKlSqZXBkAoDCZM2eOBg8eLEmaNGmSQmvUyPb7wn/jfSGAnOLfiwKQpLSmLDntwpp65bysns0KID3DMDR9+nSFhoZq/fr18vX11Weffaa1a9cS9AEABWrz5s168cUXJUlvvvnmta+tSuuiH6C0WfobvSG3Xnn96rG8cQeQEyzjz2eJki47YBz2ZgE3988//6hr165auXKlJKlx48aaMWOGqlWrZnJlAIDC5tChQ2rUqJFiY2PVunVrLVq0SFbrjeM6vZwAOBo3CPNRkhwT9HVlHGb4gRv76quvFBISopUrV8rLy0sfffSRfvzxR4I+AKDAnT9/Xo899phiY2NVt25dzZ49O8ugL6UFe5vS9tjaRNAHkHeE/Xxil5SQyffnREYq2GLRjt9+y/S8R1u0UOOQkExfS1DmTf2AwuzUqVNq27at2rVrpzNnzqhu3bratm2b3nzzTdlstLkEABSslJQUtWvXTv/9739VpkwZLV++XP7+/maXBaAQIuznk0suNi7gilasWKGQkBDNnz9fNptN7777rrZs2aKQG9wwAwAgv/Xp00erV6+Wr6+vVqxYofLly5tdEoBCim78+SBVOW/Gl9Oxma9EYXb+/Hm9+uqrioyMlCTVqlVLM2fOVP369c0tDABQqI0fP17jxo2TJM2ePZufSwBMxcx+PsjvvfXs3Udh9t133yk0NFSRkZGyWCzq27evtm3bxhsqAICp1qxZo969e0uShg0bpjZt2phcEYDCjpn9fJCSjWPizp/X6VOnMp6bnOyQ8QF3c/HiRfXr10/jx4+XJFWpUkWRkZFq1qyZyZUBAAq7ffv26dlnn1VqaqrCw8PVr18/s0sCAMK+o119bMrNtGrZ8oav1axdO8tz//1YFqAw2LRpk8LDwxUVFSVJeumllzRixAgaHgEATBcbG6vHHntMcXFxat68uSZNmiSLhXdpAMxH2Hew7HbL/3j8eFWtXj3D9/u//rrsqTff8W8X+/bh/PL6zODExEQNGjRIH3/8sQzDUPny5TVt2jQ98MAD+VEuAAA5kpiYqNatW+vw4cOqUqWKFi9eLG9vb7PLAgBJhH2HM7J5XP2GDVW3QYMM3w8uWlRnMlnef7177rlHhw4eVHBwsIKCghQcHJyjr319fbnrjHyRqrS+EinK/OaXVWn/8Hgp6xtW27ZtU8eOHfXf//5XkhQREaHRo0crODjYsQUDAJALhmGoS5cu2rx5s4KCgrRy5UqVKFHC7LIA4BrCvoMVVHyOO39eMTExiomJydX5np6eub5REBwcrMDAQFmt9HfE/9iV9mjIm61LsSvtZkCS0sK+n9J3Ck1OTtbQoUM1ZMgQpaSkqFSpUpo8ebKeeOKJfKkbAIDc+PDDDzV79mzZbDYtXLhQt99+u9klAUA6hH0HK4j4axiGli5ZovPnzunclY/z589n+2u73a7k5GTFxsYqNjY2VzVYLBYVKVIkVzcKrn7t6enp4N8ZmCVJUkIuzkuVdEGSr9Jm+vft26eOHTtq+/btkqSnn35an3/+OTMlAACnMn/+fA0cOFCS9Nlnn6llFr2YAMAshH0Hu7ovObt793PDZrGo8m235epcwzAUHx+f7iZATm4WnD17VklJSTIMQ+fPn9f58+d15MiRXNXi5+eXp9UFbEVwDomSLudxjARJP/z4ox5t2VJJSUkqWrSoJkyYoLZt2/L/GADgVLZu3arw8HBJ0quvvqru3bubXBEAZI6wnw88lDbTmZ/j55bFYlFgYKACAwNVvnz5XI2RmJiYo5UE138dHx8vSbp06ZIuXbqUp60Iub1RwFYEx0hS3oP+VXc2b662HTrozIkTmjJlisqUKeOgkQEAcIy///5bTzzxhBITE/Xoo4/q448/NrskALghwn4+8FL+hn2vfBw7O3x8fOTj46NSpUrl6vyUlBTFxcXl6kbB9VsRTp06pVPZaGiYmX9vRcjNTYOgoCB5eZn9f8M8dt186f6hqCiNHTFC369dq+MxMfLy8lKt0FC1fvZZRXTtKl9f32vHGoahMZMmKchmk43ZfACAk7lw4YIef/xxnThxQqGhoZo3b55sNp6NBMB5WQzDyG4DeeRAvG7eqCw3bJIC8mFcV5LZVoScfn35smPmo/38/PK0usCVtyLc7M/4mlWrFPHMM/Ly9la7jh1VKyRESUlJ+uWnn7R80SK1j4jQ2MmTM5zHn3EAgLNJTU1V69attXLlSpUqVUpbtmxRpUqVzC4LALJE2M8ndqU1HnO0QBVME0B39++tCDm9UfDvrQh55eHhkacmh0WKFDFlK0Kq0sL+jRw+dEjNwsJUtnx5LV+/XqWvW5L/18GDWrNqlXr07p3p+QHK+rF8AAAUpNdff12ffPKJvL29tXHjRjVq1MjskgDgpgj7+Si3Hcpv5GrHcpjPUVsR8urqVoTcri7I7VaEBGW9VaVPjx6aNnGi1mzapEZNmuR4fC+l/XkHAMBskydPVrdu3SRJX375pdq2bWtyRQCQPYT9fOaITuWS5C3JxwHjwDk401YEX1/fHN8oqNGggTyyuElQq3x5eXl7a2dUVK5qsiptFQsAAGZat26dHn74YaWkpOj999/XoEGDzC4JALKNsF8A8jrDz4w+MpOXrQjnz5/XhQu522gSEBCgv8+fv+H2gbi4OFUMCtIjrVpp7tKluf71FVHaoywBADDD/v37ddddd+ncuXNq3769Zs+e7bJ9dgAUTnTjLwBeSvuNvqScNe2zSfITe/SROUc9FSGnNwpuKVMmyz4BF+LiJEkBgXmbm7eLffsAAHOcPn1ajz76qM6dO6fGjRtr6tSpBH0ALoewX0CsSms6lqq0mf4UpYWZzI7zUNoNAoIO8pOHh4eKFSumYsWK5ei8FEkXs3g9sEgRSVJ8LlcOXMWSIwCAGZKSktSmTRtFRUXp1ltv1dKlS+Xjw2ZKAK6HsF/AbPpf4zFDaYHfUNpyZatYtgznd7M/o0WKFFGZsmX1+969+XodAAAczTAMde/eXT/88IMCAwO1YsUK3XLLLWaXBQC5wgpxE1mUFv49rnwm3MAVZOcfjYcee0yHoqK09eef8/U6AAA40siRIzV9+nRZrVbNnz9fISEhZpcEALnG+2kAOXJ1FUpWer/5pvz9/fVK5846eeJEhtcPRUXp87Fjb3g+q1wAAAVtyZIleuuttyRJY8eO1cMPP2xyRQCQNyzjB5BjHkrrPXEjt1Wpoilz5+rFtm3VsGZNtevYUbVCQpSUlKStmzdr6YIFah8RkeX4AAAUlO3bt6tDhw4yDEM9e/ZUr169zC4JAPKMR+8ByLFUSfHZOC7qwAF9OnKkvl+7VsdjYuTt7a3aYWFq066dwrt0kbe3d6bnBYgGlQCAghEdHa2GDRsqJiZGDz74oFatWiUPD247A3B9hH0AuRKvnD1KMjtSUlJ0+sQJVStblkccAQDy3cWLF3X33Xdr+/btqlWrljZv3qygoCCzywIAh2DPPoBc8XPweIZhKDkpSQ82a6annnpKp06dcvAVAAD4H7vdrueff17bt29XiRIltGLFCoI+ALdC2AeQK1b97zGSjmCxWPTLhg2KiY7WkiVLFBoaqm+++caBVwAA4H/69++vJUuWyMvLS0uXLlXlypXNLgkAHIqwDyDXvCRlvus+57wltX7kEW3ZskU1a9bU8ePH9cgjj6hnz566dOmSg64CAIAUGRmp4cOHS5KmTp2qpk2bmlwRADgeYR9Anvgo7zP8vlfGkaS6detq27ZteuWVVyRJEyZMUL169fTbb7/l8SoAAEgbN25U165dJUkDBgxQhw4dTK4IAPIHDfoAOIRd0iXlrGmfTWl7/29013Ht2rWKiIhQTEyMPDw89O677+qtt96iSzIAIFcOHjyoRo0a6cyZM3rmmWf05Zdfympl7guAeyLsA3CoVElJklKUdgPgelZJHkrbApCdx+udOXNG3bt314IFCyRJjRs31qxZs1SlShUHVQwAKAzOnj2rxo0ba//+/brzzju1YcMG+fk5ut0sADgPwj6AfGMoLfAbkixKC/q5eaCeYRiaPXu2evXqpbi4OPn7+2vMmDHq1KkTj+gDANxUcnKy/vOf/2jdunWqUKGCtm7dqtKlS5tdFgDkK9YtAcg3FqXN3ntc+ZzbWG6xWPT8889r9+7duueee3Tx4kV16dJFTz75pE6ePOmwegEA7scwDPXq1Uvr1q2Tv7+/VqxYQdAHUCgQ9gG4jEqVKmndunUaMWKEPD09tWzZMoWGhmrVqlVmlwYAcFJjxozR5MmTZbFYNG/ePNWpU8fskgCgQLCMH4BL2rVrl5577jnt27dPktStWzeNGjVK/v7+JlcGAHAWK1asUKtWrWQYhkaNGqU+ffqYXRIAFBjCPgCXlZiYqHfeeUejR4+WJFWrVk2zZs1So0aNTK4MAGC2Xbt2qWnTpte2fk2aNIk+LwAKFcI+AJe3bt06RURE6NixY7LZbBowYIAGDBjAI/oAoJA6fvy4GjZsqKNHj+q+++7T6tWr5enpaXZZAFCgCPsA3MLZs2fVs2dPzZs3T5LUsGFDzZ49W9WqVTO5MgBAQUpISFCLFi20detWVa9eXb/88ouKFi1qdlkAUOBo0AfALRQtWlRz587VnDlzFBQUpK1bt+qOO+7QpEmTxD1NACgc7Ha7IiIitHXrVhUrVkwrV64k6AMotAj7ANxK+/bttWfPHt177726dOmSunfvrieeeEInTpwwuzQAQD577733NH/+fHl6emrx4sWs7gJQqBH2AbidChUq6LvvvtOoUaPk5eWllStXKjQ0VMuXLze7NABAPpkzZ44++OADSdKkSZN0zz33mFwRAJiLPfsA3NqePXv03HPPac+ePZKkzp07a/To0QoICDC5MgCAo2zatEn33XefkpKS1K9fPw0fPtzskgDAdIR9AG7v8uXLGjBggEaNGiXDMFSlShXNmjVLjRs3Nrs0AEAeHTp0SI0aNVJsbKxat26tRYsWyWpl8SoAEPYBFBobNmxQx44ddfToUVmtVr3zzjsaNGgQj2MCABd1/vx5NWnSRP/9739Vt25d/fjjj/L39ze7LABwCoR9AIXKuXPn1KtXL82ZM0eS1KBBA82ePVs1atQwuTIAQE6kpKToscce05o1a1S2bFlt3bpV5cqVM7ssAHAarHECUKgEBwdr9uzZ+vLLL1W0aFH99ttvqlu3riZMmMAj+gDAhbz22mtas2aN/Pz8tHz5coI+AFyHmX0AhVZ0dLQiIiL03XffSZL+85//aOrUqSpTpozJlQEAsvLZZ5/p5ZdfliQtXrxYTz75pMkVAYDzYWYfQKFVrlw5rVmzRmPGjJG3t7e++eYbhYaGasmSJWaXBgC4gdWrV6t3796SpOHDhxP0AeAGmNkHAEn79u1Thw4dtHPnTknSCy+8oLFjxyowMNDcwgAA1+zbt09NmjRRXFycIiIiNG3aNFksFrPLAgCnRNgHgCuSkpI0aNAgjRgxQoZh6LbbbtPMmTPVrFkzs0sDgELv5MmTatSokQ4fPqy7775ba9eulZeXl9llAYDTIuwDwHV+/PFHPf/88zpy5IisVqv69eun9957jzeVAGCSxMRE3X///dq8ebOqVKmiX375RSVKlDC7LABwauzZB4DrNG/eXLt371Z4eLjsdruGDRumxo0b6/fffze7NAAodAzDUOfOnbV582YFBwdr5cqVBH0AyAbCPgBkokiRIoqMjNTChQtVrFgxbd++XfXq1dO4ceNkt9vNLg8ACo0PP/xQc+bMkc1m08KFC3X77bebXRIAuASW8QPATcTExOjFF1/UmjVrJEkPPvigpk+frrJly5pcGQC4t/nz56tt27aSpEmTJqlr164mVwQAroOZfQC4ibJly+qbb77RuHHj5OPjo2+//VahoaFauHCh2aUBgNvasmWLwsPDJUmvvfYaQR8AcoiZfQDIgd9//10dOnTQ9u3bJUkdO3bUp59+qqCgIJMrAwD38ffff6thw4Y6ceKEHn30US1btkw2m83ssgDApTCzDwA5ULNmTf3888/q37+/rFarZs6cqTp16uiHH34wuzQAcAsXLlzQ448/rhMnTigsLEzz5s0j6ANALhD2ASCHvLy8NGTIEP3www+67bbbdOTIEbVo0UL9+vXT5cuXzS4PAFxWamqq2rdvr927d6tUqVJasWKFAgMDzS4LAFwSYR8Acqlp06batWuXXnzxRRmGoREjRqhRo0bat2+f2aUBgEt64403tHLlSvn4+GjZsmWqWLGi2SUBgMsi7ANAHgQGBmrq1KlasmSJSpQooV27dql+/foaM2YMj+gDgByYNGmSRo8eLUmaMWOGGjVqZHJFAODaaNAHAA5y/Phxvfjii/rmm28kSffff78iIyNVvnx5kysDAOf23Xff6eGHH1ZqaqoGDx6sgQMHml0SALg8wj4AOJBhGJo0aZL69OmjhIQEBQcH6/PPP1e7du3MLg0AnNIff/yhu+66S+fPn9dzzz2nWbNmyWKxmF0WALg8wj4A5IM///xTHTp00K+//ipJat++vcaPH6/g4GBzCwMAJ3L69Gk1atRIUVFRatKkidatWycfHx+zywIAt8CefQDIB9WrV9emTZs0aNAgWa1WzZ07V2FhYfr+++/NLg0AnMLly5fVpk0bRUVF6dZbb9WSJUsI+gDgQIR9AMgnnp6eev/997Vp0yZVqVJFR48e1f3336++ffvyiD4AhZphGOrWrZt++OEHBQYGauXKlbrlllvMLgsA3AphHwDy2V133aWdO3eqS5cuMgxDo0aN0p133qk9e/aYXRoAmGLEiBGaMWOGrFar5s+fr9q1a5tdEgC4HcI+ABSAgIAATZ48WcuWLVPJkiW1Z88eNWjQQKNGjeIRfQAKlcWLF+utt96SJI0dO1YPP/ywyRUBgHuiQR8AFLATJ06oc+fOWrlypSSpRYsWmjFjhipWrGhyZQCQv7Zt26bmzZsrISFBvXr10rhx48wuCQDcFmEfAExgGIa++OILvfrqq7p06ZKCgoI0YcIEtW/f3uzSACBfREdHq2HDhoqJidFDDz2klStXysPDw+yyAMBtEfYBwEQHDhzQ888/ry1btkiS2rVrpwkTJqho0aImVwYAjnPx4kU1b95cO3bsUK1atbR582YFBQWZXRYAuDX27AOAiapVq6affvpJ77//vmw2m7788kuFhoZq3bp1ZpcGAA5ht9vVoUMH7dixQyVKlNDKlSsJ+gBQAAj7AGAyDw8PDRo0SJs3b1a1atUUHR2tli1b6rXXXlNCQoLZ5QFAnrzzzjtaunSpvLy8tHTpUt12221mlwQAhQJhHwCcRMOGDbVjxw716NFDkjRmzBg1aNBAO3fuNLcwAMil6dOn66OPPpIkTZs2TU2bNjW5IgAoPAj7AOBE/P39NWHCBK1atUqlSpXSf//7XzVs2FAjRoxQamqq2eUBQLZt3LhR3bp1kyQNHDhQzz33nMkVAUDhQoM+AHBSsbGx6tKli5YtWyZJuvvuuzVjxgzdeuut5hYGADdx4MAB3XXXXTpz5oyeffZZzZs3T1Yrc0wAUJAI+wDgxAzD0PTp09W7d2/Fx8crMDBQn332mZ5//nlZLBazywOADM6ePau77rpLf/75pxo2bKgNGzbI19fX7LIAoNAh7AOAC/jrr7/0/PPPa/PmzZKkp59+WhMnTlTx4sVNrgwA/ic5OVkPP/yw1q9frwoVKmjr1q0qXbq02WUBQKHEeioAcAGVK1fWxo0bNWTIEHl4eGjhwoUKDQ3Vt99+a3ZpACApbSVSr169tH79egUEBGjlypUEfQAwEWEfAFyEh4eH+vfvr59//lk1atTQP//8o4ceekivvPIKj+gDYLrRo0dr8uTJslgsmjdvnsLCwswuCQAKNcI+ALiYBg0aaPv27erZs6ckady4capfv762b99ucmUACqsVK1aob9++kqRRo0bpscceM7kiAAB79gHAha1evVovvPCCjh8/Lg8PDw0ePFhvvvmmbDab2aUBKCR27dqlpk2b6uLFi+ratasmTpxIA1EAcAKEfQBwcadOnVK3bt20ePFiSVLTpk01a9Ys3XbbbSZXBsDd/fPPP2rUqJGOHj2q+++/X9988408PT3NLgsAIJbxA4DLK1GihBYuXKjIyEgFBgZq06ZNCgsL0/Tp08X9XAD5JSEhQa1atdLRo0dVo0YNLViwgKAPAE6EmX0AcCOHDh1Sx44d9dNPP0mSnnzySU2ePFklSpQwuTIA7sRut6tdu3ZasGCBihUrpi1btqhq1apmlwUA+Bdm9gHAjdx2223asGGDhg0bJk9PTy1ZskShoaH65ptvzC4NgBt59913r83kL168mKAPAE6ImX0AcFM7duzQc889p99//12S9NJLL2nkyJHy8/MzuTIAzsiQZL/y2aK0GaHM2uzNnj1bzz//vCRp2rRpeuGFFwqsRgBA9hH2AcCNJSQk6O2339bYsWMlSdWrV9fs2bN15513mlwZAGeQKilJUorSgv71rJI8JHlJsknatGmT7rvvPiUlJalfv34aPnx4wRULAMgRwj4AFAJr165VRESEYmJi5OHhoUGDBuntt9+Wh4eH2aUBMIFd0iWlhf3sSrp0SQ82b66d27frySef1MKFC2W1siMUAJwVYR8ACokzZ86oR48emj9/viSpcePGmjVrlqpUqWJyZQAKUpKkhFycl5KSouSkJI0fNUpv9ekjf39/R5cGAHAgwj4AFCKGYWjOnDnq2bOn4uLi5O/vrzFjxqhTp06yWDLbnQvAnSRKupyH8w3DkMVikbckHwfVBADIH4R9ACiEjhw5ovDwcG3cuFGS9MQTT2jKlCm65ZZbTK4MQH7J7Yz+jfgqbS8/AMA5sdEKAAqhSpUqad26dRoxYoQ8PT21fPlyhYaGauXKlWaXBiAf2HXzoH8oKkqvduumOpUrq5SPjyoUKaKHmjbV52PHKiEh49kJyrypHwDAOTCzDwCF3K5du9ShQwft3btXktS1a1d98skn7McF3Ei8sm7Gt2bVKkU884y8vL3VrmNH1QoJUVJSkn756SctX7RI7SMiNHby5Azn2SQF5FfRAIA8IewDAJSYmKj+/fvrk08+kSRVrVpVs2fPVqNGjUyuDEBepSot7N/I4UOH1CwsTGXLl9fy9etVukyZdK//dfCg1qxapR69e2d6foDSQj8AwLkQ9gEA16xfv17h4eE6duyYbDabBgwYoP79+8vT09Ps0gDkUoLS9uvfSJ8ePTRt4kSt2bRJjZo0yfH4Xkrbvw8AcC6EfQBAOmfPnlXPnj01b948SVLDhg01e/ZsVatWzeTKAOTGBWW9t75W+fLy8vbWzqioXI1vlRSYqzMBAPmJBn0AgHSKFi2quXPnau7cuQoKCtLWrVt1xx13aNKkSeL+MOBaDGUd9OPi4hQTHa1aoaG5vob9ynUAAM6FmX0AwA0dPXpU4eHh+v777yVJjz76qKZOnapSpUqZXBkASUpJSdH58+d17tw5nTt3TmfPnr329blz5+Tl46PwXr1ueH70sWOqXaGCnu3QQZNnzcp1HezbBwDnQ9gHAGTJbrdr7Nixevvtt3X58mWVKFFCX3zxhVq1amV2aYDLs9vt6cL6vz+uD+6ZvRYfn1XrPal+w4Zat2XLDV+Pi4tTxaAgPdKqleYuXZrrX4e/JI9cnw0AyA+EfQBAtuzdu1fPPfecdu/eLUnq1KmTRo8ercDAnO/Wvbq02JBkUdqeMosDawUKimEYunDhQrZCembfj4uLc8j2mICAAAUHB1/7KFq0qIKDg3V77drq2a9flufWLFdOPr6+2nHwYO6vL2b2AcDZEPYBANl2+fJlDRw4UB9//LEMw1DlypU1e/ZsNW7c+KbnpiqtI3iKMt9DbFXazKCXCA0oOIZh6NKlSzkK6P9+7fz587Lbs9oVnz2+vr7XAvr1Hzf6/tXXgoKC5OGR+by6ISnuJtd+tVs3RU6erG83b1bDbPxdzkwRccMOAJwNYR8AkGMbN25Ux44d9ffff8tqteqdd97RoEGDMn1En13SJaWF/eyySfITXWRxc4ZhKDExMdshPbPvp6Sk5LkOLy+vDKE8u+E9KChI3t7eDvjdyNzNuvEfiopSszp1VKFSJS1fv163XNeT41BUlFavXKkevXtnej7d+AHAORH2AQC5cv78efXq1UuzZ8+WJDVo0ECzZ89WjRo1rh2TpLRnfOeWr9Jm+uHekpKSchzQ//39pKSsniKfPR4eHjkK6Ne/5uPj44DfifyRoLS/i1n5evlyvdi2rXx8fdWuY0fVCglRUlKStm7erKULFqh9RITGTJqU6bleSvu7CgBwLoR9AECezJ8/X927d9fZs2fl6+urkSNH6qWXXtJli0WXHTC+tyTnjVGQpOTk5AxN5rLTXO7qR0JCXm4JpbFarTkO6P/+bz8/P1ks7rkQPVVS1m380kQdOKBPR47U92vX6nhMjLy9vVU7LExt2rVTeJcuN1x9wH59AHBOhH0AQJ5FR0frhRde0Nq1ayVJH40erW6vvuqw8Znhz1+pqamKi4vL9ez6xYsXHVJHUFBQrmbXixYtqoCAALcN644Qr5xtpcmOlJQUGcnJKuHLvD4AOCPCPgDAIex2uz777DN9NmGCftixQz4+PjcMX4eiojR2xIhrM4heXl6qFRqq1s8+q4iuXeWbSXgIFHv4b8Rut2foCJ+T4B4Xd7MWbtkTGBiYo4D+7/8ODAyUzcb8cH6xK23vvqMYhqHEhAQ90Lix+r/9ttq1a+fA0QEAjkDYBwA41In4eHn4+NywO/iaVasU8cwz8vL2Trc3+JefftLyRYvUPiJCYydPznCeTWnLhd2RYRi6ePFijpe/X/1wVEd4Pz+/HIf0fzeZu9H/cziHvPbQuN7ooUP1fv/+kqTw8HCNGzcuV4/iBADkD8I+AMBhbrY3+PChQ2oWFqay5ctr+fr1Kl2mTLrX/zp4UGtWrbph129n3RtsGIYSEhJy1Vzu6kdqat4XWfv4+OR4+fu/w7qXF5sl3F2i5LBeGrbkZH3wwQf68MMPZbfbVaVKFc2ZM0eNGjVywBUAAHlF2AcAOMzNun736dFD0yZO1JpNm9SoSZMcj5+fXb8vX76cq+ZyVz8c1RH+agDPSXO5qx/O3BEezsPRT8n48ccf1aFDB/3999+y2Wx6//339dZbb7EtAwBMRtgHADjMzZ7nXat8eXl5e2tnVFSuxs/qed7Jyck5Duj//n5iYmKuavo3m82W44D+7+/7+vrSZA4Fwi7pknLWtM8myU+Z9844d+6cevTooS+//FKS1Lx5c82ePVsVK1bMc60AgNwh7AMAHMKQlFWbt7i4OFUMCtIjrVpp7tKlubuGYej1zp114sSJDMHdER3hLRbLtY7wudm3Tkd4uJpUpc30pyjzG3VWSR5Km8m/2Ty9YRiaNWuWevbsqfj4eAUFBWnSpElq27atY4sGAGQLnXQAAA5xs/ZwF650fA/IQwMvi8WiX7dt055du254TGBgYK4e3RZ8pSO81UrPfxQeNv1va4yhtL/HhiSL0oJ+Tm5dWSwWdezYUU2bNtVzzz2nLVu2qF27dvrmm29o3gcAJmBmHwDgECmSsppbd8TMviQtmzNHyYmJmQb3IkWK0BEecALJyckaPHiwhg4deq1539y5c9WwYUOzSwOAQoOwDwBwiJt14pekmuXKycfXVzsOHsz1dZy1Iz+AjGjeBwDmYa0iAMAhsvMD5aHHHtOhqCht/fnnfL0OAOfQvHlz7dq1S23btlVqaqoGDBig++67T3///bfZpQGA2+M9EwDAIa7u8c1K7zfflL+/v17p3FknT5zI8PqhqCh9PnbsDc/P6R5iAOYLDg7WvHnzFBkZqYCAAP3www+qU6eO5s+fb3ZpAODWWMYPAHCYBKV19s7K18uX68W2beXj66t2HTuqVkiIkpKStHXzZi1dsEDtIyI0ZtKkTM/10v+aiQFwPVFRUdea90lSRESEPv30U5r3AUA+IOwDABwmO/v2JSnqwAF9OnKkvl+7VsdjYuTt7a3aYWFq066dwrt0kbe3d6bnsV8fcH3Jycl6//33NXToUBmGQfM+AMgnhH0AgEPFKy30O5pNaWEfgHv44Ycf1KFDBx09elQeHh56//331a9fP5r3AYCDEPYBAA5ll3RBkgxDsjhuh32gaDQDuJuzZ8+qe/fu1/bv33333Zo9e7YqVKhgcmUA4Pp43wQAcCirJI/kZIcGfV/xAwtwR0WLFtWXX36p6dOny9/fXz/88IPCwsK0YMECs0sDAJfHeycAgEPZ7Xa92KGDPujfX5KU1wVk3kprzAfAPVksFkVERGjnzp1q2LChzp07p2effVYvvvii4uOz0wUEAJAZlvEDABzGMAz17t1b48aNk6enp7bu3KnbatXK9Xi+IugDhcn1zfuqVq2quXPn6s477zS7NABwOczsAwAcZvjw4Ro3bpwkaebMmbqjVi0FKucd9G1K26NP0AcKF09PTw0ZMkQbNmxQhQoVdPDgQTVp0kTDhg1Tamp+tP4EAPfFzD4AwCGmT5+uF198UZI0evRovfrqq+leT5WUJClFaU38rmeV5KG0gE8vbgDXN++75557NGvWLJr3AUA2EfYBAHm2cuVKtW7dWqmpqXrzzTf10UcfZXm8obTAb0iyKC3oO66dHwB3YRiGIiMj9fLLL+vixYsKDg7W5MmT9cwzz5hdGgA4PcI+ACBPfv75Z91///1KSEhQx44dFRkZKYsDO/EDwMGDB9W+fXv9+uuvkqQXXnhBn376qQICAkyuDACcF2EfAJBrv//+u5o1a6YzZ87oP//5j5YtWyZPT0+zywLghpKTk/Xee+9p2LBhNO8DgGwg7AMAciU6OlqNGzfW0aNH1bBhQ61fv17+/v5mlwXAzW3cuFEdOnTQsWPH5OHhoQ8++EBvvPGGbDa6fQDAvxH2AQA5dvbsWd19993au3evqlevrk2bNqlEiRJmlwWgkDh79qy6deumBQsWSJJatGihmTNn0rwPAP6FR+8BAHIkISFBrVq10t69e1WmTBmtWbOGoA+gQBUtWlRfffWVpk2bJn9/f23YsEF16tTRwoULzS4NAJwGYR8AkG2pqal67rnn9OOPP6pIkSJavXq1br31VrPLAlAIWSwWvfDCC9qxY4caNGigs2fP6plnnlGnTp0UHx9vdnkAYDrCPgAgWwzDUM+ePbVkyRJ5eXlp2bJlCgsLM7ssAIVctWrVtHnzZr399tuyWCyaNm2a6tWrp99++83s0gDAVIR9AEC2DB48WJMmTZLFYtGcOXPUokULs0sCAEmSp6enhg4dqvXr16t8+fI6cOCAGjdurOHDhys1NdXs8gDAFDToAwDc1KRJk9S9e3dJ0vjx4/XSSy+ZXBEAZO7MmTPq1q3btf37LVq00KxZs1S+fHmTKwOAgsXMPgAgS0uXLr0W7gcMGEDQB+DUihUrpvnz52vq1KnXmveFhYVp0aJFZpcGAAWKmX0AwA39+OOPeuCBB3T58mV17txZkydPlsViMbssAMiWAwcOqH379tf273fq1EljxoxRQECAyZUBQP4j7AMAMrV37141b95c586d0xNPPKFFixbJw8PD7LIAIEeSkpL07rvv6qOPPpJhGKpWrZrmzp2rBg0amF0aAOQrwj4AIIO///5bTZo0UXR0tJo0aaK1a9fKz8/P7LIAINc2bNigDh06KDo6Wh4eHhoyZIjeeOMNWa3sagXgngj7AIB0Tp8+rWbNmumPP/5QrVq19OOPP6pYsWJmlwUAeXbmzBl17dr12v79e++9VzNnzqR5HwC3xK1MAMA1ly5d0mOPPaY//vhD5cuX1+rVqwn6ANxGsWLFtGDBAn3xxRfy8/PT999/T/M+AG6LsA8AkCSlpKSobdu2+uWXXxQcHKzVq1erQoUKZpcFAA5lsVjUqVMn7dixQ/Xr19fZs2f19NNPq0uXLrp48aLZ5QGAwxD2AQAyDEPdunXTypUr5ePjo5UrV6p27dpmlwUA+aZ69eravHmz+vXrJ4vFoi+++EL16tXTtm3bzC4NAByCsA8A0IABAzRt2jRZrVZ99dVXatq0qdklAUC+8/Ly0vDhw7Vu3TqVK1dOf/75pxo3bqwRI0bIbrebXR4A5AkN+gCgkBs3bpxeeeUVSdKUKVPUuXNnkysCgIJ3ffO+++67TzNmzKB5HwCXxcw+ABRi8+fPV+/evSVJgwcPJugDKLSub963fv16hYWFafHixWaXBgC5wsw+ABRS33//vR5++GElJSXppZde0meffSaLxWJ2WQBguj///FPt27e/tn+/c+fOGjNmjPz9/U2uDACyj7APAIXQzp07dffdd+vChQt66qmn9NVXX8lms5ldFgA4jaSkJA0cOFAjR46UYRiqXr265s6dq/r165tdGgBkC2EfAAqZQ4cOqUmTJjp+/LjuuecerV69Wj4+PmaXBQBOaf369erYsaOio6Pl6empIUOGqG/fvrJa2Q0LwLkR9gGgEImNjVXTpk114MABhYaG6ocfflBwcLDZZQGAUzt9+rS6du16bf/+fffdp5kzZ6pcuXImVwYAN8YtSQAoJOLj4/Xoo4/qwIEDqlSpklavXk3QB4BsKF68uBYuXKgpU6aka963ZMkSs0sDgBsi7ANAIZCcnKynn35av/76q4oXL641a9aobNmyZpcFAC7DYrGoc+fO2r59u+rVq6czZ86oTZs26tq1qy5evGh2eQCQAWEfANyc3W5Xp06dtGbNGvn5+WnVqlWqUaOG2WUBgEuqUaOGfv75Z7355puyWCyaMmWK6tevr+3bt5tdGgCkQ9gHADf31ltvadasWbLZbFq4cKEaNWpkdkkA4NK8vLz00Ucf6bvvvlPZsmW1f/9+3XXXXRo5cqTsdrvZ5QGAJBr0AYBbGz16tPr06SNJioyMVHh4uMkVAYB7OX36tLp06XJt//7999+vGTNm0LwPgOmY2QcANzV37txrQX/48OEEfQDIB8WLF9eiRYs0efJk+fn5ad26dQoLC9PSpUvNLg1AIcfMPgC4obVr1+rRRx9VcnKyevfurdGjR8tisZhdFgC4tf3796t9+/bX9u937dpVn3zyifz9/U2uDEBhRNgHADezbds2tWjRQvHx8WrXrp3mzJkjq5WFXABQEJKSkjRgwACNHDlSUlpDv3nz5qlu3bomVwagsCHsA4AbOXjwoJo0aaLY2Fjdf//9WrVqlby9vc0uCwAKnXXr1qljx46KiYmRp6enhg4dqj59+nDzFUCBIewDgJs4fvy4mjZtqr/++kt169bVhg0bVKRIEbPLAoBC6/Tp0+rcufO1/fstW7bUjBkzVLZsWXMLA1AocGsRANxAXFycHnnkEf3111+qXLmyvvnmG4I+AJisePHiWrx4sSZNmiRfX1999913Cg0NpXkfgAJB2AcAF3f58mW1adNGO3bs0C233KI1a9aoVKlSZpcFAJBksVjUtWtXbd++XXXr1tWZM2f05JNPqlu3brp48aLZ5QFwY4R9AHBhdrtd4eHhWrdunQICAvT111+ratWqZpcFALjO7bffrp9//ll9+/aVJE2ePFn169fXjh07TK4MgLsi7AOAizIMQ3369NFXX30lT09PLV68WPXr1ze7LADADXh7e2vkyJFau3atypQpo/3796tRo0YaNWqU7Ha72eUBcDOEfQBwUSNGjNDYsWMlSTNmzNADDzxgckUAgOxo2bKldu/erVatWik5OVl9+/bVww8/rJiYGLNLA+BGCPsA4IJmzJiht956S5L0ySef6P/+7/9MrggAkBMlSpTQkiVLrjXvW7t2rcLCwrRs2bJcj2lISpWUcuUzj9wCCjcevQcALubrr7/WE088odTUVL3xxhsaMWKE2SUBAPLgjz/+UPv27a/t3+/WrZs++eQT+fn53fTcVElJSgv4mW0EsErykOQlyeawigG4AsI+ALiQLVu26L777tOlS5f0/PPPKzIyUlYri7QAwNVdvnxZAwYM0McffywpraHf3LlzVbdu3UyPt0u6pLSwn102SX5iaS9QWBD2AcBF7N+/X02bNtXp06f18MMPa/ny5fL09DS7LACAA61du1bh4eH6559/5OnpqWHDhum1115Ld2M3SVJCHq7hq7SZfgDujbAPAC4gJiZGTZo00ZEjR3TnnXdq/fr1CggIMLssAEA+OHXqlDp16qTly5dLkh544AHNmDFDZcqUUaKkyw64hrckHweMA8B5EfYBwMmdO3dOd999t/bs2aNq1app06ZNKlmypNllAQDykWEYmjx5sl577TUlJCSoePHi+vq771Tjjjscdg1m+AH3xpYdAHBiiYmJatWqlfbs2aPSpUtrzZo1BH0AKAQsFou6deumbdu26Y477lBAYKAq1qih6+fp5kRGKthi0Y7ffst0nEdbtFDjkJBMX0tQ5k39ALgHD7MLAABkLjU1Vc8995x++OEHFSlSRKtXr9Ztt91mdlkAgAJUs2ZN/fLLL9p3+LA8PDxksVgcOv4lSWwKA9wTYR8AnJBhGHr55Ze1ePFieXl5admyZapTp47ZZQEATODh7a0qNWrky9ipVz54LB/gfljGDwBOaMiQIfr8889lsVg0Z84ctWjRwuySAAAmSXLx8QGYg5l9AHAyU6ZM0aBBgyRJ48aN09NPP21yRQAAM6Vk45i48+d1+tSpjOcmJztkfACuh7APAE5k2bJl6t69uySpf//+6tmzp8kVAQDMZCh7TfRatWx5w9dq1q6d5bn2K9dxbDcAAGYj7AOAk9i0aZPatWsnu92uTp066YMPPjC7JACAybLbLf/j8eNVtXr1DN/v//rrsqemZus67NsH3AthHwCcwL59+/TYY48pMTFRjz/+uCZOnOjwjssAANdj3PwQSVL9hg1Vt0GDDN8PLlpUZzJZ3p/b6wBwHTToAwCTHT16VA8//LDOnTunxo0b68svv5SHB/diAQAFt7Se28uA+yHsA4CJzpw5o4ceekjHjh1TzZo1tXLlSvn5+ZldFgDASRTUm3VCAeB++HsNACa5dOmSHn/8cf3+++8qV66cVq9erWLFipldFgDAiViU/2/YrWJmH3BHhH0AMEFKSoratWunzZs3Kzg4WKtXr1bFihXNLgsA4ITye2MXG8cA90TYB4ACZhiGunfvrhUrVsjb21vLly9XSEiI2WUBAJyUl4uPD8AcFsMwaL4JAAVo4MCBGjJkiKxWqxYtWqTWrVubXRIAwMnFS7r5A/RyziYpIB/GBWA+ZvYBoABNmDBBQ4YMkSR9/vnnBH0AQLbkV+tWWsIC7ouwDwAFZOHCherVq5ck6b333lPXrl1NrggA4CqsknwdPKavCAOAO2MZPwAUgA0bNuihhx5SUlKSunXrps8//1wWC72PAQA5kyjpsgPG8Zbk44BxADgvwj4A5LNdu3bp7rvvVlxcnJ588kktWLBANpvN7LIAAC4qSVJCHs73FU35gMKAsA8A+ejw4cNq3Lixjh8/rubNm+vbb7+Vjw9zKQCAvLFLuqScNe2zKW2PPkv3gcKBsA8A+SQ2NlbNmjXTn3/+qZCQEP34448KDg42uywAgBtJVdpMf4rSbgBczyrJQ2kz+awpAwoXD7MLAABXYijtzZQhyaK0N1GZ7by/ePGiHnvsMf3555+qWLGiVq9eTdAHADicTf9r3Jfdn1EACgfCPgDcRE5nTZKTk/XMM89o69atKlasmNasWaNy5coVXMEAgELJImbvAfwPYR8AbiC7+yHtSrsZkCTJZhga+NZb+uabb+Tr66tVq1bp9ttvz+9SAQAAgHQI+wCQidx2Ok6y29Xvgw909sIFPdOqle666y5HlwYAAADcFA36AOA6eX2GsWEYslgsPMMYAAAApuHJGwDwL0nKW9CXJIslrR3S5SvjAQAAAAWNsA8AV9iV9dL9OZGRCrZYMv147623Mj0nQZk39QMAAADyE3v2AeCKS9k87p3Bg1XpttvSfa9mSEiW4wbkviwAAAAgxwj7AKC0jvs367p/1QP/+Y/qNmiQ47F5HBIAAAAKCsv4AUD5v7eevfsAAAAoSMzsA4CklBwcG3f+vE6fOpXue8VLlHDY+AAAAEBeEfYBFHqGctZEr1XLlhm+d+4mTzG1X7mOJSeFAQAAALlE2AdQ6OW0W/7H48eravXquboO+/YBAABQEAj7AAq9rOfkM6rfsGGOGvTl9joAAABAbtGgD0ChV1BL61nCDwAAgIJC2AdQ6BXUP4T8gwsAAICCwntPAIWeRfn/j6FVzOwDAACg4BD2AUD538CEBikAAAAoSIR9AJDk5eLjAwAAAP9mMYybPBwaAAqJeEmp+TCuTVJAPowLAAAA3Agz+wBwhZ+LjQsAAADcCGEfAK6wSvJ18Ji+4h9aAAAAFDzegwLAv3hJ8nbQWN5irz4AAADMQdgHgOv4KO8z/L5XxgEAAADMQIM+ALgBu6RLylnTPpvS9uhzJxUAAABmIuwDwE2kSkqSlKK0GwDXs0ryUNqSfVsB1gUAAADcCGEfAHLAUFrgNyRZlBb0LaZWBAAAAGRE2AcAAAAAwM2wrRQAAAAAADdD2AcAAAAAwM0Q9gEAAAAAcDOEfQAAAAAA3AxhHwAAAAAAN0PYBwAAAADAzRD2AQAAAABwM4R9AAAAAADcDGEfAAAAAAA3Q9gHAAAAAMDNEPYBAAAAAHAzhH0AAAAAANwMYR8AAAAAADdD2AcAAAAAwM0Q9gEAAAAAcDOEfQAAAAAA3AxhHwAAAAAAN0PYBwAAAADAzRD2AQAAAABwM4R9AAAAAADcDGEfAAAAAAA3Q9gHAAAAAMDNEPYBAAAAAHAzhH0AAAAAANwMYR8AAAAAADdD2AcAAAAAwM0Q9gEAAAAAcDOEfQAAAAAA3AxhHwAAAAAAN0PYBwAAAADAzRD2AQAAAABwM4R9AAAAAADcDGEfAAAAAAA3Q9gHAAAAAMDNEPYBAAAAAHAzhH0AAAAAANwMYR8AAAAAADdD2AcAAAAAwM38Pz2cVBPl0jUeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data = random.choice([t for t in train_dataset])\n",
    "mol = to_molecule(data)\n",
    "plt.figure(figsize=(10, 5))\n",
    "draw_molecule(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GraphConv, global_add_pool\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_features = dataset.num_features\n",
    "        self.dim = dim\n",
    "\n",
    "        self.conv1 = GraphConv(num_features, dim)\n",
    "        self.conv2 = GraphConv(dim, dim)\n",
    "        self.conv3 = GraphConv(dim, dim)\n",
    "        self.conv4 = GraphConv(dim, dim)\n",
    "        self.conv5 = GraphConv(dim, dim)\n",
    "\n",
    "        self.lin1 = Linear(dim, dim)\n",
    "        self.lin2 = Linear(dim, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight).relu()\n",
    "        x = self.conv2(x, edge_index, edge_weight).relu()\n",
    "        x = self.conv3(x, edge_index, edge_weight).relu()\n",
    "        x = self.conv4(x, edge_index, edge_weight).relu()\n",
    "        x = self.conv5(x, edge_index, edge_weight).relu()\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    if epoch == 51:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.5 * param_group['lr']\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.7534, Train Acc: 0.6575, Test Acc: 0.6259\n",
      "Epoch: 002, Loss: 0.6313, Train Acc: 0.6609, Test Acc: 0.6328\n",
      "Epoch: 003, Loss: 0.6098, Train Acc: 0.6947, Test Acc: 0.6559\n",
      "Epoch: 004, Loss: 0.5942, Train Acc: 0.7057, Test Acc: 0.6674\n",
      "Epoch: 005, Loss: 0.5810, Train Acc: 0.7154, Test Acc: 0.6721\n",
      "Epoch: 006, Loss: 0.5732, Train Acc: 0.7303, Test Acc: 0.6790\n",
      "Epoch: 007, Loss: 0.5532, Train Acc: 0.7436, Test Acc: 0.6998\n",
      "Epoch: 008, Loss: 0.5606, Train Acc: 0.7395, Test Acc: 0.6882\n",
      "Epoch: 009, Loss: 0.5443, Train Acc: 0.7549, Test Acc: 0.7182\n",
      "Epoch: 010, Loss: 0.5403, Train Acc: 0.7462, Test Acc: 0.7159\n",
      "Epoch: 011, Loss: 0.5261, Train Acc: 0.7674, Test Acc: 0.7506\n",
      "Epoch: 012, Loss: 0.5303, Train Acc: 0.7741, Test Acc: 0.7413\n",
      "Epoch: 013, Loss: 0.5203, Train Acc: 0.7725, Test Acc: 0.7390\n",
      "Epoch: 014, Loss: 0.5192, Train Acc: 0.7784, Test Acc: 0.7598\n",
      "Epoch: 015, Loss: 0.5096, Train Acc: 0.7713, Test Acc: 0.7344\n",
      "Epoch: 016, Loss: 0.5066, Train Acc: 0.7864, Test Acc: 0.7691\n",
      "Epoch: 017, Loss: 0.4925, Train Acc: 0.7889, Test Acc: 0.7714\n",
      "Epoch: 018, Loss: 0.4923, Train Acc: 0.7900, Test Acc: 0.7598\n",
      "Epoch: 019, Loss: 0.4900, Train Acc: 0.7923, Test Acc: 0.7783\n",
      "Epoch: 020, Loss: 0.4914, Train Acc: 0.7882, Test Acc: 0.7552\n",
      "Epoch: 021, Loss: 0.4839, Train Acc: 0.7925, Test Acc: 0.7737\n",
      "Epoch: 022, Loss: 0.4804, Train Acc: 0.7961, Test Acc: 0.7691\n",
      "Epoch: 023, Loss: 0.4754, Train Acc: 0.7999, Test Acc: 0.7806\n",
      "Epoch: 024, Loss: 0.4566, Train Acc: 0.8038, Test Acc: 0.7783\n",
      "Epoch: 025, Loss: 0.4602, Train Acc: 0.8033, Test Acc: 0.7829\n",
      "Epoch: 026, Loss: 0.4612, Train Acc: 0.8025, Test Acc: 0.7829\n",
      "Epoch: 027, Loss: 0.4547, Train Acc: 0.8012, Test Acc: 0.7737\n",
      "Epoch: 028, Loss: 0.4473, Train Acc: 0.8089, Test Acc: 0.7898\n",
      "Epoch: 029, Loss: 0.4452, Train Acc: 0.8202, Test Acc: 0.7991\n",
      "Epoch: 030, Loss: 0.4361, Train Acc: 0.8194, Test Acc: 0.7991\n",
      "Epoch: 031, Loss: 0.4301, Train Acc: 0.8207, Test Acc: 0.7921\n",
      "Epoch: 032, Loss: 0.4327, Train Acc: 0.8268, Test Acc: 0.7991\n",
      "Epoch: 033, Loss: 0.4203, Train Acc: 0.8238, Test Acc: 0.7852\n",
      "Epoch: 034, Loss: 0.4176, Train Acc: 0.8309, Test Acc: 0.8014\n",
      "Epoch: 035, Loss: 0.4146, Train Acc: 0.8350, Test Acc: 0.8037\n",
      "Epoch: 036, Loss: 0.4033, Train Acc: 0.8233, Test Acc: 0.7945\n",
      "Epoch: 037, Loss: 0.4141, Train Acc: 0.8289, Test Acc: 0.7945\n",
      "Epoch: 038, Loss: 0.4124, Train Acc: 0.8238, Test Acc: 0.7852\n",
      "Epoch: 039, Loss: 0.4131, Train Acc: 0.8245, Test Acc: 0.7968\n",
      "Epoch: 040, Loss: 0.4087, Train Acc: 0.8332, Test Acc: 0.8060\n",
      "Epoch: 041, Loss: 0.4067, Train Acc: 0.8327, Test Acc: 0.7898\n",
      "Epoch: 042, Loss: 0.4031, Train Acc: 0.8376, Test Acc: 0.8083\n",
      "Epoch: 043, Loss: 0.3978, Train Acc: 0.8440, Test Acc: 0.8060\n",
      "Epoch: 044, Loss: 0.3937, Train Acc: 0.8422, Test Acc: 0.8060\n",
      "Epoch: 045, Loss: 0.3949, Train Acc: 0.8440, Test Acc: 0.8083\n",
      "Epoch: 046, Loss: 0.3919, Train Acc: 0.8432, Test Acc: 0.8268\n",
      "Epoch: 047, Loss: 0.3816, Train Acc: 0.8471, Test Acc: 0.8129\n",
      "Epoch: 048, Loss: 0.3828, Train Acc: 0.8443, Test Acc: 0.7945\n",
      "Epoch: 049, Loss: 0.3741, Train Acc: 0.8517, Test Acc: 0.8060\n",
      "Epoch: 050, Loss: 0.3739, Train Acc: 0.8512, Test Acc: 0.8245\n",
      "Epoch: 051, Loss: 0.3622, Train Acc: 0.8509, Test Acc: 0.7945\n",
      "Epoch: 052, Loss: 0.3795, Train Acc: 0.8225, Test Acc: 0.7783\n",
      "Epoch: 053, Loss: 0.3970, Train Acc: 0.8235, Test Acc: 0.7829\n",
      "Epoch: 054, Loss: 0.3840, Train Acc: 0.8274, Test Acc: 0.7806\n",
      "Epoch: 055, Loss: 0.3704, Train Acc: 0.8455, Test Acc: 0.8014\n",
      "Epoch: 056, Loss: 0.3484, Train Acc: 0.8481, Test Acc: 0.7945\n",
      "Epoch: 057, Loss: 0.3625, Train Acc: 0.8338, Test Acc: 0.7829\n",
      "Epoch: 058, Loss: 0.3595, Train Acc: 0.8340, Test Acc: 0.7829\n",
      "Epoch: 059, Loss: 0.3653, Train Acc: 0.8404, Test Acc: 0.7898\n",
      "Epoch: 060, Loss: 0.3492, Train Acc: 0.8478, Test Acc: 0.7991\n",
      "Epoch: 061, Loss: 0.3438, Train Acc: 0.8502, Test Acc: 0.8106\n",
      "Epoch: 062, Loss: 0.3471, Train Acc: 0.8491, Test Acc: 0.8014\n",
      "Epoch: 063, Loss: 0.3403, Train Acc: 0.8517, Test Acc: 0.8060\n",
      "Epoch: 064, Loss: 0.3421, Train Acc: 0.8438, Test Acc: 0.7945\n",
      "Epoch: 065, Loss: 0.3377, Train Acc: 0.8502, Test Acc: 0.8083\n",
      "Epoch: 066, Loss: 0.3374, Train Acc: 0.8545, Test Acc: 0.7968\n",
      "Epoch: 067, Loss: 0.3373, Train Acc: 0.8478, Test Acc: 0.8014\n",
      "Epoch: 068, Loss: 0.3328, Train Acc: 0.8430, Test Acc: 0.7875\n",
      "Epoch: 069, Loss: 0.3335, Train Acc: 0.8571, Test Acc: 0.8037\n",
      "Epoch: 070, Loss: 0.3267, Train Acc: 0.8568, Test Acc: 0.8083\n",
      "Epoch: 071, Loss: 0.3336, Train Acc: 0.8568, Test Acc: 0.8129\n",
      "Epoch: 072, Loss: 0.3258, Train Acc: 0.8522, Test Acc: 0.7921\n",
      "Epoch: 073, Loss: 0.3248, Train Acc: 0.8502, Test Acc: 0.7921\n",
      "Epoch: 074, Loss: 0.3261, Train Acc: 0.8594, Test Acc: 0.7991\n",
      "Epoch: 075, Loss: 0.3243, Train Acc: 0.8502, Test Acc: 0.7991\n",
      "Epoch: 076, Loss: 0.3294, Train Acc: 0.8527, Test Acc: 0.7945\n",
      "Epoch: 077, Loss: 0.3232, Train Acc: 0.8607, Test Acc: 0.8014\n",
      "Epoch: 078, Loss: 0.3145, Train Acc: 0.8612, Test Acc: 0.8083\n",
      "Epoch: 079, Loss: 0.3215, Train Acc: 0.8640, Test Acc: 0.8106\n",
      "Epoch: 080, Loss: 0.3145, Train Acc: 0.8665, Test Acc: 0.8060\n",
      "Epoch: 081, Loss: 0.3133, Train Acc: 0.8619, Test Acc: 0.8037\n",
      "Epoch: 082, Loss: 0.3105, Train Acc: 0.8599, Test Acc: 0.7898\n",
      "Epoch: 083, Loss: 0.3072, Train Acc: 0.8691, Test Acc: 0.8176\n",
      "Epoch: 084, Loss: 0.3045, Train Acc: 0.8601, Test Acc: 0.7991\n",
      "Epoch: 085, Loss: 0.3022, Train Acc: 0.8581, Test Acc: 0.7921\n",
      "Epoch: 086, Loss: 0.3172, Train Acc: 0.8591, Test Acc: 0.7898\n",
      "Epoch: 087, Loss: 0.3048, Train Acc: 0.8512, Test Acc: 0.7898\n",
      "Epoch: 088, Loss: 0.3194, Train Acc: 0.8571, Test Acc: 0.7852\n",
      "Epoch: 089, Loss: 0.3101, Train Acc: 0.8568, Test Acc: 0.7875\n",
      "Epoch: 090, Loss: 0.3142, Train Acc: 0.8373, Test Acc: 0.7760\n",
      "Epoch: 091, Loss: 0.3114, Train Acc: 0.8432, Test Acc: 0.7852\n",
      "Epoch: 092, Loss: 0.3182, Train Acc: 0.8571, Test Acc: 0.7945\n",
      "Epoch: 093, Loss: 0.3036, Train Acc: 0.8719, Test Acc: 0.8037\n",
      "Epoch: 094, Loss: 0.2940, Train Acc: 0.8668, Test Acc: 0.7968\n",
      "Epoch: 095, Loss: 0.2972, Train Acc: 0.8614, Test Acc: 0.7898\n",
      "Epoch: 096, Loss: 0.3024, Train Acc: 0.8696, Test Acc: 0.8060\n",
      "Epoch: 097, Loss: 0.2996, Train Acc: 0.8686, Test Acc: 0.8060\n",
      "Epoch: 098, Loss: 0.3003, Train Acc: 0.8804, Test Acc: 0.8106\n",
      "Epoch: 099, Loss: 0.2875, Train Acc: 0.8791, Test Acc: 0.8060\n",
      "Epoch: 100, Loss: 0.2822, Train Acc: 0.8773, Test Acc: 0.8037\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(dim=32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(epoch)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "          f'Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Saliency, IntegratedGradients\n",
    "\n",
    "def model_forward(edge_mask, data):\n",
    "    batch = torch.zeros(data.x.shape[0], dtype=int).to(device)\n",
    "    out = model(data.x, data.edge_index, batch, edge_mask)\n",
    "    return out\n",
    "\n",
    "\n",
    "def explain(method, data, target=0):\n",
    "    input_mask = torch.ones(data.edge_index.shape[1]).requires_grad_(True).to(device)\n",
    "    if method == 'ig':\n",
    "        ig = IntegratedGradients(model_forward)\n",
    "        mask = ig.attribute(input_mask, target=target,\n",
    "                            additional_forward_args=(data,),\n",
    "                            internal_batch_size=data.edge_index.shape[1])\n",
    "    elif method == 'saliency':\n",
    "        saliency = Saliency(model_forward)\n",
    "        mask = saliency.attribute(input_mask, target=target,\n",
    "                                  additional_forward_args=(data,))\n",
    "    else:\n",
    "        raise Exception('Unknown explanation method')\n",
    "\n",
    "    edge_mask = np.abs(mask.cpu().detach().numpy())\n",
    "    if edge_mask.max() > 0:  # avoid division by zero\n",
    "        edge_mask = edge_mask / edge_mask.max()\n",
    "    return edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def aggregate_edge_directions(edge_mask, data):\n",
    "    edge_mask_dict = defaultdict(float)\n",
    "    for val, u, v in list(zip(edge_mask, *data.edge_index)):\n",
    "        u, v = u.item(), v.item()\n",
    "        if u > v:\n",
    "            u, v = v, u\n",
    "        edge_mask_dict[(u, v)] += val\n",
    "    return edge_mask_dict\n",
    "\n",
    "\n",
    "data = random.choice([t for t in test_dataset if not t.y.item()])\n",
    "data.to(device)\n",
    "mol = to_molecule(data)\n",
    "\n",
    "for title, method in [('Integrated Gradients', 'ig'), ('Saliency', 'saliency')]:\n",
    "    edge_mask = explain(method, data, target=0)\n",
    "    edge_mask_dict = aggregate_edge_directions(edge_mask, data)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(title)\n",
    "    draw_molecule(mol, edge_mask_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum Explainer torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated explanations in ['edge_mask', 'node_mask']\n",
      "Feature importance plot has been saved to 'feature_importance.png'\n",
      "Subgraph plot has been saved to 'subgraph.pdf'\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.explain import CaptumExplainer, Explainer\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "dataset = 'Cora'\n",
    "dataset = Planetoid(\"/home/fox/projects/general/learning-portfolio/university/masters/masters-thesis/data/planetoid_dataset\", dataset)\n",
    "data = dataset[0]\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "for _ in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type='topk',\n",
    "        value=200,\n",
    "    ),\n",
    ")\n",
    "\n",
    "node_index = 10\n",
    "explanation = explainer(data.x, data.edge_index, index=node_index)\n",
    "print(f'Generated explanations in {explanation.available_explanations}')\n",
    "\n",
    "path = 'feature_importance.png'\n",
    "explanation.visualize_feature_importance(path, top_k=10)\n",
    "print(f\"Feature importance plot has been saved to '{path}'\")\n",
    "\n",
    "path = 'subgraph.pdf'\n",
    "explanation.visualize_graph(path)\n",
    "print(f\"Subgraph plot has been saved to '{path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated explanations in ['edge_mask', 'node_mask']\n",
      "Feature importance plot has been saved to 'feature_importance.png'\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import MovieLens\n",
    "from torch_geometric.explain import CaptumExplainer, Explainer, GNNExplainer\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = MovieLens(\"data/MovieLens\", model_name='all-MiniLM-L6-v2')\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "# Add user node features for message passing:\n",
    "data['user'].x = torch.eye(data['user'].num_nodes, device=device)\n",
    "del data['user'].num_nodes\n",
    "\n",
    "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
    "data = T.ToUndirected()(data)\n",
    "data['user', 'movie'].edge_label = data['user',\n",
    "                                        'movie'].edge_label.to(torch.float)\n",
    "del data['movie', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label.\n",
    "\n",
    "# Perform a link-level split into training, validation, and test edges:\n",
    "data, _, _ = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'movie')],\n",
    "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")(data)\n",
    "\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "\n",
    "model = Model(hidden_channels=32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(\n",
    "        data.x_dict,\n",
    "        data.edge_index_dict,\n",
    "        data['user', 'movie'].edge_label_index,\n",
    "    )\n",
    "    loss = F.mse_loss(pred, data['user', 'movie'].edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='edge',\n",
    "        return_type='raw',\n",
    "    ),\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type='topk',\n",
    "        value=200,\n",
    "    ),\n",
    ")\n",
    "\n",
    "index = torch.tensor([2, 10])  # Explain edge labels with index 2 and 10.\n",
    "explanation = explainer(\n",
    "    data.x_dict,\n",
    "    data.edge_index_dict,\n",
    "    index=index,\n",
    "    edge_label_index=data['user', 'movie'].edge_label_index,\n",
    ")\n",
    "print(f'Generated explanations in {explanation.available_explanations}')\n",
    "\n",
    "path = 'feature_importance.png'\n",
    "explanation.visualize_feature_importance(path, top_k=10)\n",
    "print(f\"Feature importance plot has been saved to '{path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
