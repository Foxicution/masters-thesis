{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import OGB_MAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from mt.helper import flatten\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from typing import Any\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data, Batch\n",
    "import requests\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import cached_property\n",
    "from mt.definitions import REPO_DIR\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all, cfg, ch22, dg, ast\n",
    "# also npy features\n",
    "g_types = {\"ast\": 1, \"ch22\": 2, \"cfg\": 3, \"dg\": 4, \"cfg_ast\": 5}\n",
    "repo_dir = REPO_DIR / \"pytorch/vision\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, repo_dir: Path, graph_type: str) -> None:\n",
    "        self.graph_type = graph_type\n",
    "        self.repo_dir = repo_dir\n",
    "        with open(repo_dir / \"maps.json\") as f:\n",
    "            self.maps = json.load(f)\n",
    "        \n",
    "        self.node_type = len(self.maps[graph_type][\"nodes\"])\n",
    "        self.g_type_node = len(g_types) - 1\n",
    "        self.g_type_edge = len(g_types) if graph_type != \"all\" else len(g_types) + 1\n",
    "        self.edge_type = len(self.maps[graph_type][\"edges\"])\n",
    "\n",
    "        self.root_dir = repo_dir / \"pts\"\n",
    "        with open(self.repo_dir / \"residuals.pkl\", \"rb\") as f:\n",
    "            self.targets = pickle.load(f)\n",
    "        self.files = list(self.root_dir.glob(f\"{graph_type}_*.pt\"))\n",
    "        self.num_samples = len(self.files)\n",
    "\n",
    "        target_values = list(self.targets.values())\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.fit([[target] for target in target_values])\n",
    "\n",
    "        # Scale the targets and store them in a dictionary\n",
    "        self.scaled_targets = {key: self.scaler.transform([[value]])[0][0] for key, value in self.targets.items()}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        100\n",
    "        # return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[str, Batch, torch.FloatTensor]:\n",
    "        commit_sha, graph = torch.load(self.root_dir / f\"{self.graph_type}_{idx}.pt\")\n",
    "        scaled_target = self.scaled_targets[commit_sha]\n",
    "        graph.y = torch.tensor(scaled_target, dtype=torch.float32)\n",
    "        return commit_sha, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GraphDataset(repo_dir, \"dg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('c9eab681e4bd8800fd0169c26e225b64f696cb8a',\n",
       " Data(x=[3507, 2], edge_index=[2, 3382], edge_attr=[3382, 2], y=0.5616480708122253))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_s = {}\n",
    "for i in range(100): \n",
    "    c_s, _ = dataset[i]\n",
    "    i_s[i] = c_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(repo_dir / 'idx_to_sha.pkl', \"wb\") as f:\n",
    "    pickle.dump(i_s, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GraphDataset'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1].x[:, 1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[231, 333, 627, 324, 99, 879, 831, 319, 136, 47, 513, 673, 934, 211, 147, 305, 765, 335, 871, 557, 395, 297, 970, 302, 497, 572, 288, 25, 462, 67, 774, 316, 456, 163, 807, 289, 138, 680, 329, 779, 975, 176, 760, 492, 762, 510, 294, 579, 190, 993, 151, 240, 146, 905, 743, 539, 690, 85, 260, 158, 617, 619, 900, 654, 672, 300, 89, 797, 257, 81, 474, 182, 906, 675, 963, 506, 910, 264, 325, 307, 734, 568, 755, 663, 76, 56, 315, 388, 268, 600, 290, 251, 573, 756, 49, 744, 84, 887, 142, 772]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define the total number of indexes\n",
    "total_indexes = 1000\n",
    "\n",
    "# Generate a list of indexes from 0 to 999\n",
    "indexes = list(range(total_indexes))\n",
    "\n",
    "# Randomly sample 100 indexes from the list\n",
    "sampled_indexes = random.sample(indexes, 100)\n",
    "\n",
    "print(sampled_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/home/fox/projects/general/learning-portfolio/university/masters/masters-thesis/data/repos/pytorch/vision/sample.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sampled_indexes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6, 17, 230)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.g_type_node, dataset.g_type_edge, dataset.edge_type, dataset.node_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[961808, 2], edge_index=[2, 573692], edge_attr=[573692, 2], y=0.5556620955467224)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0][1]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3507"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = data.num_nodes\n",
    "indices = torch.randperm(num_nodes)\n",
    "train_idx = indices[:int(0.8 * num_nodes)]\n",
    "val_idx = indices[int(0.8 * num_nodes):int(0.9 * num_nodes)]\n",
    "test_idx = indices[int(0.9 * num_nodes):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loaders using NeighborLoader\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[1000] * 2,  # Adjust number of neighbors as needed\n",
    "    batch_size=1000,\n",
    "    input_nodes=train_idx,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[351, 2], edge_index=[2, 301], edge_attr=[301, 2], y=0.5556620955467224, n_id=[351], e_id=[301], input_id=[240], batch_size=240)\n",
      "Data(x=[351, 2], edge_index=[2, 301], edge_attr=[301, 2], y=0.5556620955467224, n_id=[351], e_id=[301], input_id=[240], batch_size=240)\n"
     ]
    }
   ],
   "source": [
    "# Example iteration through the loader\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2958276, 2], edge_index=[2, 4742679], edge_attr=[4742679, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NeighborLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mNeighborLoader\u001b[49m(\n\u001b[1;32m      2\u001b[0m     dataset[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Sample 30 neighbors for each node for 2 iterations\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     num_neighbors\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1000\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Use a batch size of 128 for sampling training nodes\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      7\u001b[0m     input_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NeighborLoader' is not defined"
     ]
    }
   ],
   "source": [
    "loader = NeighborLoader(\n",
    "    dataset[0][1],\n",
    "    # Sample 30 neighbors for each node for 2 iterations\n",
    "    num_neighbors=[1000] * 3,\n",
    "    # Use a batch size of 128 for sampling training nodes\n",
    "    batch_size=128,\n",
    "    input_nodes=len(dataset[0][1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, AttentionalAggregation, GATv2Conv, GCNConv, GINEConv, SAGEConv\n",
    "from torch.nn import Sequential, Linear, ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, num_x, num_y, emb_x, emb_y):\n",
    "        super(NodeFeatureEmbedding, self).__init__()\n",
    "        self.embedding_x = nn.Embedding(num_x, emb_x)\n",
    "        self.embedding_y = nn.Embedding(num_y, emb_y)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Assuming x is of shape (num_nodes, 2), where each entry is a category index\n",
    "        x_embedding = self.embedding_x(x[:, 0])\n",
    "        y_embedding = self.embedding_y(x[:, 1])\n",
    "        # Concatenate the embeddings along the last dimension\n",
    "        return torch.cat([x_embedding, y_embedding], dim=-1)\n",
    "\n",
    "class EdgeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, num_x, num_y, emb_x, emb_y):\n",
    "        super(EdgeFeatureEmbedding, self).__init__()\n",
    "        self.embedding_x = nn.Embedding(num_x, emb_x)\n",
    "        self.embedding_y = nn.Embedding(num_y, emb_y)\n",
    "        \n",
    "    def forward(self, edge_attr):\n",
    "        # Assuming edge_attr is of shape (num_edges, 2), where each entry is a category index\n",
    "        x_embedding = self.embedding_x(edge_attr[:, 0])\n",
    "        y_embedding = self.embedding_y(edge_attr[:, 1])\n",
    "        # Concatenate the embeddings along the last dimension\n",
    "        return torch.cat([x_embedding, y_embedding], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_emb_model = NodeFeatureEmbedding(dataset.node_type, dataset.g_type_node, 56, 8)\n",
    "edge_emb_model = EdgeFeatureEmbedding(dataset.edge_type, dataset.g_type_edge, 56, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_sha, data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[961808, 2], edge_index=[2, 573692], edge_attr=[573692, 2], y=0.5556620955467224)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_x = node_emb_model(data.x)\n",
    "edge_index = data.edge_index\n",
    "emb_edge_attr = edge_emb_model(data.edge_attr)\n",
    "emb_x.shape, emb_edge_attr.shape\n",
    "batch = data.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, node_embedding_dim, edge_embedding_dim, hidden_channels, out_channels=1):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(node_embedding_dim, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(edge_embedding_dim, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, 1)  # Transform edge attributes to scalar weights\n",
    "        )\n",
    "        \n",
    "        self.regressor = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        edge_weight = self.edge_mlp(edge_attr).squeeze()  # Transform edge attributes to edge weights\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_weight))\n",
    "        x = F.relu(self.conv3(x, edge_index, edge_weight))\n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        return self.regressor(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3304, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCNModel(64, 64, 124)\n",
    "model(emb_x, edge_index, emb_edge_attr, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention based\n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, node_embedding_dim, edge_embedding_dim, hidden_channels, agg_hidden_channels, out_channels=1, num_heads=2):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATv2Conv(node_embedding_dim, hidden_channels, heads=num_heads, concat=True, edge_dim=edge_embedding_dim)\n",
    "        self.conv2 = GATv2Conv(hidden_channels * num_heads, hidden_channels, heads=num_heads, concat=True, edge_dim=edge_embedding_dim)\n",
    "        self.conv3 = GATv2Conv(hidden_channels * num_heads, hidden_channels, heads=1, concat=False, edge_dim=edge_embedding_dim)\n",
    "        \n",
    "        self.gate_nn = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, agg_hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(agg_hidden_channels, 1)\n",
    "        )\n",
    "\n",
    "        self.attention_aggregation = AttentionalAggregation(gate_nn=self.gate_nn)\n",
    "        \n",
    "        self.regressor = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        \n",
    "        x = self.attention_aggregation(x, batch)\n",
    "        \n",
    "        return self.regressor(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure, sequence based\n",
    "class GINEModel(nn.Module):\n",
    "    def __init__(self, node_embedding_dim, edge_embedding_dim, hidden_channels, lstm_hidden_dim, out_channels=1):\n",
    "        super(GINEModel, self).__init__()\n",
    "        nn1 = Sequential(Linear(node_embedding_dim, hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels))\n",
    "        nn2 = Sequential(Linear(hidden_channels, hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels))\n",
    "        nn3 = Sequential(Linear(hidden_channels, hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels))\n",
    "        \n",
    "        self.conv1 = GINEConv(nn1, edge_dim=edge_embedding_dim)\n",
    "        self.conv2 = GINEConv(nn2, edge_dim=edge_embedding_dim)\n",
    "        self.conv3 = GINEConv(nn3, edge_dim=edge_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(hidden_channels, lstm_hidden_dim, batch_first=True)\n",
    "        \n",
    "        self.regressor = nn.Linear(lstm_hidden_dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = F.relu(self.conv3(x, edge_index, edge_attr))\n",
    "        \n",
    "        # Aggregate node embeddings into a graph-level embedding\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Expand dimensions to fit LSTM input requirements: (batch_size, seq_len, input_dim)\n",
    "        x = x.unsqueeze(1)  # Assuming each graph is treated as a single sequence\n",
    "        \n",
    "        # Pass through LSTM\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        # Use the output of the last LSTM cell\n",
    "        x = x[:, -1, :]\n",
    "        \n",
    "        return self.regressor(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0061], grad_fn=<ViewBackward0>)\n",
      "tensor([0.5656])\n"
     ]
    }
   ],
   "source": [
    "graph_types = [\"\"]\n",
    "\n",
    "for graph_type in graph_types:\n",
    "    dataset = GraphDataset(repo_dir, graph_type)\n",
    "    node_emb_model = NodeFeatureEmbedding(dataset.node_type, dataset.g_type_node, 56, 8)\n",
    "    edge_emb_model = EdgeFeatureEmbedding(dataset.edge_type, dataset.g_type_edge, 56, 8)\n",
    "    model1, model2, model3 = GCNModel(64, 64, 1), GATModel(64, 64, 1, 1), GINEModel(64, 64, 1, 1)\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "    for commit_sha, graph, target in train_loader:\n",
    "        emb_x = node_emb_model(graph.x)\n",
    "        edge_index = graph.edge_index\n",
    "        emb_edge_attr = edge_emb_model(graph.edge_attr)\n",
    "        batch = graph.batch\n",
    "        print(model1(emb_x, edge_index, emb_edge_attr, batch).view(-1))\n",
    "        print(target)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=50, patience=10):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for commit_sha, graph, target in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            graph = graph.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            emb_x = node_emb_model(graph.x.to(device))\n",
    "            edge_index = graph.edge_index.to(device)\n",
    "            emb_edge_attr = edge_emb_model(graph.edge_attr.to(device))\n",
    "            batch = graph.batch.to(device)\n",
    "            output = model(emb_x, edge_index, emb_edge_attr, batch)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for commit_sha, graph, target in val_loader:\n",
    "                graph = graph.to(device)\n",
    "                target = target.to(device)\n",
    "                emb_x = node_emb_model(graph.x.to(device))\n",
    "                edge_index = graph.edge_index.to(device)\n",
    "                emb_edge_attr = edge_emb_model(graph.edge_attr.to(device))\n",
    "                batch = graph.batch.to(device)\n",
    "                output = model(emb_x, edge_index, emb_edge_attr, batch)\n",
    "                val_loss += criterion(output, target).item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('best_model.pt'))\n",
    "    \n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = Path('/path/to/repo')\n",
    "graph_types = [\"ast\", \"cfg\", \"ddg\", \"pdg\", \"cdg\"]  # Example graph types\n",
    "models = {\n",
    "    \"GCNModel\": GCNModel(64, 64, 100, 1),\n",
    "    \"GATModel\": GATModel(64, 64, 100, 100, 1),\n",
    "    \"GINEModel\": GINEModel(64, 64, 100, 100, 1)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for graph_type in graph_types:\n",
    "    dataset = GraphDataset(repo_dir, graph_type)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    for model_name, model_class in models.items():\n",
    "        # Initialize node and edge embeddings\n",
    "        node_emb_model = NodeFeatureEmbedding(dataset.node_type, dataset.g_type_node, 56, 8).to(device)\n",
    "        edge_emb_model = EdgeFeatureEmbedding(dataset.edge_type, dataset.g_type_edge, 56, 8).to(device)\n",
    "        \n",
    "        # Initialize model, optimizer, and loss criterion\n",
    "        model = model_class.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Train the model\n",
    "        print(f'Training {model_name} on {graph_type} dataset...')\n",
    "        model, train_losses, val_losses = train_model(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=50)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        test_true = []\n",
    "        test_pred = []\n",
    "        with torch.no_grad():\n",
    "            for commit_sha, graph, target in test_loader:\n",
    "                graph = graph.to(device)\n",
    "                target = target.to(device)\n",
    "                emb_x = node_emb_model(graph.x.to(device))\n",
    "                edge_index = graph.edge_index.to(device)\n",
    "                emb_edge_attr = edge_emb_model(graph.edge_attr.to(device))\n",
    "                batch = graph.batch.to(device)\n",
    "                output = model(emb_x, edge_index, emb_edge_attr, batch)\n",
    "                test_true.append(target.cpu().numpy())\n",
    "                test_pred.append(output.cpu().numpy())\n",
    "        \n",
    "        test_true = np.concatenate(test_true)\n",
    "        test_pred = np.concatenate(test_pred)\n",
    "        mse = mean_squared_error(test_true, test_pred)\n",
    "        \n",
    "        # Save results\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            \"graph_type\": graph_type,\n",
    "            \"test_true\": test_true,\n",
    "            \"test_pred\": test_pred,\n",
    "            \"mse\": mse\n",
    "        })\n",
    "        \n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), f'{model_name}_{graph_type}.pt')\n",
    "\n",
    "# Save all results to a file\n",
    "with open('results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
